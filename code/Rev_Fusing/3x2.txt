
wave_rev_auto:     ファイル形式 elf64-x86-64


セクション .init の逆アセンブル:

0000000000001000 <_init>:
    1000:	f3 0f 1e fa          	endbr64 
    1004:	48 83 ec 08          	sub    $0x8,%rsp
    1008:	48 8b 05 c9 6f 00 00 	mov    0x6fc9(%rip),%rax        # 7fd8 <__gmon_start__@Base>
    100f:	48 85 c0             	test   %rax,%rax
    1012:	74 02                	je     1016 <_init+0x16>
    1014:	ff d0                	call   *%rax
    1016:	48 83 c4 08          	add    $0x8,%rsp
    101a:	c3                   	ret    

セクション .plt の逆アセンブル:

0000000000001020 <.plt>:
    1020:	ff 35 02 6f 00 00    	push   0x6f02(%rip)        # 7f28 <_GLOBAL_OFFSET_TABLE_+0x8>
    1026:	f2 ff 25 03 6f 00 00 	bnd jmp *0x6f03(%rip)        # 7f30 <_GLOBAL_OFFSET_TABLE_+0x10>
    102d:	0f 1f 00             	nopl   (%rax)
    1030:	f3 0f 1e fa          	endbr64 
    1034:	68 00 00 00 00       	push   $0x0
    1039:	f2 e9 e1 ff ff ff    	bnd jmp 1020 <_init+0x20>
    103f:	90                   	nop
    1040:	f3 0f 1e fa          	endbr64 
    1044:	68 01 00 00 00       	push   $0x1
    1049:	f2 e9 d1 ff ff ff    	bnd jmp 1020 <_init+0x20>
    104f:	90                   	nop
    1050:	f3 0f 1e fa          	endbr64 
    1054:	68 02 00 00 00       	push   $0x2
    1059:	f2 e9 c1 ff ff ff    	bnd jmp 1020 <_init+0x20>
    105f:	90                   	nop
    1060:	f3 0f 1e fa          	endbr64 
    1064:	68 03 00 00 00       	push   $0x3
    1069:	f2 e9 b1 ff ff ff    	bnd jmp 1020 <_init+0x20>
    106f:	90                   	nop
    1070:	f3 0f 1e fa          	endbr64 
    1074:	68 04 00 00 00       	push   $0x4
    1079:	f2 e9 a1 ff ff ff    	bnd jmp 1020 <_init+0x20>
    107f:	90                   	nop
    1080:	f3 0f 1e fa          	endbr64 
    1084:	68 05 00 00 00       	push   $0x5
    1089:	f2 e9 91 ff ff ff    	bnd jmp 1020 <_init+0x20>
    108f:	90                   	nop
    1090:	f3 0f 1e fa          	endbr64 
    1094:	68 06 00 00 00       	push   $0x6
    1099:	f2 e9 81 ff ff ff    	bnd jmp 1020 <_init+0x20>
    109f:	90                   	nop
    10a0:	f3 0f 1e fa          	endbr64 
    10a4:	68 07 00 00 00       	push   $0x7
    10a9:	f2 e9 71 ff ff ff    	bnd jmp 1020 <_init+0x20>
    10af:	90                   	nop
    10b0:	f3 0f 1e fa          	endbr64 
    10b4:	68 08 00 00 00       	push   $0x8
    10b9:	f2 e9 61 ff ff ff    	bnd jmp 1020 <_init+0x20>
    10bf:	90                   	nop
    10c0:	f3 0f 1e fa          	endbr64 
    10c4:	68 09 00 00 00       	push   $0x9
    10c9:	f2 e9 51 ff ff ff    	bnd jmp 1020 <_init+0x20>
    10cf:	90                   	nop
    10d0:	f3 0f 1e fa          	endbr64 
    10d4:	68 0a 00 00 00       	push   $0xa
    10d9:	f2 e9 41 ff ff ff    	bnd jmp 1020 <_init+0x20>
    10df:	90                   	nop
    10e0:	f3 0f 1e fa          	endbr64 
    10e4:	68 0b 00 00 00       	push   $0xb
    10e9:	f2 e9 31 ff ff ff    	bnd jmp 1020 <_init+0x20>
    10ef:	90                   	nop
    10f0:	f3 0f 1e fa          	endbr64 
    10f4:	68 0c 00 00 00       	push   $0xc
    10f9:	f2 e9 21 ff ff ff    	bnd jmp 1020 <_init+0x20>
    10ff:	90                   	nop
    1100:	f3 0f 1e fa          	endbr64 
    1104:	68 0d 00 00 00       	push   $0xd
    1109:	f2 e9 11 ff ff ff    	bnd jmp 1020 <_init+0x20>
    110f:	90                   	nop
    1110:	f3 0f 1e fa          	endbr64 
    1114:	68 0e 00 00 00       	push   $0xe
    1119:	f2 e9 01 ff ff ff    	bnd jmp 1020 <_init+0x20>
    111f:	90                   	nop
    1120:	f3 0f 1e fa          	endbr64 
    1124:	68 0f 00 00 00       	push   $0xf
    1129:	f2 e9 f1 fe ff ff    	bnd jmp 1020 <_init+0x20>
    112f:	90                   	nop
    1130:	f3 0f 1e fa          	endbr64 
    1134:	68 10 00 00 00       	push   $0x10
    1139:	f2 e9 e1 fe ff ff    	bnd jmp 1020 <_init+0x20>
    113f:	90                   	nop
    1140:	f3 0f 1e fa          	endbr64 
    1144:	68 11 00 00 00       	push   $0x11
    1149:	f2 e9 d1 fe ff ff    	bnd jmp 1020 <_init+0x20>
    114f:	90                   	nop
    1150:	f3 0f 1e fa          	endbr64 
    1154:	68 12 00 00 00       	push   $0x12
    1159:	f2 e9 c1 fe ff ff    	bnd jmp 1020 <_init+0x20>
    115f:	90                   	nop
    1160:	f3 0f 1e fa          	endbr64 
    1164:	68 13 00 00 00       	push   $0x13
    1169:	f2 e9 b1 fe ff ff    	bnd jmp 1020 <_init+0x20>
    116f:	90                   	nop

セクション .plt.got の逆アセンブル:

0000000000001170 <__cxa_finalize@plt>:
    1170:	f3 0f 1e fa          	endbr64 
    1174:	f2 ff 25 75 6e 00 00 	bnd jmp *0x6e75(%rip)        # 7ff0 <__cxa_finalize@GLIBC_2.2.5>
    117b:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

セクション .plt.sec の逆アセンブル:

0000000000001180 <memset@plt>:
    1180:	f3 0f 1e fa          	endbr64 
    1184:	f2 ff 25 ad 6d 00 00 	bnd jmp *0x6dad(%rip)        # 7f38 <memset@GLIBC_2.2.5>
    118b:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

0000000000001190 <omp_get_num_threads@plt>:
    1190:	f3 0f 1e fa          	endbr64 
    1194:	f2 ff 25 a5 6d 00 00 	bnd jmp *0x6da5(%rip)        # 7f40 <omp_get_num_threads@OMP_1.0>
    119b:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

00000000000011a0 <posix_memalign@plt>:
    11a0:	f3 0f 1e fa          	endbr64 
    11a4:	f2 ff 25 9d 6d 00 00 	bnd jmp *0x6d9d(%rip)        # 7f48 <posix_memalign@GLIBC_2.2.5>
    11ab:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

00000000000011b0 <clock_gettime@plt>:
    11b0:	f3 0f 1e fa          	endbr64 
    11b4:	f2 ff 25 95 6d 00 00 	bnd jmp *0x6d95(%rip)        # 7f50 <clock_gettime@GLIBC_2.17>
    11bb:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

00000000000011c0 <__assert_fail@plt>:
    11c0:	f3 0f 1e fa          	endbr64 
    11c4:	f2 ff 25 8d 6d 00 00 	bnd jmp *0x6d8d(%rip)        # 7f58 <__assert_fail@GLIBC_2.2.5>
    11cb:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

00000000000011d0 <__printf_chk@plt>:
    11d0:	f3 0f 1e fa          	endbr64 
    11d4:	f2 ff 25 85 6d 00 00 	bnd jmp *0x6d85(%rip)        # 7f60 <__printf_chk@GLIBC_2.3.4>
    11db:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

00000000000011e0 <putchar@plt>:
    11e0:	f3 0f 1e fa          	endbr64 
    11e4:	f2 ff 25 7d 6d 00 00 	bnd jmp *0x6d7d(%rip)        # 7f68 <putchar@GLIBC_2.2.5>
    11eb:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

00000000000011f0 <malloc@plt>:
    11f0:	f3 0f 1e fa          	endbr64 
    11f4:	f2 ff 25 75 6d 00 00 	bnd jmp *0x6d75(%rip)        # 7f70 <malloc@GLIBC_2.2.5>
    11fb:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

0000000000001200 <omp_get_thread_num@plt>:
    1200:	f3 0f 1e fa          	endbr64 
    1204:	f2 ff 25 6d 6d 00 00 	bnd jmp *0x6d6d(%rip)        # 7f78 <omp_get_thread_num@OMP_1.0>
    120b:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

0000000000001210 <free@plt>:
    1210:	f3 0f 1e fa          	endbr64 
    1214:	f2 ff 25 65 6d 00 00 	bnd jmp *0x6d65(%rip)        # 7f80 <free@GLIBC_2.2.5>
    121b:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

0000000000001220 <strtol@plt>:
    1220:	f3 0f 1e fa          	endbr64 
    1224:	f2 ff 25 5d 6d 00 00 	bnd jmp *0x6d5d(%rip)        # 7f88 <strtol@GLIBC_2.2.5>
    122b:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

0000000000001230 <GOMP_parallel@plt>:
    1230:	f3 0f 1e fa          	endbr64 
    1234:	f2 ff 25 55 6d 00 00 	bnd jmp *0x6d55(%rip)        # 7f90 <GOMP_parallel@GOMP_4.0>
    123b:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

0000000000001240 <madvise@plt>:
    1240:	f3 0f 1e fa          	endbr64 
    1244:	f2 ff 25 4d 6d 00 00 	bnd jmp *0x6d4d(%rip)        # 7f98 <madvise@GLIBC_2.2.5>
    124b:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

0000000000001250 <sincos@plt>:
    1250:	f3 0f 1e fa          	endbr64 
    1254:	f2 ff 25 45 6d 00 00 	bnd jmp *0x6d45(%rip)        # 7fa0 <sincos@GLIBC_2.2.5>
    125b:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

0000000000001260 <__stack_chk_fail@plt>:
    1260:	f3 0f 1e fa          	endbr64 
    1264:	f2 ff 25 3d 6d 00 00 	bnd jmp *0x6d3d(%rip)        # 7fa8 <__stack_chk_fail@GLIBC_2.4>
    126b:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

0000000000001270 <munmap@plt>:
    1270:	f3 0f 1e fa          	endbr64 
    1274:	f2 ff 25 35 6d 00 00 	bnd jmp *0x6d35(%rip)        # 7fb0 <munmap@GLIBC_2.2.5>
    127b:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

0000000000001280 <rand@plt>:
    1280:	f3 0f 1e fa          	endbr64 
    1284:	f2 ff 25 2d 6d 00 00 	bnd jmp *0x6d2d(%rip)        # 7fb8 <rand@GLIBC_2.2.5>
    128b:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

0000000000001290 <memcpy@plt>:
    1290:	f3 0f 1e fa          	endbr64 
    1294:	f2 ff 25 25 6d 00 00 	bnd jmp *0x6d25(%rip)        # 7fc0 <memcpy@GLIBC_2.14>
    129b:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

00000000000012a0 <mmap@plt>:
    12a0:	f3 0f 1e fa          	endbr64 
    12a4:	f2 ff 25 1d 6d 00 00 	bnd jmp *0x6d1d(%rip)        # 7fc8 <mmap@GLIBC_2.2.5>
    12ab:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

00000000000012b0 <drand48@plt>:
    12b0:	f3 0f 1e fa          	endbr64 
    12b4:	f2 ff 25 15 6d 00 00 	bnd jmp *0x6d15(%rip)        # 7fd0 <drand48@GLIBC_2.2.5>
    12bb:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

セクション .text の逆アセンブル:

00000000000012c0 <main>:
    12c0:	f3 0f 1e fa          	endbr64 
    12c4:	41 57                	push   %r15
    12c6:	41 56                	push   %r14
    12c8:	41 55                	push   %r13
    12ca:	ba 0a 00 00 00       	mov    $0xa,%edx
    12cf:	41 54                	push   %r12
    12d1:	55                   	push   %rbp
    12d2:	53                   	push   %rbx
    12d3:	48 89 f3             	mov    %rsi,%rbx
    12d6:	48 81 ec 98 00 00 00 	sub    $0x98,%rsp
    12dd:	48 8b 7e 08          	mov    0x8(%rsi),%rdi
    12e1:	31 f6                	xor    %esi,%esi
    12e3:	64 48 8b 04 25 28 00 	mov    %fs:0x28,%rax
    12ea:	00 00 
    12ec:	48 89 84 24 88 00 00 	mov    %rax,0x88(%rsp)
    12f3:	00 
    12f4:	31 c0                	xor    %eax,%eax
    12f6:	e8 25 ff ff ff       	call   1220 <strtol@plt>
    12fb:	48 8b 7b 08          	mov    0x8(%rbx),%rdi
    12ff:	31 f6                	xor    %esi,%esi
    1301:	ba 0a 00 00 00       	mov    $0xa,%edx
    1306:	48 89 c5             	mov    %rax,%rbp
    1309:	41 89 c6             	mov    %eax,%r14d
    130c:	e8 0f ff ff ff       	call   1220 <strtol@plt>
    1311:	48 8b 7b 10          	mov    0x10(%rbx),%rdi
    1315:	31 f6                	xor    %esi,%esi
    1317:	ba 0a 00 00 00       	mov    $0xa,%edx
    131c:	49 89 c4             	mov    %rax,%r12
    131f:	e8 fc fe ff ff       	call   1220 <strtol@plt>
    1324:	48 8b 7b 18          	mov    0x18(%rbx),%rdi
    1328:	31 f6                	xor    %esi,%esi
    132a:	ba 0a 00 00 00       	mov    $0xa,%edx
    132f:	48 89 44 24 10       	mov    %rax,0x10(%rsp)
    1334:	8b 44 24 10          	mov    0x10(%rsp),%eax
    1338:	89 44 24 48          	mov    %eax,0x48(%rsp)
    133c:	e8 df fe ff ff       	call   1220 <strtol@plt>
    1341:	48 8b 7b 20          	mov    0x20(%rbx),%rdi
    1345:	31 f6                	xor    %esi,%esi
    1347:	ba 0a 00 00 00       	mov    $0xa,%edx
    134c:	49 89 c5             	mov    %rax,%r13
    134f:	8d 5d 10             	lea    0x10(%rbp),%ebx
    1352:	e8 c9 fe ff ff       	call   1220 <strtol@plt>
    1357:	c5 f9 6e 74 24 10    	vmovd  0x10(%rsp),%xmm6
    135d:	45 8d 44 24 ff       	lea    -0x1(%r12),%r8d
    1362:	f7 c5 ff 01 00 00    	test   $0x1ff,%ebp
    1368:	43 8d 0c 00          	lea    (%r8,%r8,1),%ecx
    136c:	0f 45 dd             	cmovne %ebp,%ebx
    136f:	c4 c1 79 6e ec       	vmovd  %r12d,%xmm5
    1374:	44 89 e6             	mov    %r12d,%esi
    1377:	f7 c1 fe 01 00 00    	test   $0x1fe,%ecx
    137d:	c4 e3 51 22 c3 01    	vpinsrd $0x1,%ebx,%xmm5,%xmm0
    1383:	89 da                	mov    %ebx,%edx
    1385:	44 89 f7             	mov    %r14d,%edi
    1388:	44 89 44 24 4c       	mov    %r8d,0x4c(%rsp)
    138d:	89 4c 24 08          	mov    %ecx,0x8(%rsp)
    1391:	48 89 44 24 18       	mov    %rax,0x18(%rsp)
    1396:	c4 e3 49 22 cd 01    	vpinsrd $0x1,%ebp,%xmm6,%xmm1
    139c:	8d 69 10             	lea    0x10(%rcx),%ebp
    139f:	0f 45 e9             	cmovne %ecx,%ebp
    13a2:	c5 f1 6c c8          	vpunpcklqdq %xmm0,%xmm1,%xmm1
    13a6:	c5 f9 6e fd          	vmovd  %ebp,%xmm7
    13aa:	c5 f9 7f 4c 24 30    	vmovdqa %xmm1,0x30(%rsp)
    13b0:	c4 c3 41 22 d5 01    	vpinsrd $0x1,%r13d,%xmm7,%xmm2
    13b6:	c5 f9 d6 54 24 40    	vmovq  %xmm2,0x40(%rsp)
    13bc:	e8 5f 09 00 00       	call   1d20 <dmatrix>
    13c1:	8b 74 24 48          	mov    0x48(%rsp),%esi
    13c5:	8b 7c 24 08          	mov    0x8(%rsp),%edi
    13c9:	89 ea                	mov    %ebp,%edx
    13cb:	49 89 c5             	mov    %rax,%r13
    13ce:	e8 4d 09 00 00       	call   1d20 <dmatrix>
    13d3:	89 d9                	mov    %ebx,%ecx
    13d5:	44 89 e6             	mov    %r12d,%esi
    13d8:	44 89 f7             	mov    %r14d,%edi
    13db:	c4 e1 f9 6e e0       	vmovq  %rax,%xmm4
    13e0:	4c 89 ea             	mov    %r13,%rdx
    13e3:	48 89 44 24 08       	mov    %rax,0x8(%rsp)
    13e8:	c4 c3 d9 22 dd 01    	vpinsrq $0x1,%r13,%xmm4,%xmm3
    13ee:	c5 f9 7f 5c 24 20    	vmovdqa %xmm3,0x20(%rsp)
    13f4:	e8 d7 09 00 00       	call   1dd0 <drandomM>
    13f9:	48 8b 54 24 08       	mov    0x8(%rsp),%rdx
    13fe:	8b 74 24 48          	mov    0x48(%rsp),%esi
    1402:	8b 7c 24 4c          	mov    0x4c(%rsp),%edi
    1406:	89 e9                	mov    %ebp,%ecx
    1408:	48 63 ed             	movslq %ebp,%rbp
    140b:	e8 40 0a 00 00       	call   1e50 <drandomG>
    1410:	89 d9                	mov    %ebx,%ecx
    1412:	44 89 e2             	mov    %r12d,%edx
    1415:	44 89 f6             	mov    %r14d,%esi
    1418:	4c 89 ef             	mov    %r13,%rdi
    141b:	4c 8d 74 24 50       	lea    0x50(%rsp),%r14
    1420:	48 63 db             	movslq %ebx,%rbx
    1423:	4d 63 e4             	movslq %r12d,%r12
    1426:	e8 b5 30 00 00       	call   44e0 <copyMatrix>
    142b:	49 0f af dc          	imul   %r12,%rbx
    142f:	4c 89 f6             	mov    %r14,%rsi
    1432:	bf 01 00 00 00       	mov    $0x1,%edi
    1437:	e8 74 fd ff ff       	call   11b0 <clock_gettime@plt>
    143c:	48 69 44 24 50 00 ca 	imul   $0x3b9aca00,0x50(%rsp),%rax
    1443:	9a 3b 
    1445:	c5 f8 57 c0          	vxorps %xmm0,%xmm0,%xmm0
    1449:	48 03 44 24 58       	add    0x58(%rsp),%rax
    144e:	c4 e1 fb 2a c0       	vcvtsi2sd %rax,%xmm0,%xmm0
    1453:	c5 fb 59 05 85 4c 00 	vmulsd 0x4c85(%rip),%xmm0,%xmm0        # 60e0 <__PRETTY_FUNCTION__.0+0xa0>
    145a:	00 
    145b:	e8 c0 07 00 00       	call   1c20 <flush_cache>
    1460:	4c 89 f6             	mov    %r14,%rsi
    1463:	bf 01 00 00 00       	mov    $0x1,%edi
    1468:	e8 43 fd ff ff       	call   11b0 <clock_gettime@plt>
    146d:	c5 fa 7e 54 24 40    	vmovq  0x40(%rsp),%xmm2
    1473:	c5 f9 6f 5c 24 20    	vmovdqa 0x20(%rsp),%xmm3
    1479:	8b 44 24 18          	mov    0x18(%rsp),%eax
    147d:	c5 f9 6f 4c 24 30    	vmovdqa 0x30(%rsp),%xmm1
    1483:	31 c9                	xor    %ecx,%ecx
    1485:	31 d2                	xor    %edx,%edx
    1487:	4c 89 f6             	mov    %r14,%rsi
    148a:	48 8d 3d 2f 1d 00 00 	lea    0x1d2f(%rip),%rdi        # 31c0 <dmatrix_vector_multiply_mt_rev_avx512_fma_seq_ALL._omp_fn.0>
    1491:	89 44 24 78          	mov    %eax,0x78(%rsp)
    1495:	c5 f9 d6 54 24 70    	vmovq  %xmm2,0x70(%rsp)
    149b:	c5 f9 7f 5c 24 50    	vmovdqa %xmm3,0x50(%rsp)
    14a1:	c5 f9 7f 4c 24 60    	vmovdqa %xmm1,0x60(%rsp)
    14a7:	e8 84 fd ff ff       	call   1230 <GOMP_parallel@plt>
    14ac:	4c 89 f6             	mov    %r14,%rsi
    14af:	bf 01 00 00 00       	mov    $0x1,%edi
    14b4:	e8 f7 fc ff ff       	call   11b0 <clock_gettime@plt>
    14b9:	48 8d 34 dd ff ff 1f 	lea    0x1fffff(,%rbx,8),%rsi
    14c0:	00 
    14c1:	4c 89 ef             	mov    %r13,%rdi
    14c4:	48 81 e6 00 00 e0 ff 	and    $0xffffffffffe00000,%rsi
    14cb:	e8 a0 fd ff ff       	call   1270 <munmap@plt>
    14d0:	48 63 44 24 10       	movslq 0x10(%rsp),%rax
    14d5:	48 8b 7c 24 08       	mov    0x8(%rsp),%rdi
    14da:	48 0f af e8          	imul   %rax,%rbp
    14de:	48 8d 34 ed ff ff 1f 	lea    0x1fffff(,%rbp,8),%rsi
    14e5:	00 
    14e6:	48 81 e6 00 00 e0 ff 	and    $0xffffffffffe00000,%rsi
    14ed:	e8 7e fd ff ff       	call   1270 <munmap@plt>
    14f2:	48 8b 84 24 88 00 00 	mov    0x88(%rsp),%rax
    14f9:	00 
    14fa:	64 48 2b 04 25 28 00 	sub    %fs:0x28,%rax
    1501:	00 00 
    1503:	75 14                	jne    1519 <main+0x259>
    1505:	48 81 c4 98 00 00 00 	add    $0x98,%rsp
    150c:	31 c0                	xor    %eax,%eax
    150e:	5b                   	pop    %rbx
    150f:	5d                   	pop    %rbp
    1510:	41 5c                	pop    %r12
    1512:	41 5d                	pop    %r13
    1514:	41 5e                	pop    %r14
    1516:	41 5f                	pop    %r15
    1518:	c3                   	ret    
    1519:	e8 42 fd ff ff       	call   1260 <__stack_chk_fail@plt>
    151e:	66 90                	xchg   %ax,%ax

0000000000001520 <_start>:
    1520:	f3 0f 1e fa          	endbr64 
    1524:	31 ed                	xor    %ebp,%ebp
    1526:	49 89 d1             	mov    %rdx,%r9
    1529:	5e                   	pop    %rsi
    152a:	48 89 e2             	mov    %rsp,%rdx
    152d:	48 83 e4 f0          	and    $0xfffffffffffffff0,%rsp
    1531:	50                   	push   %rax
    1532:	54                   	push   %rsp
    1533:	45 31 c0             	xor    %r8d,%r8d
    1536:	31 c9                	xor    %ecx,%ecx
    1538:	48 8d 3d 81 fd ff ff 	lea    -0x27f(%rip),%rdi        # 12c0 <main>
    153f:	ff 15 b3 6a 00 00    	call   *0x6ab3(%rip)        # 7ff8 <__libc_start_main@GLIBC_2.34>
    1545:	f4                   	hlt    
    1546:	66 2e 0f 1f 84 00 00 	cs nopw 0x0(%rax,%rax,1)
    154d:	00 00 00 

0000000000001550 <deregister_tm_clones>:
    1550:	48 8d 3d b9 6a 00 00 	lea    0x6ab9(%rip),%rdi        # 8010 <__TMC_END__>
    1557:	48 8d 05 b2 6a 00 00 	lea    0x6ab2(%rip),%rax        # 8010 <__TMC_END__>
    155e:	48 39 f8             	cmp    %rdi,%rax
    1561:	74 15                	je     1578 <deregister_tm_clones+0x28>
    1563:	48 8b 05 76 6a 00 00 	mov    0x6a76(%rip),%rax        # 7fe0 <_ITM_deregisterTMCloneTable@Base>
    156a:	48 85 c0             	test   %rax,%rax
    156d:	74 09                	je     1578 <deregister_tm_clones+0x28>
    156f:	ff e0                	jmp    *%rax
    1571:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)
    1578:	c3                   	ret    
    1579:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)

0000000000001580 <register_tm_clones>:
    1580:	48 8d 3d 89 6a 00 00 	lea    0x6a89(%rip),%rdi        # 8010 <__TMC_END__>
    1587:	48 8d 35 82 6a 00 00 	lea    0x6a82(%rip),%rsi        # 8010 <__TMC_END__>
    158e:	48 29 fe             	sub    %rdi,%rsi
    1591:	48 89 f0             	mov    %rsi,%rax
    1594:	48 c1 ee 3f          	shr    $0x3f,%rsi
    1598:	48 c1 f8 03          	sar    $0x3,%rax
    159c:	48 01 c6             	add    %rax,%rsi
    159f:	48 d1 fe             	sar    %rsi
    15a2:	74 14                	je     15b8 <register_tm_clones+0x38>
    15a4:	48 8b 05 3d 6a 00 00 	mov    0x6a3d(%rip),%rax        # 7fe8 <_ITM_registerTMCloneTable@Base>
    15ab:	48 85 c0             	test   %rax,%rax
    15ae:	74 08                	je     15b8 <register_tm_clones+0x38>
    15b0:	ff e0                	jmp    *%rax
    15b2:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)
    15b8:	c3                   	ret    
    15b9:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)

00000000000015c0 <__do_global_dtors_aux>:
    15c0:	f3 0f 1e fa          	endbr64 
    15c4:	80 3d 45 6a 00 00 00 	cmpb   $0x0,0x6a45(%rip)        # 8010 <__TMC_END__>
    15cb:	75 2b                	jne    15f8 <__do_global_dtors_aux+0x38>
    15cd:	55                   	push   %rbp
    15ce:	48 83 3d 1a 6a 00 00 	cmpq   $0x0,0x6a1a(%rip)        # 7ff0 <__cxa_finalize@GLIBC_2.2.5>
    15d5:	00 
    15d6:	48 89 e5             	mov    %rsp,%rbp
    15d9:	74 0c                	je     15e7 <__do_global_dtors_aux+0x27>
    15db:	48 8b 3d 26 6a 00 00 	mov    0x6a26(%rip),%rdi        # 8008 <__dso_handle>
    15e2:	e8 89 fb ff ff       	call   1170 <__cxa_finalize@plt>
    15e7:	e8 64 ff ff ff       	call   1550 <deregister_tm_clones>
    15ec:	c6 05 1d 6a 00 00 01 	movb   $0x1,0x6a1d(%rip)        # 8010 <__TMC_END__>
    15f3:	5d                   	pop    %rbp
    15f4:	c3                   	ret    
    15f5:	0f 1f 00             	nopl   (%rax)
    15f8:	c3                   	ret    
    15f9:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)

0000000000001600 <frame_dummy>:
    1600:	f3 0f 1e fa          	endbr64 
    1604:	e9 77 ff ff ff       	jmp    1580 <register_tm_clones>
    1609:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)

0000000000001610 <flush_cache._omp_fn.1>:
    1610:	f3 0f 1e fa          	endbr64 
    1614:	55                   	push   %rbp
    1615:	48 89 e5             	mov    %rsp,%rbp
    1618:	41 54                	push   %r12
    161a:	53                   	push   %rbx
    161b:	49 89 fc             	mov    %rdi,%r12
    161e:	48 83 e4 c0          	and    $0xffffffffffffffc0,%rsp
    1622:	e8 69 fb ff ff       	call   1190 <omp_get_num_threads@plt>
    1627:	89 c3                	mov    %eax,%ebx
    1629:	e8 d2 fb ff ff       	call   1200 <omp_get_thread_num@plt>
    162e:	89 c6                	mov    %eax,%esi
    1630:	41 8b 44 24 08       	mov    0x8(%r12),%eax
    1635:	99                   	cltd   
    1636:	f7 fb                	idiv   %ebx
    1638:	39 d6                	cmp    %edx,%esi
    163a:	0f 8c 50 01 00 00    	jl     1790 <flush_cache._omp_fn.1+0x180>
    1640:	0f af f0             	imul   %eax,%esi
    1643:	44 8d 0c 32          	lea    (%rdx,%rsi,1),%r9d
    1647:	46 8d 04 08          	lea    (%rax,%r9,1),%r8d
    164b:	45 39 c1             	cmp    %r8d,%r9d
    164e:	0f 8d 17 01 00 00    	jge    176b <flush_cache._omp_fn.1+0x15b>
    1654:	8d 48 ff             	lea    -0x1(%rax),%ecx
    1657:	4d 8b 14 24          	mov    (%r12),%r10
    165b:	83 f9 06             	cmp    $0x6,%ecx
    165e:	0f 86 3c 01 00 00    	jbe    17a0 <flush_cache._omp_fn.1+0x190>
    1664:	48 63 fe             	movslq %esi,%rdi
    1667:	48 63 ca             	movslq %edx,%rcx
    166a:	62 f2 fd 48 19 15 4c 	vbroadcastsd 0x4a4c(%rip),%zmm2        # 60c0 <__PRETTY_FUNCTION__.0+0x80>
    1671:	4a 00 00 
    1674:	62 f2 fd 48 19 0d 4a 	vbroadcastsd 0x4a4a(%rip),%zmm1        # 60c8 <__PRETTY_FUNCTION__.0+0x88>
    167b:	4a 00 00 
    167e:	48 01 f9             	add    %rdi,%rcx
    1681:	89 c7                	mov    %eax,%edi
    1683:	c1 ef 03             	shr    $0x3,%edi
    1686:	48 c1 e7 06          	shl    $0x6,%rdi
    168a:	49 8d 0c ca          	lea    (%r10,%rcx,8),%rcx
    168e:	48 01 cf             	add    %rcx,%rdi
    1691:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    1698:	00 00 00 00 
    169c:	0f 1f 40 00          	nopl   0x0(%rax)
    16a0:	62 f1 fd 48 28 c2    	vmovapd %zmm2,%zmm0
    16a6:	48 83 c1 40          	add    $0x40,%rcx
    16aa:	62 f2 f5 48 98 41 ff 	vfmadd132pd -0x40(%rcx),%zmm1,%zmm0
    16b1:	62 f1 fd 48 11 41 ff 	vmovupd %zmm0,-0x40(%rcx)
    16b8:	48 39 f9             	cmp    %rdi,%rcx
    16bb:	75 e3                	jne    16a0 <flush_cache._omp_fn.1+0x90>
    16bd:	89 c1                	mov    %eax,%ecx
    16bf:	83 e1 f8             	and    $0xfffffff8,%ecx
    16c2:	41 01 c9             	add    %ecx,%r9d
    16c5:	39 c8                	cmp    %ecx,%eax
    16c7:	0f 84 b3 00 00 00    	je     1780 <flush_cache._omp_fn.1+0x170>
    16cd:	29 c8                	sub    %ecx,%eax
    16cf:	8d 78 ff             	lea    -0x1(%rax),%edi
    16d2:	83 ff 02             	cmp    $0x2,%edi
    16d5:	76 37                	jbe    170e <flush_cache._omp_fn.1+0xfe>
    16d7:	48 63 d2             	movslq %edx,%rdx
    16da:	48 63 f6             	movslq %esi,%rsi
    16dd:	c4 e2 7d 19 1d e2 49 	vbroadcastsd 0x49e2(%rip),%ymm3        # 60c8 <__PRETTY_FUNCTION__.0+0x88>
    16e4:	00 00 
    16e6:	48 01 f2             	add    %rsi,%rdx
    16e9:	48 01 ca             	add    %rcx,%rdx
    16ec:	49 8d 14 d2          	lea    (%r10,%rdx,8),%rdx
    16f0:	c5 fd 10 02          	vmovupd (%rdx),%ymm0
    16f4:	62 f2 e5 38 98 05 c2 	vfmadd132pd 0x49c2(%rip){1to4},%ymm3,%ymm0        # 60c0 <__PRETTY_FUNCTION__.0+0x80>
    16fb:	49 00 00 
    16fe:	c5 fd 11 02          	vmovupd %ymm0,(%rdx)
    1702:	89 c2                	mov    %eax,%edx
    1704:	83 e2 fc             	and    $0xfffffffc,%edx
    1707:	41 01 d1             	add    %edx,%r9d
    170a:	a8 03                	test   $0x3,%al
    170c:	74 72                	je     1780 <flush_cache._omp_fn.1+0x170>
    170e:	49 63 d1             	movslq %r9d,%rdx
    1711:	c5 fb 10 05 a7 49 00 	vmovsd 0x49a7(%rip),%xmm0        # 60c0 <__PRETTY_FUNCTION__.0+0x80>
    1718:	00 
    1719:	c5 fb 10 0d a7 49 00 	vmovsd 0x49a7(%rip),%xmm1        # 60c8 <__PRETTY_FUNCTION__.0+0x88>
    1720:	00 
    1721:	c5 fb 10 d0          	vmovsd %xmm0,%xmm0,%xmm2
    1725:	48 c1 e2 03          	shl    $0x3,%rdx
    1729:	49 8d 04 12          	lea    (%r10,%rdx,1),%rax
    172d:	c4 e2 f1 99 10       	vfmadd132sd (%rax),%xmm1,%xmm2
    1732:	c5 fb 11 10          	vmovsd %xmm2,(%rax)
    1736:	41 8d 41 01          	lea    0x1(%r9),%eax
    173a:	41 39 c0             	cmp    %eax,%r8d
    173d:	7e 41                	jle    1780 <flush_cache._omp_fn.1+0x170>
    173f:	49 8d 44 12 08       	lea    0x8(%r10,%rdx,1),%rax
    1744:	c5 fb 10 d0          	vmovsd %xmm0,%xmm0,%xmm2
    1748:	c4 e2 f1 99 10       	vfmadd132sd (%rax),%xmm1,%xmm2
    174d:	c5 fb 11 10          	vmovsd %xmm2,(%rax)
    1751:	41 8d 41 02          	lea    0x2(%r9),%eax
    1755:	41 39 c0             	cmp    %eax,%r8d
    1758:	7e 26                	jle    1780 <flush_cache._omp_fn.1+0x170>
    175a:	49 8d 44 12 10       	lea    0x10(%r10,%rdx,1),%rax
    175f:	c4 e2 f1 99 00       	vfmadd132sd (%rax),%xmm1,%xmm0
    1764:	c5 fb 11 00          	vmovsd %xmm0,(%rax)
    1768:	c5 f8 77             	vzeroupper 
    176b:	48 8d 65 f0          	lea    -0x10(%rbp),%rsp
    176f:	5b                   	pop    %rbx
    1770:	41 5c                	pop    %r12
    1772:	5d                   	pop    %rbp
    1773:	c3                   	ret    
    1774:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    177b:	00 00 00 00 
    177f:	90                   	nop
    1780:	c5 f8 77             	vzeroupper 
    1783:	48 8d 65 f0          	lea    -0x10(%rbp),%rsp
    1787:	5b                   	pop    %rbx
    1788:	41 5c                	pop    %r12
    178a:	5d                   	pop    %rbp
    178b:	c3                   	ret    
    178c:	0f 1f 40 00          	nopl   0x0(%rax)
    1790:	ff c0                	inc    %eax
    1792:	31 d2                	xor    %edx,%edx
    1794:	e9 a7 fe ff ff       	jmp    1640 <flush_cache._omp_fn.1+0x30>
    1799:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)
    17a0:	31 c9                	xor    %ecx,%ecx
    17a2:	e9 26 ff ff ff       	jmp    16cd <flush_cache._omp_fn.1+0xbd>
    17a7:	66 0f 1f 84 00 00 00 	nopw   0x0(%rax,%rax,1)
    17ae:	00 00 

00000000000017b0 <flush_cache._omp_fn.0>:
    17b0:	f3 0f 1e fa          	endbr64 
    17b4:	55                   	push   %rbp
    17b5:	48 89 e5             	mov    %rsp,%rbp
    17b8:	41 54                	push   %r12
    17ba:	53                   	push   %rbx
    17bb:	48 89 fb             	mov    %rdi,%rbx
    17be:	48 83 e4 c0          	and    $0xffffffffffffffc0,%rsp
    17c2:	e8 c9 f9 ff ff       	call   1190 <omp_get_num_threads@plt>
    17c7:	41 89 c4             	mov    %eax,%r12d
    17ca:	e8 31 fa ff ff       	call   1200 <omp_get_thread_num@plt>
    17cf:	41 89 c0             	mov    %eax,%r8d
    17d2:	8b 43 10             	mov    0x10(%rbx),%eax
    17d5:	99                   	cltd   
    17d6:	41 f7 fc             	idiv   %r12d
    17d9:	41 39 d0             	cmp    %edx,%r8d
    17dc:	0f 8c de 01 00 00    	jl     19c0 <flush_cache._omp_fn.0+0x210>
    17e2:	44 0f af c0          	imul   %eax,%r8d
    17e6:	42 8d 34 02          	lea    (%rdx,%r8,1),%esi
    17ea:	44 8d 0c 30          	lea    (%rax,%rsi,1),%r9d
    17ee:	44 39 ce             	cmp    %r9d,%esi
    17f1:	0f 8d af 01 00 00    	jge    19a6 <flush_cache._omp_fn.0+0x1f6>
    17f7:	8d 48 ff             	lea    -0x1(%rax),%ecx
    17fa:	4c 8b 5b 08          	mov    0x8(%rbx),%r11
    17fe:	c5 fb 10 2b          	vmovsd (%rbx),%xmm5
    1802:	83 f9 0e             	cmp    $0xe,%ecx
    1805:	0f 86 c5 01 00 00    	jbe    19d0 <flush_cache._omp_fn.0+0x220>
    180b:	49 63 f8             	movslq %r8d,%rdi
    180e:	62 f2 7d 48 7c d6    	vpbroadcastd %esi,%zmm2
    1814:	48 63 ca             	movslq %edx,%rcx
    1817:	62 f1 6d 48 fe 15 5f 	vpaddd 0x485f(%rip),%zmm2,%zmm2        # 6080 <__PRETTY_FUNCTION__.0+0x40>
    181e:	48 00 00 
    1821:	48 01 f9             	add    %rdi,%rcx
    1824:	89 c7                	mov    %eax,%edi
    1826:	41 ba 10 00 00 00    	mov    $0x10,%r10d
    182c:	62 f2 fd 48 19 dd    	vbroadcastsd %xmm5,%zmm3
    1832:	c1 ef 04             	shr    $0x4,%edi
    1835:	62 d2 7d 48 7c e2    	vpbroadcastd %r10d,%zmm4
    183b:	48 c1 e7 07          	shl    $0x7,%rdi
    183f:	49 8d 0c cb          	lea    (%r11,%rcx,8),%rcx
    1843:	48 01 cf             	add    %rcx,%rdi
    1846:	66 2e 0f 1f 84 00 00 	cs nopw 0x0(%rax,%rax,1)
    184d:	00 00 00 
    1850:	62 f1 7d 48 6f c2    	vmovdqa32 %zmm2,%zmm0
    1856:	48 83 e9 80          	sub    $0xffffffffffffff80,%rcx
    185a:	62 f1 6d 48 fe d4    	vpaddd %zmm4,%zmm2,%zmm2
    1860:	62 f1 7e 48 e6 c8    	vcvtdq2pd %ymm0,%zmm1
    1866:	62 f3 7d 48 3b c0 01 	vextracti32x8 $0x1,%zmm0,%ymm0
    186d:	62 f1 7e 48 e6 c0    	vcvtdq2pd %ymm0,%zmm0
    1873:	62 f1 f5 48 59 cb    	vmulpd %zmm3,%zmm1,%zmm1
    1879:	62 f1 fd 48 59 c3    	vmulpd %zmm3,%zmm0,%zmm0
    187f:	62 f1 fd 48 11 49 fe 	vmovupd %zmm1,-0x80(%rcx)
    1886:	62 f1 fd 48 11 41 ff 	vmovupd %zmm0,-0x40(%rcx)
    188d:	48 39 f9             	cmp    %rdi,%rcx
    1890:	75 be                	jne    1850 <flush_cache._omp_fn.0+0xa0>
    1892:	89 c1                	mov    %eax,%ecx
    1894:	83 e1 f0             	and    $0xfffffff0,%ecx
    1897:	01 ce                	add    %ecx,%esi
    1899:	39 c8                	cmp    %ecx,%eax
    189b:	0f 84 0f 01 00 00    	je     19b0 <flush_cache._omp_fn.0+0x200>
    18a1:	29 c8                	sub    %ecx,%eax
    18a3:	8d 78 ff             	lea    -0x1(%rax),%edi
    18a6:	83 ff 06             	cmp    $0x6,%edi
    18a9:	76 51                	jbe    18fc <flush_cache._omp_fn.0+0x14c>
    18ab:	62 f2 7d 28 7c c6    	vpbroadcastd %esi,%ymm0
    18b1:	c5 fd fe 05 c7 47 00 	vpaddd 0x47c7(%rip),%ymm0,%ymm0        # 6080 <__PRETTY_FUNCTION__.0+0x40>
    18b8:	00 
    18b9:	c4 e2 7d 19 cd       	vbroadcastsd %xmm5,%ymm1
    18be:	48 63 d2             	movslq %edx,%rdx
    18c1:	4d 63 c0             	movslq %r8d,%r8
    18c4:	4c 01 c2             	add    %r8,%rdx
    18c7:	48 01 ca             	add    %rcx,%rdx
    18ca:	49 8d 14 d3          	lea    (%r11,%rdx,8),%rdx
    18ce:	c5 fe e6 d0          	vcvtdq2pd %xmm0,%ymm2
    18d2:	c4 e3 7d 39 c0 01    	vextracti128 $0x1,%ymm0,%xmm0
    18d8:	c5 fe e6 c0          	vcvtdq2pd %xmm0,%ymm0
    18dc:	c5 ed 59 d1          	vmulpd %ymm1,%ymm2,%ymm2
    18e0:	c5 fd 59 c1          	vmulpd %ymm1,%ymm0,%ymm0
    18e4:	c5 fd 11 12          	vmovupd %ymm2,(%rdx)
    18e8:	c5 fd 11 42 20       	vmovupd %ymm0,0x20(%rdx)
    18ed:	89 c2                	mov    %eax,%edx
    18ef:	83 e2 f8             	and    $0xfffffff8,%edx
    18f2:	01 d6                	add    %edx,%esi
    18f4:	a8 07                	test   $0x7,%al
    18f6:	0f 84 b4 00 00 00    	je     19b0 <flush_cache._omp_fn.0+0x200>
    18fc:	48 63 c6             	movslq %esi,%rax
    18ff:	8d 56 01             	lea    0x1(%rsi),%edx
    1902:	c5 f8 57 c0          	vxorps %xmm0,%xmm0,%xmm0
    1906:	c5 fb 2a ce          	vcvtsi2sd %esi,%xmm0,%xmm1
    190a:	48 c1 e0 03          	shl    $0x3,%rax
    190e:	c5 f3 59 cd          	vmulsd %xmm5,%xmm1,%xmm1
    1912:	c4 c1 7b 11 0c 03    	vmovsd %xmm1,(%r11,%rax,1)
    1918:	41 39 d1             	cmp    %edx,%r9d
    191b:	0f 8e 8f 00 00 00    	jle    19b0 <flush_cache._omp_fn.0+0x200>
    1921:	c5 fb 2a ca          	vcvtsi2sd %edx,%xmm0,%xmm1
    1925:	8d 56 02             	lea    0x2(%rsi),%edx
    1928:	c5 f3 59 cd          	vmulsd %xmm5,%xmm1,%xmm1
    192c:	c4 c1 7b 11 4c 03 08 	vmovsd %xmm1,0x8(%r11,%rax,1)
    1933:	41 39 d1             	cmp    %edx,%r9d
    1936:	7e 78                	jle    19b0 <flush_cache._omp_fn.0+0x200>
    1938:	c5 fb 2a ca          	vcvtsi2sd %edx,%xmm0,%xmm1
    193c:	8d 56 03             	lea    0x3(%rsi),%edx
    193f:	c5 f3 59 cd          	vmulsd %xmm5,%xmm1,%xmm1
    1943:	c4 c1 7b 11 4c 03 10 	vmovsd %xmm1,0x10(%r11,%rax,1)
    194a:	41 39 d1             	cmp    %edx,%r9d
    194d:	7e 61                	jle    19b0 <flush_cache._omp_fn.0+0x200>
    194f:	c5 fb 2a ca          	vcvtsi2sd %edx,%xmm0,%xmm1
    1953:	8d 56 04             	lea    0x4(%rsi),%edx
    1956:	c5 f3 59 cd          	vmulsd %xmm5,%xmm1,%xmm1
    195a:	c4 c1 7b 11 4c 03 18 	vmovsd %xmm1,0x18(%r11,%rax,1)
    1961:	41 39 d1             	cmp    %edx,%r9d
    1964:	7e 4a                	jle    19b0 <flush_cache._omp_fn.0+0x200>
    1966:	c5 fb 2a ca          	vcvtsi2sd %edx,%xmm0,%xmm1
    196a:	8d 56 05             	lea    0x5(%rsi),%edx
    196d:	c5 f3 59 cd          	vmulsd %xmm5,%xmm1,%xmm1
    1971:	c4 c1 7b 11 4c 03 20 	vmovsd %xmm1,0x20(%r11,%rax,1)
    1978:	41 39 d1             	cmp    %edx,%r9d
    197b:	7e 33                	jle    19b0 <flush_cache._omp_fn.0+0x200>
    197d:	83 c6 06             	add    $0x6,%esi
    1980:	c5 fb 2a ca          	vcvtsi2sd %edx,%xmm0,%xmm1
    1984:	c5 f3 59 cd          	vmulsd %xmm5,%xmm1,%xmm1
    1988:	c4 c1 7b 11 4c 03 28 	vmovsd %xmm1,0x28(%r11,%rax,1)
    198f:	41 39 f1             	cmp    %esi,%r9d
    1992:	7e 1c                	jle    19b0 <flush_cache._omp_fn.0+0x200>
    1994:	c5 fb 2a c6          	vcvtsi2sd %esi,%xmm0,%xmm0
    1998:	c5 fb 59 c5          	vmulsd %xmm5,%xmm0,%xmm0
    199c:	c4 c1 7b 11 44 03 30 	vmovsd %xmm0,0x30(%r11,%rax,1)
    19a3:	c5 f8 77             	vzeroupper 
    19a6:	48 8d 65 f0          	lea    -0x10(%rbp),%rsp
    19aa:	5b                   	pop    %rbx
    19ab:	41 5c                	pop    %r12
    19ad:	5d                   	pop    %rbp
    19ae:	c3                   	ret    
    19af:	90                   	nop
    19b0:	c5 f8 77             	vzeroupper 
    19b3:	48 8d 65 f0          	lea    -0x10(%rbp),%rsp
    19b7:	5b                   	pop    %rbx
    19b8:	41 5c                	pop    %r12
    19ba:	5d                   	pop    %rbp
    19bb:	c3                   	ret    
    19bc:	0f 1f 40 00          	nopl   0x0(%rax)
    19c0:	ff c0                	inc    %eax
    19c2:	31 d2                	xor    %edx,%edx
    19c4:	e9 19 fe ff ff       	jmp    17e2 <flush_cache._omp_fn.0+0x32>
    19c9:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)
    19d0:	31 c9                	xor    %ecx,%ecx
    19d2:	e9 ca fe ff ff       	jmp    18a1 <flush_cache._omp_fn.0+0xf1>
    19d7:	66 0f 1f 84 00 00 00 	nopw   0x0(%rax,%rax,1)
    19de:	00 00 

00000000000019e0 <flush_cache._omp_fn.2>:
    19e0:	f3 0f 1e fa          	endbr64 
    19e4:	41 54                	push   %r12
    19e6:	55                   	push   %rbp
    19e7:	53                   	push   %rbx
    19e8:	48 89 fb             	mov    %rdi,%rbx
    19eb:	48 8b 2f             	mov    (%rdi),%rbp
    19ee:	e8 9d f7 ff ff       	call   1190 <omp_get_num_threads@plt>
    19f3:	41 89 c4             	mov    %eax,%r12d
    19f6:	e8 05 f8 ff ff       	call   1200 <omp_get_thread_num@plt>
    19fb:	89 c1                	mov    %eax,%ecx
    19fd:	8b 43 10             	mov    0x10(%rbx),%eax
    1a00:	99                   	cltd   
    1a01:	41 f7 fc             	idiv   %r12d
    1a04:	39 d1                	cmp    %edx,%ecx
    1a06:	0f 8c 04 01 00 00    	jl     1b10 <flush_cache._omp_fn.2+0x130>
    1a0c:	0f af c8             	imul   %eax,%ecx
    1a0f:	c5 f9 57 c0          	vxorpd %xmm0,%xmm0,%xmm0
    1a13:	8d 34 0a             	lea    (%rdx,%rcx,1),%esi
    1a16:	8d 3c 30             	lea    (%rax,%rsi,1),%edi
    1a19:	39 fe                	cmp    %edi,%esi
    1a1b:	0f 8d c9 00 00 00    	jge    1aea <flush_cache._omp_fn.2+0x10a>
    1a21:	44 8d 40 ff          	lea    -0x1(%rax),%r8d
    1a25:	41 83 f8 06          	cmp    $0x6,%r8d
    1a29:	76 60                	jbe    1a8b <flush_cache._omp_fn.2+0xab>
    1a2b:	48 63 c9             	movslq %ecx,%rcx
    1a2e:	48 63 d2             	movslq %edx,%rdx
    1a31:	48 01 ca             	add    %rcx,%rdx
    1a34:	89 c1                	mov    %eax,%ecx
    1a36:	c1 e9 03             	shr    $0x3,%ecx
    1a39:	48 c1 e1 06          	shl    $0x6,%rcx
    1a3d:	48 8d 54 d5 00       	lea    0x0(%rbp,%rdx,8),%rdx
    1a42:	48 01 d1             	add    %rdx,%rcx
    1a45:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    1a4c:	00 00 00 00 
    1a50:	c5 fb 58 02          	vaddsd (%rdx),%xmm0,%xmm0
    1a54:	48 83 c2 40          	add    $0x40,%rdx
    1a58:	c5 fb 58 42 c8       	vaddsd -0x38(%rdx),%xmm0,%xmm0
    1a5d:	c5 fb 58 42 d0       	vaddsd -0x30(%rdx),%xmm0,%xmm0
    1a62:	c5 fb 58 42 d8       	vaddsd -0x28(%rdx),%xmm0,%xmm0
    1a67:	c5 fb 58 42 e0       	vaddsd -0x20(%rdx),%xmm0,%xmm0
    1a6c:	c5 fb 58 42 e8       	vaddsd -0x18(%rdx),%xmm0,%xmm0
    1a71:	c5 fb 58 42 f0       	vaddsd -0x10(%rdx),%xmm0,%xmm0
    1a76:	c5 fb 58 42 f8       	vaddsd -0x8(%rdx),%xmm0,%xmm0
    1a7b:	48 39 d1             	cmp    %rdx,%rcx
    1a7e:	75 d0                	jne    1a50 <flush_cache._omp_fn.2+0x70>
    1a80:	89 c2                	mov    %eax,%edx
    1a82:	83 e2 f8             	and    $0xfffffff8,%edx
    1a85:	01 d6                	add    %edx,%esi
    1a87:	39 d0                	cmp    %edx,%eax
    1a89:	74 5f                	je     1aea <flush_cache._omp_fn.2+0x10a>
    1a8b:	48 63 d6             	movslq %esi,%rdx
    1a8e:	48 8d 04 d5 00 00 00 	lea    0x0(,%rdx,8),%rax
    1a95:	00 
    1a96:	c5 fb 58 44 d5 00    	vaddsd 0x0(%rbp,%rdx,8),%xmm0,%xmm0
    1a9c:	8d 56 01             	lea    0x1(%rsi),%edx
    1a9f:	39 d7                	cmp    %edx,%edi
    1aa1:	7e 47                	jle    1aea <flush_cache._omp_fn.2+0x10a>
    1aa3:	8d 56 02             	lea    0x2(%rsi),%edx
    1aa6:	c5 fb 58 44 05 08    	vaddsd 0x8(%rbp,%rax,1),%xmm0,%xmm0
    1aac:	39 d7                	cmp    %edx,%edi
    1aae:	7e 3a                	jle    1aea <flush_cache._omp_fn.2+0x10a>
    1ab0:	8d 56 03             	lea    0x3(%rsi),%edx
    1ab3:	c5 fb 58 44 05 10    	vaddsd 0x10(%rbp,%rax,1),%xmm0,%xmm0
    1ab9:	39 d7                	cmp    %edx,%edi
    1abb:	7e 2d                	jle    1aea <flush_cache._omp_fn.2+0x10a>
    1abd:	8d 56 04             	lea    0x4(%rsi),%edx
    1ac0:	c5 fb 58 44 05 18    	vaddsd 0x18(%rbp,%rax,1),%xmm0,%xmm0
    1ac6:	39 d7                	cmp    %edx,%edi
    1ac8:	7e 20                	jle    1aea <flush_cache._omp_fn.2+0x10a>
    1aca:	8d 56 05             	lea    0x5(%rsi),%edx
    1acd:	c5 fb 58 44 05 20    	vaddsd 0x20(%rbp,%rax,1),%xmm0,%xmm0
    1ad3:	39 d7                	cmp    %edx,%edi
    1ad5:	7e 13                	jle    1aea <flush_cache._omp_fn.2+0x10a>
    1ad7:	83 c6 06             	add    $0x6,%esi
    1ada:	c5 fb 58 44 05 28    	vaddsd 0x28(%rbp,%rax,1),%xmm0,%xmm0
    1ae0:	39 f7                	cmp    %esi,%edi
    1ae2:	7e 06                	jle    1aea <flush_cache._omp_fn.2+0x10a>
    1ae4:	c5 fb 58 44 05 30    	vaddsd 0x30(%rbp,%rax,1),%xmm0,%xmm0
    1aea:	48 8b 53 08          	mov    0x8(%rbx),%rdx
    1aee:	48 8d 4b 08          	lea    0x8(%rbx),%rcx
    1af2:	c4 e1 f9 6e d2       	vmovq  %rdx,%xmm2
    1af7:	48 89 d0             	mov    %rdx,%rax
    1afa:	c5 fb 58 ca          	vaddsd %xmm2,%xmm0,%xmm1
    1afe:	c4 e1 f9 7e ce       	vmovq  %xmm1,%rsi
    1b03:	f0 48 0f b1 31       	lock cmpxchg %rsi,(%rcx)
    1b08:	75 0f                	jne    1b19 <flush_cache._omp_fn.2+0x139>
    1b0a:	5b                   	pop    %rbx
    1b0b:	5d                   	pop    %rbp
    1b0c:	41 5c                	pop    %r12
    1b0e:	c3                   	ret    
    1b0f:	90                   	nop
    1b10:	ff c0                	inc    %eax
    1b12:	31 d2                	xor    %edx,%edx
    1b14:	e9 f3 fe ff ff       	jmp    1a0c <flush_cache._omp_fn.2+0x2c>
    1b19:	48 89 c2             	mov    %rax,%rdx
    1b1c:	eb d4                	jmp    1af2 <flush_cache._omp_fn.2+0x112>
    1b1e:	66 90                	xchg   %ax,%ax

0000000000001b20 <i64time>:
    1b20:	f3 0f 1e fa          	endbr64 
    1b24:	48 83 ec 28          	sub    $0x28,%rsp
    1b28:	bf 01 00 00 00       	mov    $0x1,%edi
    1b2d:	48 89 e6             	mov    %rsp,%rsi
    1b30:	64 48 8b 04 25 28 00 	mov    %fs:0x28,%rax
    1b37:	00 00 
    1b39:	48 89 44 24 18       	mov    %rax,0x18(%rsp)
    1b3e:	31 c0                	xor    %eax,%eax
    1b40:	e8 6b f6 ff ff       	call   11b0 <clock_gettime@plt>
    1b45:	48 69 04 24 00 ca 9a 	imul   $0x3b9aca00,(%rsp),%rax
    1b4c:	3b 
    1b4d:	48 03 44 24 08       	add    0x8(%rsp),%rax
    1b52:	48 8b 54 24 18       	mov    0x18(%rsp),%rdx
    1b57:	64 48 2b 14 25 28 00 	sub    %fs:0x28,%rdx
    1b5e:	00 00 
    1b60:	75 05                	jne    1b67 <i64time+0x47>
    1b62:	48 83 c4 28          	add    $0x28,%rsp
    1b66:	c3                   	ret    
    1b67:	e8 f4 f6 ff ff       	call   1260 <__stack_chk_fail@plt>
    1b6c:	0f 1f 40 00          	nopl   0x0(%rax)

0000000000001b70 <hugealloc>:
    1b70:	f3 0f 1e fa          	endbr64 
    1b74:	55                   	push   %rbp
    1b75:	53                   	push   %rbx
    1b76:	48 8d 9f ff ff 1f 00 	lea    0x1fffff(%rdi),%rbx
    1b7d:	45 31 c9             	xor    %r9d,%r9d
    1b80:	48 81 e3 00 00 e0 ff 	and    $0xffffffffffe00000,%rbx
    1b87:	48 83 ec 08          	sub    $0x8,%rsp
    1b8b:	41 b8 ff ff ff ff    	mov    $0xffffffff,%r8d
    1b91:	b9 22 00 00 00       	mov    $0x22,%ecx
    1b96:	48 89 de             	mov    %rbx,%rsi
    1b99:	ba 03 00 00 00       	mov    $0x3,%edx
    1b9e:	31 ff                	xor    %edi,%edi
    1ba0:	e8 fb f6 ff ff       	call   12a0 <mmap@plt>
    1ba5:	48 89 de             	mov    %rbx,%rsi
    1ba8:	ba 0e 00 00 00       	mov    $0xe,%edx
    1bad:	48 89 c7             	mov    %rax,%rdi
    1bb0:	48 89 c5             	mov    %rax,%rbp
    1bb3:	e8 88 f6 ff ff       	call   1240 <madvise@plt>
    1bb8:	48 83 c4 08          	add    $0x8,%rsp
    1bbc:	48 89 e8             	mov    %rbp,%rax
    1bbf:	5b                   	pop    %rbx
    1bc0:	5d                   	pop    %rbp
    1bc1:	c3                   	ret    
    1bc2:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    1bc9:	00 00 00 00 
    1bcd:	0f 1f 00             	nopl   (%rax)

0000000000001bd0 <hugefree>:
    1bd0:	f3 0f 1e fa          	endbr64 
    1bd4:	48 81 c6 ff ff 1f 00 	add    $0x1fffff,%rsi
    1bdb:	48 81 e6 00 00 e0 ff 	and    $0xffffffffffe00000,%rsi
    1be2:	e9 89 f6 ff ff       	jmp    1270 <munmap@plt>
    1be7:	66 0f 1f 84 00 00 00 	nopw   0x0(%rax,%rax,1)
    1bee:	00 00 

0000000000001bf0 <freedmatrix>:
    1bf0:	f3 0f 1e fa          	endbr64 
    1bf4:	48 63 c9             	movslq %ecx,%rcx
    1bf7:	48 63 d2             	movslq %edx,%rdx
    1bfa:	48 0f af ca          	imul   %rdx,%rcx
    1bfe:	48 8d 34 cd ff ff 1f 	lea    0x1fffff(,%rcx,8),%rsi
    1c05:	00 
    1c06:	48 81 e6 00 00 e0 ff 	and    $0xffffffffffe00000,%rsi
    1c0d:	e9 5e f6 ff ff       	jmp    1270 <munmap@plt>
    1c12:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    1c19:	00 00 00 00 
    1c1d:	0f 1f 00             	nopl   (%rax)

0000000000001c20 <flush_cache>:
    1c20:	f3 0f 1e fa          	endbr64 
    1c24:	41 55                	push   %r13
    1c26:	41 54                	push   %r12
    1c28:	55                   	push   %rbp
    1c29:	bf 00 68 89 09       	mov    $0x9896800,%edi
    1c2e:	53                   	push   %rbx
    1c2f:	4c 8d 2d da f9 ff ff 	lea    -0x626(%rip),%r13        # 1610 <flush_cache._omp_fn.1>
    1c36:	bb 05 00 00 00       	mov    $0x5,%ebx
    1c3b:	48 83 ec 38          	sub    $0x38,%rsp
    1c3f:	4c 8d 64 24 10       	lea    0x10(%rsp),%r12
    1c44:	c5 fb 11 44 24 08    	vmovsd %xmm0,0x8(%rsp)
    1c4a:	64 48 8b 04 25 28 00 	mov    %fs:0x28,%rax
    1c51:	00 00 
    1c53:	48 89 44 24 28       	mov    %rax,0x28(%rsp)
    1c58:	31 c0                	xor    %eax,%eax
    1c5a:	e8 91 f5 ff ff       	call   11f0 <malloc@plt>
    1c5f:	31 c9                	xor    %ecx,%ecx
    1c61:	31 d2                	xor    %edx,%edx
    1c63:	4c 89 e6             	mov    %r12,%rsi
    1c66:	48 8d 3d 43 fb ff ff 	lea    -0x4bd(%rip),%rdi        # 17b0 <flush_cache._omp_fn.0>
    1c6d:	c5 fb 10 4c 24 08    	vmovsd 0x8(%rsp),%xmm1
    1c73:	48 89 c5             	mov    %rax,%rbp
    1c76:	48 89 44 24 18       	mov    %rax,0x18(%rsp)
    1c7b:	c7 44 24 20 00 2d 31 	movl   $0x1312d00,0x20(%rsp)
    1c82:	01 
    1c83:	c5 fb 11 4c 24 10    	vmovsd %xmm1,0x10(%rsp)
    1c89:	e8 a2 f5 ff ff       	call   1230 <GOMP_parallel@plt>
    1c8e:	66 90                	xchg   %ax,%ax
    1c90:	31 c9                	xor    %ecx,%ecx
    1c92:	31 d2                	xor    %edx,%edx
    1c94:	4c 89 e6             	mov    %r12,%rsi
    1c97:	4c 89 ef             	mov    %r13,%rdi
    1c9a:	48 89 6c 24 10       	mov    %rbp,0x10(%rsp)
    1c9f:	c7 44 24 18 00 2d 31 	movl   $0x1312d00,0x18(%rsp)
    1ca6:	01 
    1ca7:	e8 84 f5 ff ff       	call   1230 <GOMP_parallel@plt>
    1cac:	ff cb                	dec    %ebx
    1cae:	75 e0                	jne    1c90 <flush_cache+0x70>
    1cb0:	31 c9                	xor    %ecx,%ecx
    1cb2:	31 d2                	xor    %edx,%edx
    1cb4:	4c 89 e6             	mov    %r12,%rsi
    1cb7:	48 8d 3d 22 fd ff ff 	lea    -0x2de(%rip),%rdi        # 19e0 <flush_cache._omp_fn.2>
    1cbe:	48 c7 44 24 18 00 00 	movq   $0x0,0x18(%rsp)
    1cc5:	00 00 
    1cc7:	48 89 6c 24 10       	mov    %rbp,0x10(%rsp)
    1ccc:	c7 44 24 20 00 2d 31 	movl   $0x1312d00,0x20(%rsp)
    1cd3:	01 
    1cd4:	e8 57 f5 ff ff       	call   1230 <GOMP_parallel@plt>
    1cd9:	48 89 ef             	mov    %rbp,%rdi
    1cdc:	c5 fb 10 44 24 18    	vmovsd 0x18(%rsp),%xmm0
    1ce2:	c5 fb 11 44 24 08    	vmovsd %xmm0,0x8(%rsp)
    1ce8:	e8 23 f5 ff ff       	call   1210 <free@plt>
    1ced:	c5 fb 10 44 24 08    	vmovsd 0x8(%rsp),%xmm0
    1cf3:	48 8b 44 24 28       	mov    0x28(%rsp),%rax
    1cf8:	64 48 2b 04 25 28 00 	sub    %fs:0x28,%rax
    1cff:	00 00 
    1d01:	75 0b                	jne    1d0e <flush_cache+0xee>
    1d03:	48 83 c4 38          	add    $0x38,%rsp
    1d07:	5b                   	pop    %rbx
    1d08:	5d                   	pop    %rbp
    1d09:	41 5c                	pop    %r12
    1d0b:	41 5d                	pop    %r13
    1d0d:	c3                   	ret    
    1d0e:	e8 4d f5 ff ff       	call   1260 <__stack_chk_fail@plt>
    1d13:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    1d1a:	00 00 00 00 
    1d1e:	66 90                	xchg   %ax,%ax

0000000000001d20 <dmatrix>:
    1d20:	f3 0f 1e fa          	endbr64 
    1d24:	55                   	push   %rbp
    1d25:	53                   	push   %rbx
    1d26:	48 83 ec 08          	sub    $0x8,%rsp
    1d2a:	85 ff                	test   %edi,%edi
    1d2c:	7e 5b                	jle    1d89 <dmatrix+0x69>
    1d2e:	85 f6                	test   %esi,%esi
    1d30:	7e 57                	jle    1d89 <dmatrix+0x69>
    1d32:	39 d7                	cmp    %edx,%edi
    1d34:	7f 72                	jg     1da8 <dmatrix+0x88>
    1d36:	48 63 f6             	movslq %esi,%rsi
    1d39:	48 63 d2             	movslq %edx,%rdx
    1d3c:	45 31 c9             	xor    %r9d,%r9d
    1d3f:	41 b8 ff ff ff ff    	mov    $0xffffffff,%r8d
    1d45:	48 0f af d6          	imul   %rsi,%rdx
    1d49:	b9 22 00 00 00       	mov    $0x22,%ecx
    1d4e:	31 ff                	xor    %edi,%edi
    1d50:	48 8d 2c d5 ff ff 1f 	lea    0x1fffff(,%rdx,8),%rbp
    1d57:	00 
    1d58:	ba 03 00 00 00       	mov    $0x3,%edx
    1d5d:	48 81 e5 00 00 e0 ff 	and    $0xffffffffffe00000,%rbp
    1d64:	48 89 ee             	mov    %rbp,%rsi
    1d67:	e8 34 f5 ff ff       	call   12a0 <mmap@plt>
    1d6c:	48 89 ee             	mov    %rbp,%rsi
    1d6f:	ba 0e 00 00 00       	mov    $0xe,%edx
    1d74:	48 89 c7             	mov    %rax,%rdi
    1d77:	48 89 c3             	mov    %rax,%rbx
    1d7a:	e8 c1 f4 ff ff       	call   1240 <madvise@plt>
    1d7f:	48 83 c4 08          	add    $0x8,%rsp
    1d83:	48 89 d8             	mov    %rbx,%rax
    1d86:	5b                   	pop    %rbx
    1d87:	5d                   	pop    %rbp
    1d88:	c3                   	ret    
    1d89:	48 8d 0d b0 42 00 00 	lea    0x42b0(%rip),%rcx        # 6040 <__PRETTY_FUNCTION__.0>
    1d90:	ba 3e 00 00 00       	mov    $0x3e,%edx
    1d95:	48 8d 35 68 42 00 00 	lea    0x4268(%rip),%rsi        # 6004 <_IO_stdin_used+0x4>
    1d9c:	48 8d 3d 71 42 00 00 	lea    0x4271(%rip),%rdi        # 6014 <_IO_stdin_used+0x14>
    1da3:	e8 18 f4 ff ff       	call   11c0 <__assert_fail@plt>
    1da8:	48 8d 0d 91 42 00 00 	lea    0x4291(%rip),%rcx        # 6040 <__PRETTY_FUNCTION__.0>
    1daf:	ba 3f 00 00 00       	mov    $0x3f,%edx
    1db4:	48 8d 35 49 42 00 00 	lea    0x4249(%rip),%rsi        # 6004 <_IO_stdin_used+0x4>
    1dbb:	48 8d 3d 61 42 00 00 	lea    0x4261(%rip),%rdi        # 6023 <_IO_stdin_used+0x23>
    1dc2:	e8 f9 f3 ff ff       	call   11c0 <__assert_fail@plt>
    1dc7:	66 0f 1f 84 00 00 00 	nopw   0x0(%rax,%rax,1)
    1dce:	00 00 

0000000000001dd0 <drandomM>:
    1dd0:	f3 0f 1e fa          	endbr64 
    1dd4:	85 f6                	test   %esi,%esi
    1dd6:	7e 75                	jle    1e4d <drandomM+0x7d>
    1dd8:	85 ff                	test   %edi,%edi
    1dda:	7e 71                	jle    1e4d <drandomM+0x7d>
    1ddc:	48 63 ff             	movslq %edi,%rdi
    1ddf:	41 57                	push   %r15
    1de1:	48 63 c9             	movslq %ecx,%rcx
    1de4:	41 56                	push   %r14
    1de6:	41 55                	push   %r13
    1de8:	4c 8d 2c fd 00 00 00 	lea    0x0(,%rdi,8),%r13
    1def:	00 
    1df0:	41 54                	push   %r12
    1df2:	55                   	push   %rbp
    1df3:	53                   	push   %rbx
    1df4:	41 89 f7             	mov    %esi,%r15d
    1df7:	4c 8d 34 cd 00 00 00 	lea    0x0(,%rcx,8),%r14
    1dfe:	00 
    1dff:	4a 8d 2c 2a          	lea    (%rdx,%r13,1),%rbp
    1e03:	48 83 ec 08          	sub    $0x8,%rsp
    1e07:	45 31 e4             	xor    %r12d,%r12d
    1e0a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)
    1e10:	48 89 eb             	mov    %rbp,%rbx
    1e13:	4c 29 eb             	sub    %r13,%rbx
    1e16:	66 2e 0f 1f 84 00 00 	cs nopw 0x0(%rax,%rax,1)
    1e1d:	00 00 00 
    1e20:	e8 8b f4 ff ff       	call   12b0 <drand48@plt>
    1e25:	48 83 c3 08          	add    $0x8,%rbx
    1e29:	c5 fb 11 43 f8       	vmovsd %xmm0,-0x8(%rbx)
    1e2e:	48 39 eb             	cmp    %rbp,%rbx
    1e31:	75 ed                	jne    1e20 <drandomM+0x50>
    1e33:	41 ff c4             	inc    %r12d
    1e36:	4c 01 f5             	add    %r14,%rbp
    1e39:	45 39 e7             	cmp    %r12d,%r15d
    1e3c:	75 d2                	jne    1e10 <drandomM+0x40>
    1e3e:	48 83 c4 08          	add    $0x8,%rsp
    1e42:	5b                   	pop    %rbx
    1e43:	5d                   	pop    %rbp
    1e44:	41 5c                	pop    %r12
    1e46:	41 5d                	pop    %r13
    1e48:	41 5e                	pop    %r14
    1e4a:	41 5f                	pop    %r15
    1e4c:	c3                   	ret    
    1e4d:	c3                   	ret    
    1e4e:	66 90                	xchg   %ax,%ax

0000000000001e50 <drandomG>:
    1e50:	f3 0f 1e fa          	endbr64 
    1e54:	41 57                	push   %r15
    1e56:	41 56                	push   %r14
    1e58:	41 55                	push   %r13
    1e5a:	41 54                	push   %r12
    1e5c:	55                   	push   %rbp
    1e5d:	53                   	push   %rbx
    1e5e:	48 83 ec 28          	sub    $0x28,%rsp
    1e62:	89 74 24 04          	mov    %esi,0x4(%rsp)
    1e66:	85 f6                	test   %esi,%esi
    1e68:	0f 8e b2 00 00 00    	jle    1f20 <drandomG+0xd0>
    1e6e:	85 ff                	test   %edi,%edi
    1e70:	0f 8e aa 00 00 00    	jle    1f20 <drandomG+0xd0>
    1e76:	4c 63 f7             	movslq %edi,%r14
    1e79:	48 63 c9             	movslq %ecx,%rcx
    1e7c:	45 31 ed             	xor    %r13d,%r13d
    1e7f:	4c 8d 64 24 18       	lea    0x18(%rsp),%r12
    1e84:	49 c1 e6 04          	shl    $0x4,%r14
    1e88:	48 8d 04 cd 00 00 00 	lea    0x0(,%rcx,8),%rax
    1e8f:	00 
    1e90:	4a 8d 1c 32          	lea    (%rdx,%r14,1),%rbx
    1e94:	48 8d 6c 24 10       	lea    0x10(%rsp),%rbp
    1e99:	48 89 44 24 08       	mov    %rax,0x8(%rsp)
    1e9e:	66 90                	xchg   %ax,%ax
    1ea0:	49 89 df             	mov    %rbx,%r15
    1ea3:	4d 29 f7             	sub    %r14,%r15
    1ea6:	66 2e 0f 1f 84 00 00 	cs nopw 0x0(%rax,%rax,1)
    1ead:	00 00 00 
    1eb0:	e8 cb f3 ff ff       	call   1280 <rand@plt>
    1eb5:	4c 89 e7             	mov    %r12,%rdi
    1eb8:	c5 e9 57 d2          	vxorpd %xmm2,%xmm2,%xmm2
    1ebc:	49 83 c7 10          	add    $0x10,%r15
    1ec0:	89 c1                	mov    %eax,%ecx
    1ec2:	48 98                	cltq   
    1ec4:	48 69 c0 b7 60 0b b6 	imul   $0xffffffffb60b60b7,%rax,%rax
    1ecb:	89 ce                	mov    %ecx,%esi
    1ecd:	c1 fe 1f             	sar    $0x1f,%esi
    1ed0:	48 c1 e8 20          	shr    $0x20,%rax
    1ed4:	01 c8                	add    %ecx,%eax
    1ed6:	c1 f8 08             	sar    $0x8,%eax
    1ed9:	29 f0                	sub    %esi,%eax
    1edb:	48 89 ee             	mov    %rbp,%rsi
    1ede:	69 c0 68 01 00 00    	imul   $0x168,%eax,%eax
    1ee4:	29 c1                	sub    %eax,%ecx
    1ee6:	c5 eb 2a c1          	vcvtsi2sd %ecx,%xmm2,%xmm0
    1eea:	c5 fb 59 05 de 41 00 	vmulsd 0x41de(%rip),%xmm0,%xmm0        # 60d0 <__PRETTY_FUNCTION__.0+0x90>
    1ef1:	00 
    1ef2:	e8 59 f3 ff ff       	call   1250 <sincos@plt>
    1ef7:	c5 fb 10 4c 24 10    	vmovsd 0x10(%rsp),%xmm1
    1efd:	c5 f1 16 44 24 18    	vmovhpd 0x18(%rsp),%xmm1,%xmm0
    1f03:	c4 c1 79 11 47 f0    	vmovupd %xmm0,-0x10(%r15)
    1f09:	4c 39 fb             	cmp    %r15,%rbx
    1f0c:	75 a2                	jne    1eb0 <drandomG+0x60>
    1f0e:	48 8b 44 24 08       	mov    0x8(%rsp),%rax
    1f13:	41 ff c5             	inc    %r13d
    1f16:	48 01 c3             	add    %rax,%rbx
    1f19:	44 39 6c 24 04       	cmp    %r13d,0x4(%rsp)
    1f1e:	75 80                	jne    1ea0 <drandomG+0x50>
    1f20:	48 83 c4 28          	add    $0x28,%rsp
    1f24:	5b                   	pop    %rbx
    1f25:	5d                   	pop    %rbp
    1f26:	41 5c                	pop    %r12
    1f28:	41 5d                	pop    %r13
    1f2a:	41 5e                	pop    %r14
    1f2c:	41 5f                	pop    %r15
    1f2e:	c3                   	ret    
    1f2f:	90                   	nop

0000000000001f30 <applywavemx2_avx>:
    1f30:	f3 0f 1e fa          	endbr64 
    1f34:	55                   	push   %rbp
    1f35:	49 89 f1             	mov    %rsi,%r9
    1f38:	49 89 d0             	mov    %rdx,%r8
    1f3b:	48 89 e5             	mov    %rsp,%rbp
    1f3e:	48 83 e4 e0          	and    $0xffffffffffffffe0,%rsp
    1f42:	c5 fb 11 4c 24 f0    	vmovsd %xmm1,-0x10(%rsp)
    1f48:	c5 fb 11 44 24 f8    	vmovsd %xmm0,-0x8(%rsp)
    1f4e:	c5 fb 10 0d 72 41 00 	vmovsd 0x4172(%rip),%xmm1        # 60c8 <__PRETTY_FUNCTION__.0+0x88>
    1f55:	00 
    1f56:	c5 f9 2e c8          	vucomisd %xmm0,%xmm1
    1f5a:	7a 06                	jp     1f62 <applywavemx2_avx+0x32>
    1f5c:	0f 84 18 01 00 00    	je     207a <applywavemx2_avx+0x14a>
    1f62:	c4 e2 7d 19 54 24 f8 	vbroadcastsd -0x8(%rsp),%ymm2
    1f69:	c4 e2 7d 19 5c 24 f0 	vbroadcastsd -0x10(%rsp),%ymm3
    1f70:	83 ff 03             	cmp    $0x3,%edi
    1f73:	7e 50                	jle    1fc5 <applywavemx2_avx+0x95>
    1f75:	89 fe                	mov    %edi,%esi
    1f77:	4c 89 c2             	mov    %r8,%rdx
    1f7a:	4c 89 c8             	mov    %r9,%rax
    1f7d:	31 c9                	xor    %ecx,%ecx
    1f7f:	c1 fe 02             	sar    $0x2,%esi
    1f82:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    1f89:	00 00 00 00 
    1f8d:	0f 1f 00             	nopl   (%rax)
    1f90:	c5 ed 59 08          	vmulpd (%rax),%ymm2,%ymm1
    1f94:	c5 ed 59 02          	vmulpd (%rdx),%ymm2,%ymm0
    1f98:	ff c1                	inc    %ecx
    1f9a:	48 83 c0 20          	add    $0x20,%rax
    1f9e:	c4 e2 e5 b8 0a       	vfmadd231pd (%rdx),%ymm3,%ymm1
    1fa3:	c4 e2 e5 bc 40 e0    	vfnmadd231pd -0x20(%rax),%ymm3,%ymm0
    1fa9:	48 83 c2 20          	add    $0x20,%rdx
    1fad:	c5 fd 11 48 e0       	vmovupd %ymm1,-0x20(%rax)
    1fb2:	c5 fd 11 42 e0       	vmovupd %ymm0,-0x20(%rdx)
    1fb7:	39 ce                	cmp    %ecx,%esi
    1fb9:	7f d5                	jg     1f90 <applywavemx2_avx+0x60>
    1fbb:	48 c1 e6 05          	shl    $0x5,%rsi
    1fbf:	49 01 f1             	add    %rsi,%r9
    1fc2:	49 01 f0             	add    %rsi,%r8
    1fc5:	89 f8                	mov    %edi,%eax
    1fc7:	c1 f8 1f             	sar    $0x1f,%eax
    1fca:	c1 e8 1e             	shr    $0x1e,%eax
    1fcd:	01 c7                	add    %eax,%edi
    1fcf:	83 e7 03             	and    $0x3,%edi
    1fd2:	29 c7                	sub    %eax,%edi
    1fd4:	85 ff                	test   %edi,%edi
    1fd6:	0f 8e d3 00 00 00    	jle    20af <applywavemx2_avx+0x17f>
    1fdc:	c5 fb 10 4c 24 f8    	vmovsd -0x8(%rsp),%xmm1
    1fe2:	c5 fb 10 44 24 f0    	vmovsd -0x10(%rsp),%xmm0
    1fe8:	83 ff 01             	cmp    $0x1,%edi
    1feb:	0f 84 cf 00 00 00    	je     20c0 <applywavemx2_avx+0x190>
    1ff1:	49 8d 41 0f          	lea    0xf(%r9),%rax
    1ff5:	4c 29 c0             	sub    %r8,%rax
    1ff8:	48 83 f8 1e          	cmp    $0x1e,%rax
    1ffc:	0f 87 7e 00 00 00    	ja     2080 <applywavemx2_avx+0x150>
    2002:	c4 c1 7b 10 11       	vmovsd (%r9),%xmm2
    2007:	c4 c1 7b 59 18       	vmulsd (%r8),%xmm0,%xmm3
    200c:	c4 e2 f1 b9 da       	vfmadd231sd %xmm2,%xmm1,%xmm3
    2011:	c5 fb 59 d2          	vmulsd %xmm2,%xmm0,%xmm2
    2015:	c4 c1 7b 11 19       	vmovsd %xmm3,(%r9)
    201a:	c4 c2 f1 bb 10       	vfmsub231sd (%r8),%xmm1,%xmm2
    201f:	c4 c1 7b 59 58 08    	vmulsd 0x8(%r8),%xmm0,%xmm3
    2025:	c4 c1 7b 11 10       	vmovsd %xmm2,(%r8)
    202a:	c4 c1 7b 10 51 08    	vmovsd 0x8(%r9),%xmm2
    2030:	c4 e2 f1 b9 da       	vfmadd231sd %xmm2,%xmm1,%xmm3
    2035:	c5 fb 59 d2          	vmulsd %xmm2,%xmm0,%xmm2
    2039:	c4 c1 7b 11 59 08    	vmovsd %xmm3,0x8(%r9)
    203f:	c4 c2 f1 bb 50 08    	vfmsub231sd 0x8(%r8),%xmm1,%xmm2
    2045:	c4 c1 7b 11 50 08    	vmovsd %xmm2,0x8(%r8)
    204b:	83 ff 03             	cmp    $0x3,%edi
    204e:	75 5f                	jne    20af <applywavemx2_avx+0x17f>
    2050:	c4 c1 7b 10 59 10    	vmovsd 0x10(%r9),%xmm3
    2056:	c4 c1 7b 59 50 10    	vmulsd 0x10(%r8),%xmm0,%xmm2
    205c:	c4 e2 f1 b9 d3       	vfmadd231sd %xmm3,%xmm1,%xmm2
    2061:	c5 fb 59 c3          	vmulsd %xmm3,%xmm0,%xmm0
    2065:	c4 c1 7b 11 51 10    	vmovsd %xmm2,0x10(%r9)
    206b:	c4 c2 f1 bb 40 10    	vfmsub231sd 0x10(%r8),%xmm1,%xmm0
    2071:	c4 c1 7b 11 40 10    	vmovsd %xmm0,0x10(%r8)
    2077:	c5 f8 77             	vzeroupper 
    207a:	c9                   	leave  
    207b:	c3                   	ret    
    207c:	0f 1f 40 00          	nopl   0x0(%rax)
    2080:	c5 fb 12 e0          	vmovddup %xmm0,%xmm4
    2084:	c4 c1 59 59 28       	vmulpd (%r8),%xmm4,%xmm5
    2089:	c4 c1 79 10 19       	vmovupd (%r9),%xmm3
    208e:	c5 fb 12 d1          	vmovddup %xmm1,%xmm2
    2092:	c4 e2 e1 b8 ea       	vfmadd231pd %xmm2,%xmm3,%xmm5
    2097:	c5 e1 59 dc          	vmulpd %xmm4,%xmm3,%xmm3
    209b:	c4 c1 79 11 29       	vmovupd %xmm5,(%r9)
    20a0:	c4 c2 e1 9a 10       	vfmsub132pd (%r8),%xmm3,%xmm2
    20a5:	c4 c1 79 11 10       	vmovupd %xmm2,(%r8)
    20aa:	83 ff 02             	cmp    $0x2,%edi
    20ad:	75 a1                	jne    2050 <applywavemx2_avx+0x120>
    20af:	c5 f8 77             	vzeroupper 
    20b2:	c9                   	leave  
    20b3:	c3                   	ret    
    20b4:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    20bb:	00 00 00 00 
    20bf:	90                   	nop
    20c0:	c4 c1 7b 10 19       	vmovsd (%r9),%xmm3
    20c5:	c4 c1 7b 59 10       	vmulsd (%r8),%xmm0,%xmm2
    20ca:	c4 e2 f1 b9 d3       	vfmadd231sd %xmm3,%xmm1,%xmm2
    20cf:	c5 fb 59 c3          	vmulsd %xmm3,%xmm0,%xmm0
    20d3:	c4 c1 7b 11 11       	vmovsd %xmm2,(%r9)
    20d8:	c4 c2 f1 bb 00       	vfmsub231sd (%r8),%xmm1,%xmm0
    20dd:	c4 c1 7b 11 00       	vmovsd %xmm0,(%r8)
    20e2:	c5 f8 77             	vzeroupper 
    20e5:	c9                   	leave  
    20e6:	c3                   	ret    
    20e7:	66 0f 1f 84 00 00 00 	nopw   0x0(%rax,%rax,1)
    20ee:	00 00 

00000000000020f0 <applygmx2>:
    20f0:	f3 0f 1e fa          	endbr64 
    20f4:	48 89 f1             	mov    %rsi,%rcx
    20f7:	48 89 d0             	mov    %rdx,%rax
    20fa:	c5 fb 10 d8          	vmovsd %xmm0,%xmm0,%xmm3
    20fe:	c5 f9 2e 05 c2 3f 00 	vucomisd 0x3fc2(%rip),%xmm0        # 60c8 <__PRETTY_FUNCTION__.0+0x88>
    2105:	00 
    2106:	7a 06                	jp     210e <applygmx2+0x1e>
    2108:	0f 84 75 01 00 00    	je     2283 <applygmx2+0x193>
    210e:	85 ff                	test   %edi,%edi
    2110:	0f 8e 6d 01 00 00    	jle    2283 <applygmx2+0x193>
    2116:	8d 77 ff             	lea    -0x1(%rdi),%esi
    2119:	41 89 f9             	mov    %edi,%r9d
    211c:	83 fe 02             	cmp    $0x2,%esi
    211f:	76 0d                	jbe    212e <applygmx2+0x3e>
    2121:	48 8d 51 3f          	lea    0x3f(%rcx),%rdx
    2125:	48 29 c2             	sub    %rax,%rdx
    2128:	48 83 fa 7e          	cmp    $0x7e,%rdx
    212c:	77 42                	ja     2170 <applygmx2+0x80>
    212e:	48 63 ff             	movslq %edi,%rdi
    2131:	48 8d 14 f8          	lea    (%rax,%rdi,8),%rdx
    2135:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    213c:	00 00 00 00 
    2140:	c5 fb 10 01          	vmovsd (%rcx),%xmm0
    2144:	c5 f3 59 10          	vmulsd (%rax),%xmm1,%xmm2
    2148:	c4 e2 e1 b9 d0       	vfmadd231sd %xmm0,%xmm3,%xmm2
    214d:	48 83 c0 08          	add    $0x8,%rax
    2151:	c5 f3 59 c0          	vmulsd %xmm0,%xmm1,%xmm0
    2155:	48 83 c1 08          	add    $0x8,%rcx
    2159:	c5 fb 11 51 f8       	vmovsd %xmm2,-0x8(%rcx)
    215e:	c4 e2 e1 bb 40 f8    	vfmsub231sd -0x8(%rax),%xmm3,%xmm0
    2164:	c5 fb 11 40 f8       	vmovsd %xmm0,-0x8(%rax)
    2169:	48 39 d0             	cmp    %rdx,%rax
    216c:	75 d2                	jne    2140 <applygmx2+0x50>
    216e:	c3                   	ret    
    216f:	90                   	nop
    2170:	83 fe 06             	cmp    $0x6,%esi
    2173:	0f 86 6d 01 00 00    	jbe    22e6 <applygmx2+0x1f6>
    2179:	41 89 f8             	mov    %edi,%r8d
    217c:	62 f2 fd 48 19 eb    	vbroadcastsd %xmm3,%zmm5
    2182:	62 f2 fd 48 19 e1    	vbroadcastsd %xmm1,%zmm4
    2188:	48 89 ce             	mov    %rcx,%rsi
    218b:	41 c1 e8 03          	shr    $0x3,%r8d
    218f:	49 c1 e0 06          	shl    $0x6,%r8
    2193:	48 89 c2             	mov    %rax,%rdx
    2196:	49 01 c8             	add    %rcx,%r8
    2199:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)
    21a0:	62 f1 dd 48 59 12    	vmulpd (%rdx),%zmm4,%zmm2
    21a6:	62 f1 fd 48 10 06    	vmovupd (%rsi),%zmm0
    21ac:	48 83 c6 40          	add    $0x40,%rsi
    21b0:	48 83 c2 40          	add    $0x40,%rdx
    21b4:	62 f2 fd 48 b8 d5    	vfmadd231pd %zmm5,%zmm0,%zmm2
    21ba:	62 f1 fd 48 59 c4    	vmulpd %zmm4,%zmm0,%zmm0
    21c0:	62 f1 fd 48 11 56 ff 	vmovupd %zmm2,-0x40(%rsi)
    21c7:	62 f2 d5 48 ba 42 ff 	vfmsub231pd -0x40(%rdx),%zmm5,%zmm0
    21ce:	62 f1 fd 48 11 42 ff 	vmovupd %zmm0,-0x40(%rdx)
    21d5:	49 39 f0             	cmp    %rsi,%r8
    21d8:	75 c6                	jne    21a0 <applygmx2+0xb0>
    21da:	41 89 f8             	mov    %edi,%r8d
    21dd:	41 83 e0 f8          	and    $0xfffffff8,%r8d
    21e1:	44 89 c6             	mov    %r8d,%esi
    21e4:	44 89 c2             	mov    %r8d,%edx
    21e7:	48 c1 e6 03          	shl    $0x3,%rsi
    21eb:	4c 8d 14 31          	lea    (%rcx,%rsi,1),%r10
    21ef:	48 01 c6             	add    %rax,%rsi
    21f2:	44 39 c7             	cmp    %r8d,%edi
    21f5:	0f 84 85 00 00 00    	je     2280 <applygmx2+0x190>
    21fb:	41 89 f9             	mov    %edi,%r9d
    21fe:	45 29 c1             	sub    %r8d,%r9d
    2201:	45 8d 59 ff          	lea    -0x1(%r9),%r11d
    2205:	41 83 fb 02          	cmp    $0x2,%r11d
    2209:	76 4d                	jbe    2258 <applygmx2+0x168>
    220b:	48 c1 e2 03          	shl    $0x3,%rdx
    220f:	c4 e2 7d 19 e1       	vbroadcastsd %xmm1,%ymm4
    2214:	c4 e2 7d 19 c3       	vbroadcastsd %xmm3,%ymm0
    2219:	48 01 d0             	add    %rdx,%rax
    221c:	48 01 d1             	add    %rdx,%rcx
    221f:	c5 dd 59 28          	vmulpd (%rax),%ymm4,%ymm5
    2223:	c5 fd 10 11          	vmovupd (%rcx),%ymm2
    2227:	c4 e2 ed b8 e8       	vfmadd231pd %ymm0,%ymm2,%ymm5
    222c:	c5 ed 59 d4          	vmulpd %ymm4,%ymm2,%ymm2
    2230:	c5 fd 11 29          	vmovupd %ymm5,(%rcx)
    2234:	c4 e2 ed 9a 00       	vfmsub132pd (%rax),%ymm2,%ymm0
    2239:	c5 fd 11 00          	vmovupd %ymm0,(%rax)
    223d:	44 89 c8             	mov    %r9d,%eax
    2240:	83 e0 fc             	and    $0xfffffffc,%eax
    2243:	89 c2                	mov    %eax,%edx
    2245:	41 01 c0             	add    %eax,%r8d
    2248:	48 c1 e2 03          	shl    $0x3,%rdx
    224c:	49 01 d2             	add    %rdx,%r10
    224f:	48 01 d6             	add    %rdx,%rsi
    2252:	41 83 e1 03          	and    $0x3,%r9d
    2256:	74 28                	je     2280 <applygmx2+0x190>
    2258:	c4 c1 7b 10 02       	vmovsd (%r10),%xmm0
    225d:	c5 f3 59 16          	vmulsd (%rsi),%xmm1,%xmm2
    2261:	c4 e2 e1 b9 d0       	vfmadd231sd %xmm0,%xmm3,%xmm2
    2266:	41 8d 40 01          	lea    0x1(%r8),%eax
    226a:	c5 f3 59 c0          	vmulsd %xmm0,%xmm1,%xmm0
    226e:	c4 c1 7b 11 12       	vmovsd %xmm2,(%r10)
    2273:	c4 e2 e1 bb 06       	vfmsub231sd (%rsi),%xmm3,%xmm0
    2278:	c5 fb 11 06          	vmovsd %xmm0,(%rsi)
    227c:	39 c7                	cmp    %eax,%edi
    227e:	7f 10                	jg     2290 <applygmx2+0x1a0>
    2280:	c5 f8 77             	vzeroupper 
    2283:	c3                   	ret    
    2284:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    228b:	00 00 00 00 
    228f:	90                   	nop
    2290:	c4 c1 7b 10 42 08    	vmovsd 0x8(%r10),%xmm0
    2296:	c5 f3 59 56 08       	vmulsd 0x8(%rsi),%xmm1,%xmm2
    229b:	c4 e2 e1 b9 d0       	vfmadd231sd %xmm0,%xmm3,%xmm2
    22a0:	41 8d 40 02          	lea    0x2(%r8),%eax
    22a4:	c5 f3 59 c0          	vmulsd %xmm0,%xmm1,%xmm0
    22a8:	c4 c1 7b 11 52 08    	vmovsd %xmm2,0x8(%r10)
    22ae:	c4 e2 e1 bb 46 08    	vfmsub231sd 0x8(%rsi),%xmm3,%xmm0
    22b4:	c5 fb 11 46 08       	vmovsd %xmm0,0x8(%rsi)
    22b9:	39 c7                	cmp    %eax,%edi
    22bb:	7e c3                	jle    2280 <applygmx2+0x190>
    22bd:	c4 c1 7b 10 42 10    	vmovsd 0x10(%r10),%xmm0
    22c3:	c5 f3 59 56 10       	vmulsd 0x10(%rsi),%xmm1,%xmm2
    22c8:	c4 e2 e1 b9 d0       	vfmadd231sd %xmm0,%xmm3,%xmm2
    22cd:	c5 f3 59 c0          	vmulsd %xmm0,%xmm1,%xmm0
    22d1:	c4 c1 7b 11 52 10    	vmovsd %xmm2,0x10(%r10)
    22d7:	c4 e2 e1 bb 46 10    	vfmsub231sd 0x10(%rsi),%xmm3,%xmm0
    22dd:	c5 fb 11 46 10       	vmovsd %xmm0,0x10(%rsi)
    22e2:	c5 f8 77             	vzeroupper 
    22e5:	c3                   	ret    
    22e6:	48 89 c6             	mov    %rax,%rsi
    22e9:	49 89 ca             	mov    %rcx,%r10
    22ec:	31 d2                	xor    %edx,%edx
    22ee:	45 31 c0             	xor    %r8d,%r8d
    22f1:	e9 15 ff ff ff       	jmp    220b <applygmx2+0x11b>
    22f6:	66 2e 0f 1f 84 00 00 	cs nopw 0x0(%rax,%rax,1)
    22fd:	00 00 00 

0000000000002300 <applysingle_avx>:
    2300:	f3 0f 1e fa          	endbr64 
    2304:	85 ff                	test   %edi,%edi
    2306:	0f 8e 18 03 00 00    	jle    2624 <applysingle_avx+0x324>
    230c:	83 fa 01             	cmp    $0x1,%edx
    230f:	0f 8e 0f 03 00 00    	jle    2624 <applysingle_avx+0x324>
    2315:	55                   	push   %rbp
    2316:	41 89 fb             	mov    %edi,%r11d
    2319:	48 89 e5             	mov    %rsp,%rbp
    231c:	41 57                	push   %r15
    231e:	41 56                	push   %r14
    2320:	41 55                	push   %r13
    2322:	41 54                	push   %r12
    2324:	53                   	push   %rbx
    2325:	41 89 f4             	mov    %esi,%r12d
    2328:	4c 89 c3             	mov    %r8,%rbx
    232b:	c5 fb 10 3d 95 3d 00 	vmovsd 0x3d95(%rip),%xmm7        # 60c8 <__PRETTY_FUNCTION__.0+0x88>
    2332:	00 
    2333:	48 63 45 10          	movslq 0x10(%rbp),%rax
    2337:	44 89 e7             	mov    %r12d,%edi
    233a:	48 83 e4 c0          	and    $0xffffffffffffffc0,%rsp
    233e:	45 8d 74 24 ff       	lea    -0x1(%r12),%r14d
    2343:	83 e7 f8             	and    $0xfffffff8,%edi
    2346:	44 89 5c 24 cc       	mov    %r11d,-0x34(%rsp)
    234b:	89 7c 24 f4          	mov    %edi,-0xc(%rsp)
    234f:	48 8d 34 c5 00 00 00 	lea    0x0(,%rax,8),%rsi
    2356:	00 
    2357:	8d 42 fe             	lea    -0x2(%rdx),%eax
    235a:	44 89 e2             	mov    %r12d,%edx
    235d:	c1 ea 03             	shr    $0x3,%edx
    2360:	48 89 74 24 d0       	mov    %rsi,-0x30(%rsp)
    2365:	48 c1 e2 06          	shl    $0x6,%rdx
    2369:	48 89 54 24 e0       	mov    %rdx,-0x20(%rsp)
    236e:	89 fa                	mov    %edi,%edx
    2370:	48 c1 e0 04          	shl    $0x4,%rax
    2374:	48 c1 e2 03          	shl    $0x3,%rdx
    2378:	4c 8d 6c 01 10       	lea    0x10(%rcx,%rax,1),%r13
    237d:	48 89 54 24 e8       	mov    %rdx,-0x18(%rsp)
    2382:	48 c7 c1 f0 ff ff ff 	mov    $0xfffffffffffffff0,%rcx
    2389:	49 63 d4             	movslq %r12d,%rdx
    238c:	48 c1 e2 03          	shl    $0x3,%rdx
    2390:	48 29 c1             	sub    %rax,%rcx
    2393:	44 89 e0             	mov    %r12d,%eax
    2396:	48 89 54 24 f8       	mov    %rdx,-0x8(%rsp)
    239b:	31 d2                	xor    %edx,%edx
    239d:	29 f8                	sub    %edi,%eax
    239f:	48 89 4c 24 c0       	mov    %rcx,-0x40(%rsp)
    23a4:	89 44 24 f0          	mov    %eax,-0x10(%rsp)
    23a8:	ff c8                	dec    %eax
    23aa:	89 44 24 dc          	mov    %eax,-0x24(%rsp)
    23ae:	66 90                	xchg   %ax,%ax
    23b0:	48 8b 44 24 c0       	mov    -0x40(%rsp),%rax
    23b5:	89 54 24 d8          	mov    %edx,-0x28(%rsp)
    23b9:	4a 8d 3c 28          	lea    (%rax,%r13,1),%rdi
    23bd:	31 c0                	xor    %eax,%eax
    23bf:	90                   	nop
    23c0:	c5 fb 10 17          	vmovsd (%rdi),%xmm2
    23c4:	c5 f9 2e d7          	vucomisd %xmm7,%xmm2
    23c8:	7a 0a                	jp     23d4 <applysingle_avx+0xd4>
    23ca:	46 8d 04 08          	lea    (%rax,%r9,1),%r8d
    23ce:	0f 84 8a 00 00 00    	je     245e <applysingle_avx+0x15e>
    23d4:	46 8d 04 08          	lea    (%rax,%r9,1),%r8d
    23d8:	45 85 e4             	test   %r12d,%r12d
    23db:	0f 8e 7d 00 00 00    	jle    245e <applysingle_avx+0x15e>
    23e1:	45 8d 04 01          	lea    (%r9,%rax,1),%r8d
    23e5:	4c 63 d8             	movslq %eax,%r11
    23e8:	c5 fb 10 5f 08       	vmovsd 0x8(%rdi),%xmm3
    23ed:	4d 63 d0             	movslq %r8d,%r10
    23f0:	4a 8d 0c dd 00 00 00 	lea    0x0(,%r11,8),%rcx
    23f7:	00 
    23f8:	4a 8d 34 d5 00 00 00 	lea    0x0(,%r10,8),%rsi
    23ff:	00 
    2400:	48 8d 14 0b          	lea    (%rbx,%rcx,1),%rdx
    2404:	48 8d 04 33          	lea    (%rbx,%rsi,1),%rax
    2408:	41 83 fe 02          	cmp    $0x2,%r14d
    240c:	76 16                	jbe    2424 <applysingle_avx+0x124>
    240e:	4c 8d 7e 40          	lea    0x40(%rsi),%r15
    2412:	4c 39 f9             	cmp    %r15,%rcx
    2415:	0f 8d 85 00 00 00    	jge    24a0 <applysingle_avx+0x1a0>
    241b:	48 83 c1 40          	add    $0x40,%rcx
    241f:	48 39 ce             	cmp    %rcx,%rsi
    2422:	7d 7c                	jge    24a0 <applysingle_avx+0x1a0>
    2424:	48 8b 74 24 f8       	mov    -0x8(%rsp),%rsi
    2429:	48 8d 0c 30          	lea    (%rax,%rsi,1),%rcx
    242d:	0f 1f 00             	nopl   (%rax)
    2430:	c5 fb 10 02          	vmovsd (%rdx),%xmm0
    2434:	c5 e3 59 08          	vmulsd (%rax),%xmm3,%xmm1
    2438:	c4 e2 e9 b9 c8       	vfmadd231sd %xmm0,%xmm2,%xmm1
    243d:	48 83 c0 08          	add    $0x8,%rax
    2441:	c5 e3 59 c0          	vmulsd %xmm0,%xmm3,%xmm0
    2445:	48 83 c2 08          	add    $0x8,%rdx
    2449:	c5 fb 11 4a f8       	vmovsd %xmm1,-0x8(%rdx)
    244e:	c4 e2 e9 bb 40 f8    	vfmsub231sd -0x8(%rax),%xmm2,%xmm0
    2454:	c5 fb 11 40 f8       	vmovsd %xmm0,-0x8(%rax)
    2459:	48 39 c8             	cmp    %rcx,%rax
    245c:	75 d2                	jne    2430 <applysingle_avx+0x130>
    245e:	48 83 c7 10          	add    $0x10,%rdi
    2462:	44 89 c0             	mov    %r8d,%eax
    2465:	49 39 fd             	cmp    %rdi,%r13
    2468:	0f 85 52 ff ff ff    	jne    23c0 <applysingle_avx+0xc0>
    246e:	8b 54 24 d8          	mov    -0x28(%rsp),%edx
    2472:	48 8b 44 24 d0       	mov    -0x30(%rsp),%rax
    2477:	ff c2                	inc    %edx
    2479:	49 01 c5             	add    %rax,%r13
    247c:	39 54 24 cc          	cmp    %edx,-0x34(%rsp)
    2480:	0f 85 2a ff ff ff    	jne    23b0 <applysingle_avx+0xb0>
    2486:	c5 f8 77             	vzeroupper 
    2489:	48 8d 65 d8          	lea    -0x28(%rbp),%rsp
    248d:	5b                   	pop    %rbx
    248e:	41 5c                	pop    %r12
    2490:	41 5d                	pop    %r13
    2492:	41 5e                	pop    %r14
    2494:	41 5f                	pop    %r15
    2496:	5d                   	pop    %rbp
    2497:	c3                   	ret    
    2498:	0f 1f 84 00 00 00 00 	nopl   0x0(%rax,%rax,1)
    249f:	00 
    24a0:	41 83 fe 06          	cmp    $0x6,%r14d
    24a4:	0f 86 6d 01 00 00    	jbe    2617 <applysingle_avx+0x317>
    24aa:	4c 8b 7c 24 e0       	mov    -0x20(%rsp),%r15
    24af:	62 f2 fd 48 19 ea    	vbroadcastsd %xmm2,%zmm5
    24b5:	62 f2 fd 48 19 e3    	vbroadcastsd %xmm3,%zmm4
    24bb:	48 89 d6             	mov    %rdx,%rsi
    24be:	48 89 c1             	mov    %rax,%rcx
    24c1:	49 01 d7             	add    %rdx,%r15
    24c4:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    24cb:	00 00 00 00 
    24cf:	90                   	nop
    24d0:	62 f1 dd 48 59 09    	vmulpd (%rcx),%zmm4,%zmm1
    24d6:	62 f1 fd 48 10 06    	vmovupd (%rsi),%zmm0
    24dc:	48 83 c6 40          	add    $0x40,%rsi
    24e0:	48 83 c1 40          	add    $0x40,%rcx
    24e4:	62 f2 fd 48 b8 cd    	vfmadd231pd %zmm5,%zmm0,%zmm1
    24ea:	62 f1 fd 48 59 c4    	vmulpd %zmm4,%zmm0,%zmm0
    24f0:	62 f1 fd 48 11 4e ff 	vmovupd %zmm1,-0x40(%rsi)
    24f7:	62 f2 d5 48 ba 41 ff 	vfmsub231pd -0x40(%rcx),%zmm5,%zmm0
    24fe:	62 f1 fd 48 11 41 ff 	vmovupd %zmm0,-0x40(%rcx)
    2505:	49 39 f7             	cmp    %rsi,%r15
    2508:	75 c6                	jne    24d0 <applysingle_avx+0x1d0>
    250a:	48 8b 74 24 e8       	mov    -0x18(%rsp),%rsi
    250f:	8b 4c 24 f4          	mov    -0xc(%rsp),%ecx
    2513:	48 01 f2             	add    %rsi,%rdx
    2516:	48 01 f0             	add    %rsi,%rax
    2519:	41 39 cc             	cmp    %ecx,%r12d
    251c:	0f 84 3c ff ff ff    	je     245e <applysingle_avx+0x15e>
    2522:	83 7c 24 dc 02       	cmpl   $0x2,-0x24(%rsp)
    2527:	8b 74 24 f0          	mov    -0x10(%rsp),%esi
    252b:	76 59                	jbe    2586 <applysingle_avx+0x286>
    252d:	41 89 cf             	mov    %ecx,%r15d
    2530:	49 01 ca             	add    %rcx,%r10
    2533:	49 01 cb             	add    %rcx,%r11
    2536:	c4 e2 7d 19 e3       	vbroadcastsd %xmm3,%ymm4
    253b:	c4 e2 7d 19 c2       	vbroadcastsd %xmm2,%ymm0
    2540:	4a 8d 0c d3          	lea    (%rbx,%r10,8),%rcx
    2544:	4e 8d 1c db          	lea    (%rbx,%r11,8),%r11
    2548:	c5 dd 59 29          	vmulpd (%rcx),%ymm4,%ymm5
    254c:	c4 c1 7d 10 0b       	vmovupd (%r11),%ymm1
    2551:	c4 e2 f5 b8 e8       	vfmadd231pd %ymm0,%ymm1,%ymm5
    2556:	c5 f5 59 cc          	vmulpd %ymm4,%ymm1,%ymm1
    255a:	c4 c1 7d 11 2b       	vmovupd %ymm5,(%r11)
    255f:	c4 e2 f5 9a 01       	vfmsub132pd (%rcx),%ymm1,%ymm0
    2564:	c5 fd 11 01          	vmovupd %ymm0,(%rcx)
    2568:	89 f1                	mov    %esi,%ecx
    256a:	83 e1 fc             	and    $0xfffffffc,%ecx
    256d:	41 89 ca             	mov    %ecx,%r10d
    2570:	44 01 f9             	add    %r15d,%ecx
    2573:	49 c1 e2 03          	shl    $0x3,%r10
    2577:	4c 01 d2             	add    %r10,%rdx
    257a:	4c 01 d0             	add    %r10,%rax
    257d:	83 e6 03             	and    $0x3,%esi
    2580:	0f 84 d8 fe ff ff    	je     245e <applysingle_avx+0x15e>
    2586:	c5 fb 10 02          	vmovsd (%rdx),%xmm0
    258a:	c5 e3 59 08          	vmulsd (%rax),%xmm3,%xmm1
    258e:	c4 e2 e9 b9 c8       	vfmadd231sd %xmm0,%xmm2,%xmm1
    2593:	8d 71 01             	lea    0x1(%rcx),%esi
    2596:	c5 e3 59 c0          	vmulsd %xmm0,%xmm3,%xmm0
    259a:	c5 fb 11 0a          	vmovsd %xmm1,(%rdx)
    259e:	c4 e2 e9 bb 00       	vfmsub231sd (%rax),%xmm2,%xmm0
    25a3:	c5 fb 11 00          	vmovsd %xmm0,(%rax)
    25a7:	44 39 e6             	cmp    %r12d,%esi
    25aa:	0f 8d ae fe ff ff    	jge    245e <applysingle_avx+0x15e>
    25b0:	c5 fb 10 42 08       	vmovsd 0x8(%rdx),%xmm0
    25b5:	c5 e3 59 48 08       	vmulsd 0x8(%rax),%xmm3,%xmm1
    25ba:	c4 e2 e9 b9 c8       	vfmadd231sd %xmm0,%xmm2,%xmm1
    25bf:	83 c1 02             	add    $0x2,%ecx
    25c2:	c5 e3 59 c0          	vmulsd %xmm0,%xmm3,%xmm0
    25c6:	c5 fb 11 4a 08       	vmovsd %xmm1,0x8(%rdx)
    25cb:	c4 e2 e9 bb 40 08    	vfmsub231sd 0x8(%rax),%xmm2,%xmm0
    25d1:	c5 fb 11 40 08       	vmovsd %xmm0,0x8(%rax)
    25d6:	41 39 cc             	cmp    %ecx,%r12d
    25d9:	0f 8e 7f fe ff ff    	jle    245e <applysingle_avx+0x15e>
    25df:	c5 fb 10 42 10       	vmovsd 0x10(%rdx),%xmm0
    25e4:	c5 e3 59 48 10       	vmulsd 0x10(%rax),%xmm3,%xmm1
    25e9:	c4 e2 e9 b9 c8       	vfmadd231sd %xmm0,%xmm2,%xmm1
    25ee:	48 83 c7 10          	add    $0x10,%rdi
    25f2:	c5 e3 59 c0          	vmulsd %xmm0,%xmm3,%xmm0
    25f6:	c5 fb 11 4a 10       	vmovsd %xmm1,0x10(%rdx)
    25fb:	c4 e2 e9 bb 40 10    	vfmsub231sd 0x10(%rax),%xmm2,%xmm0
    2601:	c5 fb 11 40 10       	vmovsd %xmm0,0x10(%rax)
    2606:	44 89 c0             	mov    %r8d,%eax
    2609:	49 39 fd             	cmp    %rdi,%r13
    260c:	0f 85 ae fd ff ff    	jne    23c0 <applysingle_avx+0xc0>
    2612:	e9 57 fe ff ff       	jmp    246e <applysingle_avx+0x16e>
    2617:	44 89 e6             	mov    %r12d,%esi
    261a:	31 c9                	xor    %ecx,%ecx
    261c:	45 31 ff             	xor    %r15d,%r15d
    261f:	e9 0c ff ff ff       	jmp    2530 <applysingle_avx+0x230>
    2624:	c3                   	ret    
    2625:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    262c:	00 00 00 00 

0000000000002630 <dmatrix_vector_multiply_mt_avx._omp_fn.0>:
    2630:	f3 0f 1e fa          	endbr64 
    2634:	41 54                	push   %r12
    2636:	55                   	push   %rbp
    2637:	53                   	push   %rbx
    2638:	48 89 fd             	mov    %rdi,%rbp
    263b:	8b 5f 14             	mov    0x14(%rdi),%ebx
    263e:	e8 4d eb ff ff       	call   1190 <omp_get_num_threads@plt>
    2643:	41 89 c4             	mov    %eax,%r12d
    2646:	e8 b5 eb ff ff       	call   1200 <omp_get_thread_num@plt>
    264b:	89 c1                	mov    %eax,%ecx
    264d:	42 8d 44 23 ff       	lea    -0x1(%rbx,%r12,1),%eax
    2652:	99                   	cltd   
    2653:	41 f7 fc             	idiv   %r12d
    2656:	8d 70 0e             	lea    0xe(%rax),%esi
    2659:	83 c0 07             	add    $0x7,%eax
    265c:	0f 49 f0             	cmovns %eax,%esi
    265f:	89 c8                	mov    %ecx,%eax
    2661:	83 e6 f8             	and    $0xfffffff8,%esi
    2664:	0f af c6             	imul   %esi,%eax
    2667:	39 c3                	cmp    %eax,%ebx
    2669:	89 c2                	mov    %eax,%edx
    266b:	0f 4e d3             	cmovle %ebx,%edx
    266e:	01 c6                	add    %eax,%esi
    2670:	39 de                	cmp    %ebx,%esi
    2672:	0f 4f f3             	cmovg  %ebx,%esi
    2675:	39 f2                	cmp    %esi,%edx
    2677:	7c 07                	jl     2680 <dmatrix_vector_multiply_mt_avx._omp_fn.0+0x50>
    2679:	5b                   	pop    %rbx
    267a:	5d                   	pop    %rbp
    267b:	41 5c                	pop    %r12
    267d:	c3                   	ret    
    267e:	66 90                	xchg   %ax,%ax
    2680:	4c 63 d2             	movslq %edx,%r10
    2683:	29 d6                	sub    %edx,%esi
    2685:	8b 55 20             	mov    0x20(%rbp),%edx
    2688:	48 83 ec 08          	sub    $0x8,%rsp
    268c:	8b 45 18             	mov    0x18(%rbp),%eax
    268f:	4c 8b 45 08          	mov    0x8(%rbp),%r8
    2693:	48 8b 4d 00          	mov    0x0(%rbp),%rcx
    2697:	8b 7d 10             	mov    0x10(%rbp),%edi
    269a:	52                   	push   %rdx
    269b:	44 8b 4d 1c          	mov    0x1c(%rbp),%r9d
    269f:	89 c2                	mov    %eax,%edx
    26a1:	4f 8d 04 d0          	lea    (%r8,%r10,8),%r8
    26a5:	e8 56 fc ff ff       	call   2300 <applysingle_avx>
    26aa:	58                   	pop    %rax
    26ab:	5a                   	pop    %rdx
    26ac:	5b                   	pop    %rbx
    26ad:	5d                   	pop    %rbp
    26ae:	41 5c                	pop    %r12
    26b0:	c3                   	ret    
    26b1:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    26b8:	00 00 00 00 
    26bc:	0f 1f 40 00          	nopl   0x0(%rax)

00000000000026c0 <Check_seq>:
    26c0:	f3 0f 1e fa          	endbr64 
    26c4:	41 57                	push   %r15
    26c6:	41 56                	push   %r14
    26c8:	41 55                	push   %r13
    26ca:	41 54                	push   %r12
    26cc:	55                   	push   %rbp
    26cd:	53                   	push   %rbx
    26ce:	48 83 ec 48          	sub    $0x48,%rsp
    26d2:	48 89 54 24 18       	mov    %rdx,0x18(%rsp)
    26d7:	48 89 4c 24 20       	mov    %rcx,0x20(%rsp)
    26dc:	44 89 44 24 14       	mov    %r8d,0x14(%rsp)
    26e1:	85 f6                	test   %esi,%esi
    26e3:	0f 8e e8 00 00 00    	jle    27d1 <Check_seq+0x111>
    26e9:	49 63 c9             	movslq %r9d,%rcx
    26ec:	41 8d 2c 39          	lea    (%r9,%rdi,1),%ebp
    26f0:	45 31 f6             	xor    %r14d,%r14d
    26f3:	4c 8d 2d 32 39 00 00 	lea    0x3932(%rip),%r13        # 602c <_IO_stdin_used+0x2c>
    26fa:	48 89 c8             	mov    %rcx,%rax
    26fd:	c7 44 24 0c 00 00 00 	movl   $0x0,0xc(%rsp)
    2704:	00 
    2705:	c7 44 24 08 00 00 00 	movl   $0x0,0x8(%rsp)
    270c:	00 
    270d:	48 89 4c 24 30       	mov    %rcx,0x30(%rsp)
    2712:	48 f7 d8             	neg    %rax
    2715:	89 7c 24 10          	mov    %edi,0x10(%rsp)
    2719:	89 74 24 38          	mov    %esi,0x38(%rsp)
    271d:	44 89 4c 24 3c       	mov    %r9d,0x3c(%rsp)
    2722:	48 c1 e0 03          	shl    $0x3,%rax
    2726:	48 89 44 24 28       	mov    %rax,0x28(%rsp)
    272b:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)
    2730:	8b 44 24 10          	mov    0x10(%rsp),%eax
    2734:	85 c0                	test   %eax,%eax
    2736:	7e 79                	jle    27b1 <Check_seq+0xf1>
    2738:	48 63 44 24 08       	movslq 0x8(%rsp),%rax
    273d:	48 8b 54 24 28       	mov    0x28(%rsp),%rdx
    2742:	48 8b 4c 24 18       	mov    0x18(%rsp),%rcx
    2747:	4c 8b 7c 24 30       	mov    0x30(%rsp),%r15
    274c:	48 8d 1c c2          	lea    (%rdx,%rax,8),%rbx
    2750:	48 8b 44 24 20       	mov    0x20(%rsp),%rax
    2755:	48 01 c3             	add    %rax,%rbx
    2758:	48 63 44 24 0c       	movslq 0xc(%rsp),%rax
    275d:	4c 8d 24 c1          	lea    (%rcx,%rax,8),%r12
    2761:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    2768:	00 00 00 00 
    276c:	0f 1f 40 00          	nopl   0x0(%rax)
    2770:	c4 81 7b 10 04 fc    	vmovsd (%r12,%r15,8),%xmm0
    2776:	c4 a1 7b 10 0c fb    	vmovsd (%rbx,%r15,8),%xmm1
    277c:	4c 89 ee             	mov    %r13,%rsi
    277f:	bf 01 00 00 00       	mov    $0x1,%edi
    2784:	b8 02 00 00 00       	mov    $0x2,%eax
    2789:	49 ff c7             	inc    %r15
    278c:	e8 3f ea ff ff       	call   11d0 <__printf_chk@plt>
    2791:	44 39 fd             	cmp    %r15d,%ebp
    2794:	7f da                	jg     2770 <Check_seq+0xb0>
    2796:	8b 44 24 10          	mov    0x10(%rsp),%eax
    279a:	31 d2                	xor    %edx,%edx
    279c:	8b 4c 24 08          	mov    0x8(%rsp),%ecx
    27a0:	ff c8                	dec    %eax
    27a2:	39 6c 24 3c          	cmp    %ebp,0x3c(%rsp)
    27a6:	0f 4d c2             	cmovge %edx,%eax
    27a9:	8d 44 01 01          	lea    0x1(%rcx,%rax,1),%eax
    27ad:	89 44 24 08          	mov    %eax,0x8(%rsp)
    27b1:	bf 0a 00 00 00       	mov    $0xa,%edi
    27b6:	41 ff c6             	inc    %r14d
    27b9:	e8 22 ea ff ff       	call   11e0 <putchar@plt>
    27be:	8b 4c 24 14          	mov    0x14(%rsp),%ecx
    27c2:	01 4c 24 0c          	add    %ecx,0xc(%rsp)
    27c6:	44 39 74 24 38       	cmp    %r14d,0x38(%rsp)
    27cb:	0f 85 5f ff ff ff    	jne    2730 <Check_seq+0x70>
    27d1:	48 83 c4 48          	add    $0x48,%rsp
    27d5:	5b                   	pop    %rbx
    27d6:	5d                   	pop    %rbp
    27d7:	41 5c                	pop    %r12
    27d9:	41 5d                	pop    %r13
    27db:	41 5e                	pop    %r14
    27dd:	41 5f                	pop    %r15
    27df:	c3                   	ret    

00000000000027e0 <copy_seq_avx256>:
    27e0:	f3 0f 1e fa          	endbr64 
    27e4:	41 89 f2             	mov    %esi,%r10d
    27e7:	85 f6                	test   %esi,%esi
    27e9:	7e 57                	jle    2842 <copy_seq_avx256+0x62>
    27eb:	4d 63 c9             	movslq %r9d,%r9
    27ee:	4d 63 c0             	movslq %r8d,%r8
    27f1:	31 f6                	xor    %esi,%esi
    27f3:	4a 8d 14 ca          	lea    (%rdx,%r9,8),%rdx
    27f7:	4c 63 cf             	movslq %edi,%r9
    27fa:	49 c1 e0 03          	shl    $0x3,%r8
    27fe:	49 c1 e1 03          	shl    $0x3,%r9
    2802:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    2809:	00 00 00 00 
    280d:	0f 1f 00             	nopl   (%rax)
    2810:	0f 18 0a             	prefetcht0 (%rdx)
    2813:	85 ff                	test   %edi,%edi
    2815:	7e 1b                	jle    2832 <copy_seq_avx256+0x52>
    2817:	31 c0                	xor    %eax,%eax
    2819:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)
    2820:	c5 fd 28 04 c2       	vmovapd (%rdx,%rax,8),%ymm0
    2825:	c5 fd 29 04 c1       	vmovapd %ymm0,(%rcx,%rax,8)
    282a:	48 83 c0 04          	add    $0x4,%rax
    282e:	39 c7                	cmp    %eax,%edi
    2830:	7f ee                	jg     2820 <copy_seq_avx256+0x40>
    2832:	ff c6                	inc    %esi
    2834:	4c 01 c2             	add    %r8,%rdx
    2837:	4c 01 c9             	add    %r9,%rcx
    283a:	41 39 f2             	cmp    %esi,%r10d
    283d:	75 d1                	jne    2810 <copy_seq_avx256+0x30>
    283f:	c5 f8 77             	vzeroupper 
    2842:	c3                   	ret    
    2843:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    284a:	00 00 00 00 
    284e:	66 90                	xchg   %ax,%ax

0000000000002850 <copy_seq>:
    2850:	f3 0f 1e fa          	endbr64 
    2854:	48 89 d0             	mov    %rdx,%rax
    2857:	41 89 f2             	mov    %esi,%r10d
    285a:	48 89 ca             	mov    %rcx,%rdx
    285d:	85 f6                	test   %esi,%esi
    285f:	7e 55                	jle    28b6 <copy_seq+0x66>
    2861:	85 ff                	test   %edi,%edi
    2863:	7e 51                	jle    28b6 <copy_seq+0x66>
    2865:	4d 63 c9             	movslq %r9d,%r9
    2868:	4d 63 c0             	movslq %r8d,%r8
    286b:	31 f6                	xor    %esi,%esi
    286d:	4a 8d 0c c8          	lea    (%rax,%r9,8),%rcx
    2871:	4c 63 cf             	movslq %edi,%r9
    2874:	49 c1 e0 03          	shl    $0x3,%r8
    2878:	49 c1 e1 03          	shl    $0x3,%r9
    287c:	0f 1f 40 00          	nopl   0x0(%rax)
    2880:	31 c0                	xor    %eax,%eax
    2882:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    2889:	00 00 00 00 
    288d:	0f 1f 00             	nopl   (%rax)
    2890:	62 f1 fd 48 28 04 c1 	vmovapd (%rcx,%rax,8),%zmm0
    2897:	62 f1 fd 48 29 04 c2 	vmovapd %zmm0,(%rdx,%rax,8)
    289e:	48 83 c0 08          	add    $0x8,%rax
    28a2:	39 c7                	cmp    %eax,%edi
    28a4:	7f ea                	jg     2890 <copy_seq+0x40>
    28a6:	ff c6                	inc    %esi
    28a8:	4c 01 c1             	add    %r8,%rcx
    28ab:	4c 01 ca             	add    %r9,%rdx
    28ae:	41 39 f2             	cmp    %esi,%r10d
    28b1:	75 cd                	jne    2880 <copy_seq+0x30>
    28b3:	c5 f8 77             	vzeroupper 
    28b6:	c3                   	ret    
    28b7:	66 0f 1f 84 00 00 00 	nopw   0x0(%rax,%rax,1)
    28be:	00 00 

00000000000028c0 <recover_seq_avx256>:
    28c0:	f3 0f 1e fa          	endbr64 
    28c4:	41 89 f2             	mov    %esi,%r10d
    28c7:	85 f6                	test   %esi,%esi
    28c9:	7e 57                	jle    2922 <recover_seq_avx256+0x62>
    28cb:	85 ff                	test   %edi,%edi
    28cd:	7e 53                	jle    2922 <recover_seq_avx256+0x62>
    28cf:	4c 63 df             	movslq %edi,%r11
    28d2:	4d 63 c0             	movslq %r8d,%r8
    28d5:	4d 63 c9             	movslq %r9d,%r9
    28d8:	31 f6                	xor    %esi,%esi
    28da:	49 c1 e3 03          	shl    $0x3,%r11
    28de:	49 c1 e0 03          	shl    $0x3,%r8
    28e2:	4a 8d 14 ca          	lea    (%rdx,%r9,8),%rdx
    28e6:	66 2e 0f 1f 84 00 00 	cs nopw 0x0(%rax,%rax,1)
    28ed:	00 00 00 
    28f0:	31 c0                	xor    %eax,%eax
    28f2:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    28f9:	00 00 00 00 
    28fd:	0f 1f 00             	nopl   (%rax)
    2900:	c5 fd 28 04 c1       	vmovapd (%rcx,%rax,8),%ymm0
    2905:	c5 fd 29 04 c2       	vmovapd %ymm0,(%rdx,%rax,8)
    290a:	48 83 c0 04          	add    $0x4,%rax
    290e:	39 c7                	cmp    %eax,%edi
    2910:	7f ee                	jg     2900 <recover_seq_avx256+0x40>
    2912:	ff c6                	inc    %esi
    2914:	4c 01 d9             	add    %r11,%rcx
    2917:	4c 01 c2             	add    %r8,%rdx
    291a:	41 39 f2             	cmp    %esi,%r10d
    291d:	75 d1                	jne    28f0 <recover_seq_avx256+0x30>
    291f:	c5 f8 77             	vzeroupper 
    2922:	c3                   	ret    
    2923:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    292a:	00 00 00 00 
    292e:	66 90                	xchg   %ax,%ax

0000000000002930 <recover_seq>:
    2930:	f3 0f 1e fa          	endbr64 
    2934:	41 89 f2             	mov    %esi,%r10d
    2937:	85 f6                	test   %esi,%esi
    2939:	7e 5b                	jle    2996 <recover_seq+0x66>
    293b:	85 ff                	test   %edi,%edi
    293d:	7e 57                	jle    2996 <recover_seq+0x66>
    293f:	4c 63 df             	movslq %edi,%r11
    2942:	4d 63 c0             	movslq %r8d,%r8
    2945:	4d 63 c9             	movslq %r9d,%r9
    2948:	31 f6                	xor    %esi,%esi
    294a:	49 c1 e3 03          	shl    $0x3,%r11
    294e:	49 c1 e0 03          	shl    $0x3,%r8
    2952:	4a 8d 14 ca          	lea    (%rdx,%r9,8),%rdx
    2956:	66 2e 0f 1f 84 00 00 	cs nopw 0x0(%rax,%rax,1)
    295d:	00 00 00 
    2960:	31 c0                	xor    %eax,%eax
    2962:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    2969:	00 00 00 00 
    296d:	0f 1f 00             	nopl   (%rax)
    2970:	62 f1 fd 48 28 04 c1 	vmovapd (%rcx,%rax,8),%zmm0
    2977:	62 f1 fd 48 29 04 c2 	vmovapd %zmm0,(%rdx,%rax,8)
    297e:	48 83 c0 08          	add    $0x8,%rax
    2982:	39 c7                	cmp    %eax,%edi
    2984:	7f ea                	jg     2970 <recover_seq+0x40>
    2986:	ff c6                	inc    %esi
    2988:	4c 01 d9             	add    %r11,%rcx
    298b:	4c 01 c2             	add    %r8,%rdx
    298e:	41 39 f2             	cmp    %esi,%r10d
    2991:	75 cd                	jne    2960 <recover_seq+0x30>
    2993:	c5 f8 77             	vzeroupper 
    2996:	c3                   	ret    
    2997:	66 0f 1f 84 00 00 00 	nopw   0x0(%rax,%rax,1)
    299e:	00 00 

00000000000029a0 <creat_left_seq_avx256>:
    29a0:	f3 0f 1e fa          	endbr64 
    29a4:	55                   	push   %rbp
    29a5:	48 89 e5             	mov    %rsp,%rbp
    29a8:	41 57                	push   %r15
    29aa:	41 56                	push   %r14
    29ac:	41 55                	push   %r13
    29ae:	41 54                	push   %r12
    29b0:	53                   	push   %rbx
    29b1:	48 83 e4 e0          	and    $0xffffffffffffffe0,%rsp
    29b5:	48 83 ec 20          	sub    $0x20,%rsp
    29b9:	44 8b 75 10          	mov    0x10(%rbp),%r14d
    29bd:	89 74 24 1c          	mov    %esi,0x1c(%rsp)
    29c1:	85 f6                	test   %esi,%esi
    29c3:	0f 8e 97 00 00 00    	jle    2a60 <creat_left_seq_avx256+0xc0>
    29c9:	48 63 c7             	movslq %edi,%rax
    29cc:	4d 63 fe             	movslq %r14d,%r15
    29cf:	4d 63 c0             	movslq %r8d,%r8
    29d2:	4d 63 c9             	movslq %r9d,%r9
    29d5:	41 89 c5             	mov    %eax,%r13d
    29d8:	4e 8d 24 ca          	lea    (%rdx,%r9,8),%r12
    29dc:	48 89 cb             	mov    %rcx,%rbx
    29df:	45 29 f5             	sub    %r14d,%r13d
    29e2:	4d 63 ed             	movslq %r13d,%r13
    29e5:	4a 8d 34 ed 00 00 00 	lea    0x0(,%r13,8),%rsi
    29ec:	00 
    29ed:	45 31 ed             	xor    %r13d,%r13d
    29f0:	48 c1 e0 03          	shl    $0x3,%rax
    29f4:	48 89 74 24 10       	mov    %rsi,0x10(%rsp)
    29f9:	49 c1 e7 03          	shl    $0x3,%r15
    29fd:	48 89 44 24 08       	mov    %rax,0x8(%rsp)
    2a02:	4a 8d 34 c5 00 00 00 	lea    0x0(,%r8,8),%rsi
    2a09:	00 
    2a0a:	48 89 34 24          	mov    %rsi,(%rsp)
    2a0e:	66 90                	xchg   %ax,%ax
    2a10:	41 0f 18 0c 24       	prefetcht0 (%r12)
    2a15:	45 85 f6             	test   %r14d,%r14d
    2a18:	7e 1d                	jle    2a37 <creat_left_seq_avx256+0x97>
    2a1a:	31 c0                	xor    %eax,%eax
    2a1c:	0f 1f 40 00          	nopl   0x0(%rax)
    2a20:	c4 c1 7d 28 04 c4    	vmovapd (%r12,%rax,8),%ymm0
    2a26:	c5 fd 29 04 c3       	vmovapd %ymm0,(%rbx,%rax,8)
    2a2b:	48 83 c0 04          	add    $0x4,%rax
    2a2f:	41 39 c6             	cmp    %eax,%r14d
    2a32:	7f ec                	jg     2a20 <creat_left_seq_avx256+0x80>
    2a34:	c5 f8 77             	vzeroupper 
    2a37:	48 8b 54 24 10       	mov    0x10(%rsp),%rdx
    2a3c:	49 8d 3c 1f          	lea    (%r15,%rbx,1),%rdi
    2a40:	31 f6                	xor    %esi,%esi
    2a42:	41 ff c5             	inc    %r13d
    2a45:	e8 36 e7 ff ff       	call   1180 <memset@plt>
    2a4a:	48 8b 04 24          	mov    (%rsp),%rax
    2a4e:	49 01 c4             	add    %rax,%r12
    2a51:	48 8b 44 24 08       	mov    0x8(%rsp),%rax
    2a56:	48 01 c3             	add    %rax,%rbx
    2a59:	44 39 6c 24 1c       	cmp    %r13d,0x1c(%rsp)
    2a5e:	75 b0                	jne    2a10 <creat_left_seq_avx256+0x70>
    2a60:	48 8d 65 d8          	lea    -0x28(%rbp),%rsp
    2a64:	5b                   	pop    %rbx
    2a65:	41 5c                	pop    %r12
    2a67:	41 5d                	pop    %r13
    2a69:	41 5e                	pop    %r14
    2a6b:	41 5f                	pop    %r15
    2a6d:	5d                   	pop    %rbp
    2a6e:	c3                   	ret    
    2a6f:	90                   	nop

0000000000002a70 <creat_left_seq>:
    2a70:	f3 0f 1e fa          	endbr64 
    2a74:	55                   	push   %rbp
    2a75:	48 89 e5             	mov    %rsp,%rbp
    2a78:	41 57                	push   %r15
    2a7a:	41 56                	push   %r14
    2a7c:	41 55                	push   %r13
    2a7e:	41 54                	push   %r12
    2a80:	53                   	push   %rbx
    2a81:	48 83 e4 c0          	and    $0xffffffffffffffc0,%rsp
    2a85:	48 83 ec 40          	sub    $0x40,%rsp
    2a89:	44 8b 75 10          	mov    0x10(%rbp),%r14d
    2a8d:	89 74 24 3c          	mov    %esi,0x3c(%rsp)
    2a91:	85 f6                	test   %esi,%esi
    2a93:	0f 8e 9b 00 00 00    	jle    2b34 <creat_left_seq+0xc4>
    2a99:	48 63 c7             	movslq %edi,%rax
    2a9c:	4d 63 fe             	movslq %r14d,%r15
    2a9f:	4d 63 c0             	movslq %r8d,%r8
    2aa2:	4d 63 c9             	movslq %r9d,%r9
    2aa5:	41 89 c5             	mov    %eax,%r13d
    2aa8:	4e 8d 24 ca          	lea    (%rdx,%r9,8),%r12
    2aac:	48 89 cb             	mov    %rcx,%rbx
    2aaf:	45 29 f5             	sub    %r14d,%r13d
    2ab2:	4d 63 ed             	movslq %r13d,%r13
    2ab5:	4a 8d 34 ed 00 00 00 	lea    0x0(,%r13,8),%rsi
    2abc:	00 
    2abd:	45 31 ed             	xor    %r13d,%r13d
    2ac0:	48 c1 e0 03          	shl    $0x3,%rax
    2ac4:	48 89 74 24 30       	mov    %rsi,0x30(%rsp)
    2ac9:	49 c1 e7 03          	shl    $0x3,%r15
    2acd:	48 89 44 24 28       	mov    %rax,0x28(%rsp)
    2ad2:	4a 8d 34 c5 00 00 00 	lea    0x0(,%r8,8),%rsi
    2ad9:	00 
    2ada:	48 89 74 24 20       	mov    %rsi,0x20(%rsp)
    2adf:	90                   	nop
    2ae0:	45 85 f6             	test   %r14d,%r14d
    2ae3:	7e 25                	jle    2b0a <creat_left_seq+0x9a>
    2ae5:	31 c0                	xor    %eax,%eax
    2ae7:	66 0f 1f 84 00 00 00 	nopw   0x0(%rax,%rax,1)
    2aee:	00 00 
    2af0:	62 d1 fd 48 28 04 c4 	vmovapd (%r12,%rax,8),%zmm0
    2af7:	62 f1 fd 48 29 04 c3 	vmovapd %zmm0,(%rbx,%rax,8)
    2afe:	48 83 c0 08          	add    $0x8,%rax
    2b02:	41 39 c6             	cmp    %eax,%r14d
    2b05:	7f e9                	jg     2af0 <creat_left_seq+0x80>
    2b07:	c5 f8 77             	vzeroupper 
    2b0a:	48 8b 54 24 30       	mov    0x30(%rsp),%rdx
    2b0f:	49 8d 3c 1f          	lea    (%r15,%rbx,1),%rdi
    2b13:	31 f6                	xor    %esi,%esi
    2b15:	41 ff c5             	inc    %r13d
    2b18:	e8 63 e6 ff ff       	call   1180 <memset@plt>
    2b1d:	48 8b 44 24 20       	mov    0x20(%rsp),%rax
    2b22:	49 01 c4             	add    %rax,%r12
    2b25:	48 8b 44 24 28       	mov    0x28(%rsp),%rax
    2b2a:	48 01 c3             	add    %rax,%rbx
    2b2d:	44 39 6c 24 3c       	cmp    %r13d,0x3c(%rsp)
    2b32:	75 ac                	jne    2ae0 <creat_left_seq+0x70>
    2b34:	48 8d 65 d8          	lea    -0x28(%rbp),%rsp
    2b38:	5b                   	pop    %rbx
    2b39:	41 5c                	pop    %r12
    2b3b:	41 5d                	pop    %r13
    2b3d:	41 5e                	pop    %r14
    2b3f:	41 5f                	pop    %r15
    2b41:	5d                   	pop    %rbp
    2b42:	c3                   	ret    
    2b43:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    2b4a:	00 00 00 00 
    2b4e:	66 90                	xchg   %ax,%ax

0000000000002b50 <recover_seq_left_avx256>:
    2b50:	f3 0f 1e fa          	endbr64 
    2b54:	55                   	push   %rbp
    2b55:	41 89 f2             	mov    %esi,%r10d
    2b58:	48 89 e5             	mov    %rsp,%rbp
    2b5b:	8b 75 10             	mov    0x10(%rbp),%esi
    2b5e:	45 85 d2             	test   %r10d,%r10d
    2b61:	7e 4f                	jle    2bb2 <recover_seq_left_avx256+0x62>
    2b63:	4d 63 c0             	movslq %r8d,%r8
    2b66:	48 63 ff             	movslq %edi,%rdi
    2b69:	4d 63 c9             	movslq %r9d,%r9
    2b6c:	49 c1 e0 03          	shl    $0x3,%r8
    2b70:	4c 8d 1c fd 00 00 00 	lea    0x0(,%rdi,8),%r11
    2b77:	00 
    2b78:	4a 8d 14 ca          	lea    (%rdx,%r9,8),%rdx
    2b7c:	31 ff                	xor    %edi,%edi
    2b7e:	66 90                	xchg   %ax,%ax
    2b80:	0f 18 09             	prefetcht0 (%rcx)
    2b83:	85 f6                	test   %esi,%esi
    2b85:	7e 1b                	jle    2ba2 <recover_seq_left_avx256+0x52>
    2b87:	31 c0                	xor    %eax,%eax
    2b89:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)
    2b90:	c5 fd 28 04 c1       	vmovapd (%rcx,%rax,8),%ymm0
    2b95:	c5 fd 29 04 c2       	vmovapd %ymm0,(%rdx,%rax,8)
    2b9a:	48 83 c0 04          	add    $0x4,%rax
    2b9e:	39 c6                	cmp    %eax,%esi
    2ba0:	7f ee                	jg     2b90 <recover_seq_left_avx256+0x40>
    2ba2:	ff c7                	inc    %edi
    2ba4:	4c 01 d9             	add    %r11,%rcx
    2ba7:	4c 01 c2             	add    %r8,%rdx
    2baa:	41 39 fa             	cmp    %edi,%r10d
    2bad:	75 d1                	jne    2b80 <recover_seq_left_avx256+0x30>
    2baf:	c5 f8 77             	vzeroupper 
    2bb2:	5d                   	pop    %rbp
    2bb3:	c3                   	ret    
    2bb4:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    2bbb:	00 00 00 00 
    2bbf:	90                   	nop

0000000000002bc0 <recover_seq_left>:
    2bc0:	f3 0f 1e fa          	endbr64 
    2bc4:	55                   	push   %rbp
    2bc5:	41 89 f2             	mov    %esi,%r10d
    2bc8:	48 89 e5             	mov    %rsp,%rbp
    2bcb:	8b 75 10             	mov    0x10(%rbp),%esi
    2bce:	45 85 d2             	test   %r10d,%r10d
    2bd1:	7e 63                	jle    2c36 <recover_seq_left+0x76>
    2bd3:	85 f6                	test   %esi,%esi
    2bd5:	7e 5f                	jle    2c36 <recover_seq_left+0x76>
    2bd7:	4d 63 c0             	movslq %r8d,%r8
    2bda:	48 63 ff             	movslq %edi,%rdi
    2bdd:	4d 63 c9             	movslq %r9d,%r9
    2be0:	49 c1 e0 03          	shl    $0x3,%r8
    2be4:	4c 8d 1c fd 00 00 00 	lea    0x0(,%rdi,8),%r11
    2beb:	00 
    2bec:	4a 8d 14 ca          	lea    (%rdx,%r9,8),%rdx
    2bf0:	31 ff                	xor    %edi,%edi
    2bf2:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    2bf9:	00 00 00 00 
    2bfd:	0f 1f 00             	nopl   (%rax)
    2c00:	31 c0                	xor    %eax,%eax
    2c02:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    2c09:	00 00 00 00 
    2c0d:	0f 1f 00             	nopl   (%rax)
    2c10:	62 f1 fd 48 28 04 c1 	vmovapd (%rcx,%rax,8),%zmm0
    2c17:	62 f1 fd 48 29 04 c2 	vmovapd %zmm0,(%rdx,%rax,8)
    2c1e:	48 83 c0 08          	add    $0x8,%rax
    2c22:	39 c6                	cmp    %eax,%esi
    2c24:	7f ea                	jg     2c10 <recover_seq_left+0x50>
    2c26:	ff c7                	inc    %edi
    2c28:	4c 01 d9             	add    %r11,%rcx
    2c2b:	4c 01 c2             	add    %r8,%rdx
    2c2e:	41 39 fa             	cmp    %edi,%r10d
    2c31:	75 cd                	jne    2c00 <recover_seq_left+0x40>
    2c33:	c5 f8 77             	vzeroupper 
    2c36:	5d                   	pop    %rbp
    2c37:	c3                   	ret    
    2c38:	0f 1f 84 00 00 00 00 	nopl   0x0(%rax,%rax,1)
    2c3f:	00 

0000000000002c40 <apply_rev_avx512_fma_auto_mv_seq_ALL>:
    2c40:	f3 0f 1e fa          	endbr64 
    2c44:	41 57                	push   %r15
    2c46:	41 56                	push   %r14
    2c48:	41 55                	push   %r13
    2c4a:	41 54                	push   %r12
    2c4c:	55                   	push   %rbp
    2c4d:	53                   	push   %rbx
    2c4e:	48 63 ea             	movslq %edx,%rbp
    2c51:	48 81 ec b8 00 00 00 	sub    $0xb8,%rsp
    2c58:	48 89 eb             	mov    %rbp,%rbx
    2c5b:	8b 84 24 f0 00 00 00 	mov    0xf0(%rsp),%eax
    2c62:	48 89 4c 24 48       	mov    %rcx,0x48(%rsp)
    2c67:	8b 8c 24 00 01 00 00 	mov    0x100(%rsp),%ecx
    2c6e:	89 7c 24 18          	mov    %edi,0x18(%rsp)
    2c72:	89 74 24 58          	mov    %esi,0x58(%rsp)
    2c76:	4c 89 84 24 80 00 00 	mov    %r8,0x80(%rsp)
    2c7d:	00 
    2c7e:	44 89 8c 24 8c 00 00 	mov    %r9d,0x8c(%rsp)
    2c85:	00 
    2c86:	48 8d bc 24 a0 00 00 	lea    0xa0(%rsp),%rdi
    2c8d:	00 
    2c8e:	89 44 24 5c          	mov    %eax,0x5c(%rsp)
    2c92:	8b 84 24 f8 00 00 00 	mov    0xf8(%rsp),%eax
    2c99:	8d 14 cd 00 00 00 00 	lea    0x0(,%rcx,8),%edx
    2ca0:	89 44 24 1c          	mov    %eax,0x1c(%rsp)
    2ca4:	64 48 8b 04 25 28 00 	mov    %fs:0x28,%rax
    2cab:	00 00 
    2cad:	48 89 84 24 a8 00 00 	mov    %rax,0xa8(%rsp)
    2cb4:	00 
    2cb5:	31 c0                	xor    %eax,%eax
    2cb7:	89 54 24 50          	mov    %edx,0x50(%rsp)
    2cbb:	89 f0                	mov    %esi,%eax
    2cbd:	89 d6                	mov    %edx,%esi
    2cbf:	99                   	cltd   
    2cc0:	f7 fe                	idiv   %esi
    2cc2:	0f af c1             	imul   %ecx,%eax
    2cc5:	89 94 24 88 00 00 00 	mov    %edx,0x88(%rsp)
    2ccc:	c1 e0 03             	shl    $0x3,%eax
    2ccf:	89 44 24 54          	mov    %eax,0x54(%rsp)
    2cd3:	48 63 c6             	movslq %esi,%rax
    2cd6:	be 40 00 00 00       	mov    $0x40,%esi
    2cdb:	48 0f af e8          	imul   %rax,%rbp
    2cdf:	48 89 44 24 78       	mov    %rax,0x78(%rsp)
    2ce4:	48 c1 e5 03          	shl    $0x3,%rbp
    2ce8:	48 89 ea             	mov    %rbp,%rdx
    2ceb:	e8 b0 e4 ff ff       	call   11a0 <posix_memalign@plt>
    2cf0:	48 c7 44 24 10 00 00 	movq   $0x0,0x10(%rsp)
    2cf7:	00 00 
    2cf9:	85 c0                	test   %eax,%eax
    2cfb:	75 0d                	jne    2d0a <apply_rev_avx512_fma_auto_mv_seq_ALL+0xca>
    2cfd:	48 8b 84 24 a0 00 00 	mov    0xa0(%rsp),%rax
    2d04:	00 
    2d05:	48 89 44 24 10       	mov    %rax,0x10(%rsp)
    2d0a:	48 8d bc 24 98 00 00 	lea    0x98(%rsp),%rdi
    2d11:	00 
    2d12:	48 89 ea             	mov    %rbp,%rdx
    2d15:	be 40 00 00 00       	mov    $0x40,%esi
    2d1a:	e8 81 e4 ff ff       	call   11a0 <posix_memalign@plt>
    2d1f:	48 c7 44 24 68 00 00 	movq   $0x0,0x68(%rsp)
    2d26:	00 00 
    2d28:	85 c0                	test   %eax,%eax
    2d2a:	75 0d                	jne    2d39 <apply_rev_avx512_fma_auto_mv_seq_ALL+0xf9>
    2d2c:	48 8b 84 24 98 00 00 	mov    0x98(%rsp),%rax
    2d33:	00 
    2d34:	48 89 44 24 68       	mov    %rax,0x68(%rsp)
    2d39:	8b 6c 24 54          	mov    0x54(%rsp),%ebp
    2d3d:	85 ed                	test   %ebp,%ebp
    2d3f:	0f 8e 16 02 00 00    	jle    2f5b <apply_rev_avx512_fma_auto_mv_seq_ALL+0x31b>
    2d45:	48 8b 44 24 78       	mov    0x78(%rsp),%rax
    2d4a:	44 8b 7c 24 5c       	mov    0x5c(%rsp),%r15d
    2d4f:	c7 44 24 20 00 00 00 	movl   $0x0,0x20(%rsp)
    2d56:	00 
    2d57:	48 8d 2c c5 00 00 00 	lea    0x0(,%rax,8),%rbp
    2d5e:	00 
    2d5f:	48 8b 84 24 80 00 00 	mov    0x80(%rsp),%rax
    2d66:	00 
    2d67:	48 89 44 24 28       	mov    %rax,0x28(%rsp)
    2d6c:	48 63 84 24 8c 00 00 	movslq 0x8c(%rsp),%rax
    2d73:	00 
    2d74:	4c 8d 2c c5 00 00 00 	lea    0x0(,%rax,8),%r13
    2d7b:	00 
    2d7c:	48 89 44 24 70       	mov    %rax,0x70(%rsp)
    2d81:	8b 44 24 50          	mov    0x50(%rsp),%eax
    2d85:	44 8d 60 f8          	lea    -0x8(%rax),%r12d
    2d89:	41 c1 ec 03          	shr    $0x3,%r12d
    2d8d:	41 ff c4             	inc    %r12d
    2d90:	49 c1 e4 06          	shl    $0x6,%r12
    2d94:	83 f8 07             	cmp    $0x7,%eax
    2d97:	b8 40 00 00 00       	mov    $0x40,%eax
    2d9c:	4c 0f 4e e0          	cmovle %rax,%r12
    2da0:	8b 44 24 1c          	mov    0x1c(%rsp),%eax
    2da4:	44 0f af f8          	imul   %eax,%r15d
    2da8:	4d 63 ff             	movslq %r15d,%r15
    2dab:	4a 8d 04 fd 00 00 00 	lea    0x0(,%r15,8),%rax
    2db2:	00 
    2db3:	48 89 44 24 60       	mov    %rax,0x60(%rsp)
    2db8:	85 db                	test   %ebx,%ebx
    2dba:	0f 8e 72 01 00 00    	jle    2f32 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x2f2>
    2dc0:	44 8b 44 24 50       	mov    0x50(%rsp),%r8d
    2dc5:	45 85 c0             	test   %r8d,%r8d
    2dc8:	0f 8e 64 01 00 00    	jle    2f32 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x2f2>
    2dce:	66 90                	xchg   %ax,%ax
    2dd0:	48 8b 7c 24 10       	mov    0x10(%rsp),%rdi
    2dd5:	4c 8b 74 24 28       	mov    0x28(%rsp),%r14
    2dda:	45 31 ff             	xor    %r15d,%r15d
    2ddd:	0f 1f 00             	nopl   (%rax)
    2de0:	4c 89 f6             	mov    %r14,%rsi
    2de3:	4c 89 e2             	mov    %r12,%rdx
    2de6:	e8 a5 e4 ff ff       	call   1290 <memcpy@plt>
    2deb:	41 ff c7             	inc    %r15d
    2dee:	4d 01 ee             	add    %r13,%r14
    2df1:	48 89 c7             	mov    %rax,%rdi
    2df4:	48 01 ef             	add    %rbp,%rdi
    2df7:	44 39 fb             	cmp    %r15d,%ebx
    2dfa:	75 e4                	jne    2de0 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x1a0>
    2dfc:	44 8b 54 24 18       	mov    0x18(%rsp),%r10d
    2e01:	45 85 d2             	test   %r10d,%r10d
    2e04:	0f 8e 94 00 00 00    	jle    2e9e <apply_rev_avx512_fma_auto_mv_seq_ALL+0x25e>
    2e0a:	4c 89 6c 24 38       	mov    %r13,0x38(%rsp)
    2e0f:	48 89 6c 24 30       	mov    %rbp,0x30(%rsp)
    2e14:	4c 8b 6c 24 60       	mov    0x60(%rsp),%r13
    2e19:	44 8b 74 24 58       	mov    0x58(%rsp),%r14d
    2e1e:	48 8b 6c 24 48       	mov    0x48(%rsp),%rbp
    2e23:	41 89 df             	mov    %ebx,%r15d
    2e26:	4c 89 64 24 40       	mov    %r12,0x40(%rsp)
    2e2b:	44 8b 4c 24 5c       	mov    0x5c(%rsp),%r9d
    2e30:	45 31 e4             	xor    %r12d,%r12d
    2e33:	44 89 e3             	mov    %r12d,%ebx
    2e36:	49 89 ec             	mov    %rbp,%r12
    2e39:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)
    2e40:	4c 8b 44 24 10       	mov    0x10(%rsp),%r8
    2e45:	31 c0                	xor    %eax,%eax
    2e47:	89 df                	mov    %ebx,%edi
    2e49:	48 89 e9             	mov    %rbp,%rcx
    2e4c:	44 89 fa             	mov    %r15d,%edx
    2e4f:	44 89 f6             	mov    %r14d,%esi
    2e52:	41 0f 18 0c 24       	prefetcht0 (%r12)
    2e57:	44 89 4c 24 08       	mov    %r9d,0x8(%rsp)
    2e5c:	4d 01 ec             	add    %r13,%r12
    2e5f:	e8 ec 20 00 00       	call   4f50 <apply_rev_avx_mv_seq_fma>
    2e64:	8b 44 24 1c          	mov    0x1c(%rsp),%eax
    2e68:	44 8b 4c 24 08       	mov    0x8(%rsp),%r9d
    2e6d:	01 c3                	add    %eax,%ebx
    2e6f:	39 5c 24 18          	cmp    %ebx,0x18(%rsp)
    2e73:	7f cb                	jg     2e40 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x200>
    2e75:	45 85 ff             	test   %r15d,%r15d
    2e78:	0f 8e c5 02 00 00    	jle    3143 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x503>
    2e7e:	44 8b 4c 24 50       	mov    0x50(%rsp),%r9d
    2e83:	4c 8b 6c 24 38       	mov    0x38(%rsp),%r13
    2e88:	4c 8b 64 24 40       	mov    0x40(%rsp),%r12
    2e8d:	44 89 fb             	mov    %r15d,%ebx
    2e90:	48 8b 6c 24 30       	mov    0x30(%rsp),%rbp
    2e95:	45 85 c9             	test   %r9d,%r9d
    2e98:	0f 8e a2 00 00 00    	jle    2f40 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x300>
    2e9e:	4c 8b 7c 24 10       	mov    0x10(%rsp),%r15
    2ea3:	48 8b 7c 24 28       	mov    0x28(%rsp),%rdi
    2ea8:	45 31 f6             	xor    %r14d,%r14d
    2eab:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)
    2eb0:	4c 89 fe             	mov    %r15,%rsi
    2eb3:	4c 89 e2             	mov    %r12,%rdx
    2eb6:	e8 d5 e3 ff ff       	call   1290 <memcpy@plt>
    2ebb:	41 ff c6             	inc    %r14d
    2ebe:	49 01 ef             	add    %rbp,%r15
    2ec1:	48 89 c7             	mov    %rax,%rdi
    2ec4:	4c 01 ef             	add    %r13,%rdi
    2ec7:	44 39 f3             	cmp    %r14d,%ebx
    2eca:	75 e4                	jne    2eb0 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x270>
    2ecc:	8b 4c 24 50          	mov    0x50(%rsp),%ecx
    2ed0:	48 01 6c 24 28       	add    %rbp,0x28(%rsp)
    2ed5:	01 4c 24 20          	add    %ecx,0x20(%rsp)
    2ed9:	8b 44 24 20          	mov    0x20(%rsp),%eax
    2edd:	39 44 24 54          	cmp    %eax,0x54(%rsp)
    2ee1:	0f 8f e9 fe ff ff    	jg     2dd0 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x190>
    2ee7:	48 8b 7c 24 10       	mov    0x10(%rsp),%rdi
    2eec:	e8 1f e3 ff ff       	call   1210 <free@plt>
    2ef1:	8b 84 24 88 00 00 00 	mov    0x88(%rsp),%eax
    2ef8:	85 c0                	test   %eax,%eax
    2efa:	0f 85 92 00 00 00    	jne    2f92 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x352>
    2f00:	48 8b 84 24 a8 00 00 	mov    0xa8(%rsp),%rax
    2f07:	00 
    2f08:	64 48 2b 04 25 28 00 	sub    %fs:0x28,%rax
    2f0f:	00 00 
    2f11:	0f 85 9b 02 00 00    	jne    31b2 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x572>
    2f17:	48 8b 7c 24 68       	mov    0x68(%rsp),%rdi
    2f1c:	48 81 c4 b8 00 00 00 	add    $0xb8,%rsp
    2f23:	5b                   	pop    %rbx
    2f24:	5d                   	pop    %rbp
    2f25:	41 5c                	pop    %r12
    2f27:	41 5d                	pop    %r13
    2f29:	41 5e                	pop    %r14
    2f2b:	41 5f                	pop    %r15
    2f2d:	e9 de e2 ff ff       	jmp    1210 <free@plt>
    2f32:	44 8b 5c 24 18       	mov    0x18(%rsp),%r11d
    2f37:	45 85 db             	test   %r11d,%r11d
    2f3a:	0f 8f ca fe ff ff    	jg     2e0a <apply_rev_avx512_fma_auto_mv_seq_ALL+0x1ca>
    2f40:	8b 4c 24 50          	mov    0x50(%rsp),%ecx
    2f44:	48 01 6c 24 28       	add    %rbp,0x28(%rsp)
    2f49:	01 4c 24 20          	add    %ecx,0x20(%rsp)
    2f4d:	8b 44 24 20          	mov    0x20(%rsp),%eax
    2f51:	39 44 24 54          	cmp    %eax,0x54(%rsp)
    2f55:	0f 8f 5d fe ff ff    	jg     2db8 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x178>
    2f5b:	48 8b 7c 24 10       	mov    0x10(%rsp),%rdi
    2f60:	e8 ab e2 ff ff       	call   1210 <free@plt>
    2f65:	8b b4 24 88 00 00 00 	mov    0x88(%rsp),%esi
    2f6c:	85 f6                	test   %esi,%esi
    2f6e:	74 90                	je     2f00 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x2c0>
    2f70:	85 db                	test   %ebx,%ebx
    2f72:	0f 8e 29 02 00 00    	jle    31a1 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x561>
    2f78:	48 8b 44 24 78       	mov    0x78(%rsp),%rax
    2f7d:	48 8d 2c c5 00 00 00 	lea    0x0(,%rax,8),%rbp
    2f84:	00 
    2f85:	48 63 84 24 8c 00 00 	movslq 0x8c(%rsp),%rax
    2f8c:	00 
    2f8d:	48 89 44 24 70       	mov    %rax,0x70(%rsp)
    2f92:	8b 8c 24 88 00 00 00 	mov    0x88(%rsp),%ecx
    2f99:	8b 44 24 50          	mov    0x50(%rsp),%eax
    2f9d:	48 8b 74 24 68       	mov    0x68(%rsp),%rsi
    2fa2:	29 c8                	sub    %ecx,%eax
    2fa4:	48 98                	cltq   
    2fa6:	48 c1 e0 03          	shl    $0x3,%rax
    2faa:	48 89 44 24 08       	mov    %rax,0x8(%rsp)
    2faf:	48 63 c1             	movslq %ecx,%rax
    2fb2:	48 c1 e0 03          	shl    $0x3,%rax
    2fb6:	4c 8d 3c 06          	lea    (%rsi,%rax,1),%r15
    2fba:	48 89 44 24 10       	mov    %rax,0x10(%rsp)
    2fbf:	48 8b 44 24 70       	mov    0x70(%rsp),%rax
    2fc4:	48 63 74 24 54       	movslq 0x54(%rsp),%rsi
    2fc9:	4c 8d 34 c5 00 00 00 	lea    0x0(,%rax,8),%r14
    2fd0:	00 
    2fd1:	48 8b 84 24 80 00 00 	mov    0x80(%rsp),%rax
    2fd8:	00 
    2fd9:	4c 8d 24 f0          	lea    (%rax,%rsi,8),%r12
    2fdd:	8d 41 ff             	lea    -0x1(%rcx),%eax
    2fe0:	89 c2                	mov    %eax,%edx
    2fe2:	c1 ea 03             	shr    $0x3,%edx
    2fe5:	ff c2                	inc    %edx
    2fe7:	48 c1 e2 06          	shl    $0x6,%rdx
    2feb:	48 89 54 24 20       	mov    %rdx,0x20(%rsp)
    2ff0:	85 c9                	test   %ecx,%ecx
    2ff2:	0f 8e 8c 01 00 00    	jle    3184 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x544>
    2ff8:	45 31 ed             	xor    %r13d,%r13d
    2ffb:	89 d9                	mov    %ebx,%ecx
    2ffd:	48 89 74 24 28       	mov    %rsi,0x28(%rsp)
    3002:	89 44 24 50          	mov    %eax,0x50(%rsp)
    3006:	44 89 eb             	mov    %r13d,%ebx
    3009:	4d 89 e5             	mov    %r12,%r13
    300c:	41 89 cc             	mov    %ecx,%r12d
    300f:	48 8b 44 24 10       	mov    0x10(%rsp),%rax
    3014:	48 8b 54 24 20       	mov    0x20(%rsp),%rdx
    3019:	4c 89 ff             	mov    %r15,%rdi
    301c:	4c 89 ee             	mov    %r13,%rsi
    301f:	ff c3                	inc    %ebx
    3021:	4d 01 f5             	add    %r14,%r13
    3024:	48 29 c7             	sub    %rax,%rdi
    3027:	e8 64 e2 ff ff       	call   1290 <memcpy@plt>
    302c:	48 8b 54 24 08       	mov    0x8(%rsp),%rdx
    3031:	4c 89 ff             	mov    %r15,%rdi
    3034:	31 f6                	xor    %esi,%esi
    3036:	49 01 ef             	add    %rbp,%r15
    3039:	e8 42 e1 ff ff       	call   1180 <memset@plt>
    303e:	41 39 dc             	cmp    %ebx,%r12d
    3041:	75 cc                	jne    300f <apply_rev_avx512_fma_auto_mv_seq_ALL+0x3cf>
    3043:	8b 54 24 18          	mov    0x18(%rsp),%edx
    3047:	48 8b 74 24 28       	mov    0x28(%rsp),%rsi
    304c:	44 89 e3             	mov    %r12d,%ebx
    304f:	8b 44 24 50          	mov    0x50(%rsp),%eax
    3053:	4c 8b 6c 24 70       	mov    0x70(%rsp),%r13
    3058:	85 d2                	test   %edx,%edx
    305a:	0f 8e 9a 00 00 00    	jle    30fa <apply_rev_avx512_fma_auto_mv_seq_ALL+0x4ba>
    3060:	44 8b 4c 24 5c       	mov    0x5c(%rsp),%r9d
    3065:	8b 44 24 1c          	mov    0x1c(%rsp),%eax
    3069:	4c 8b 6c 24 48       	mov    0x48(%rsp),%r13
    306e:	45 31 e4             	xor    %r12d,%r12d
    3071:	44 8b 74 24 18       	mov    0x18(%rsp),%r14d
    3076:	44 89 cd             	mov    %r9d,%ebp
    3079:	4d 89 ef             	mov    %r13,%r15
    307c:	45 89 e5             	mov    %r12d,%r13d
    307f:	41 89 c4             	mov    %eax,%r12d
    3082:	0f af e8             	imul   %eax,%ebp
    3085:	48 63 ed             	movslq %ebp,%rbp
    3088:	48 c1 e5 03          	shl    $0x3,%rbp
    308c:	41 0f 18 0f          	prefetcht0 (%r15)
    3090:	44 89 4c 24 08       	mov    %r9d,0x8(%rsp)
    3095:	4c 8b 44 24 68       	mov    0x68(%rsp),%r8
    309a:	48 8b 4c 24 48       	mov    0x48(%rsp),%rcx
    309f:	8b 74 24 58          	mov    0x58(%rsp),%esi
    30a3:	44 89 ef             	mov    %r13d,%edi
    30a6:	31 c0                	xor    %eax,%eax
    30a8:	89 da                	mov    %ebx,%edx
    30aa:	45 01 e5             	add    %r12d,%r13d
    30ad:	49 01 ef             	add    %rbp,%r15
    30b0:	e8 9b 1e 00 00       	call   4f50 <apply_rev_avx_mv_seq_fma>
    30b5:	45 39 ee             	cmp    %r13d,%r14d
    30b8:	44 8b 4c 24 08       	mov    0x8(%rsp),%r9d
    30bd:	7f cd                	jg     308c <apply_rev_avx512_fma_auto_mv_seq_ALL+0x44c>
    30bf:	85 db                	test   %ebx,%ebx
    30c1:	0f 8e 39 fe ff ff    	jle    2f00 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x2c0>
    30c7:	8b 84 24 88 00 00 00 	mov    0x88(%rsp),%eax
    30ce:	85 c0                	test   %eax,%eax
    30d0:	0f 8e 2a fe ff ff    	jle    2f00 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x2c0>
    30d6:	48 8b 4c 24 78       	mov    0x78(%rsp),%rcx
    30db:	48 63 74 24 54       	movslq 0x54(%rsp),%rsi
    30e0:	ff c8                	dec    %eax
    30e2:	48 8d 2c cd 00 00 00 	lea    0x0(,%rcx,8),%rbp
    30e9:	00 
    30ea:	48 63 8c 24 8c 00 00 	movslq 0x8c(%rsp),%rcx
    30f1:	00 
    30f2:	49 89 cd             	mov    %rcx,%r13
    30f5:	48 89 4c 24 70       	mov    %rcx,0x70(%rsp)
    30fa:	48 8b 8c 24 80 00 00 	mov    0x80(%rsp),%rcx
    3101:	00 
    3102:	4c 8b 7c 24 68       	mov    0x68(%rsp),%r15
    3107:	45 31 f6             	xor    %r14d,%r14d
    310a:	c1 e8 03             	shr    $0x3,%eax
    310d:	41 89 c4             	mov    %eax,%r12d
    3110:	41 ff c4             	inc    %r12d
    3113:	48 8d 0c f1          	lea    (%rcx,%rsi,8),%rcx
    3117:	49 c1 e5 03          	shl    $0x3,%r13
    311b:	49 c1 e4 06          	shl    $0x6,%r12
    311f:	4c 89 fe             	mov    %r15,%rsi
    3122:	48 89 cf             	mov    %rcx,%rdi
    3125:	4c 89 e2             	mov    %r12,%rdx
    3128:	41 ff c6             	inc    %r14d
    312b:	e8 60 e1 ff ff       	call   1290 <memcpy@plt>
    3130:	49 01 ef             	add    %rbp,%r15
    3133:	48 89 c1             	mov    %rax,%rcx
    3136:	4c 01 e9             	add    %r13,%rcx
    3139:	44 39 f3             	cmp    %r14d,%ebx
    313c:	75 e1                	jne    311f <apply_rev_avx512_fma_auto_mv_seq_ALL+0x4df>
    313e:	e9 bd fd ff ff       	jmp    2f00 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x2c0>
    3143:	8b 4c 24 50          	mov    0x50(%rsp),%ecx
    3147:	48 8b 74 24 30       	mov    0x30(%rsp),%rsi
    314c:	01 4c 24 20          	add    %ecx,0x20(%rsp)
    3150:	8b 44 24 20          	mov    0x20(%rsp),%eax
    3154:	48 01 74 24 28       	add    %rsi,0x28(%rsp)
    3159:	39 44 24 54          	cmp    %eax,0x54(%rsp)
    315d:	0f 8f c8 fc ff ff    	jg     2e2b <apply_rev_avx512_fma_auto_mv_seq_ALL+0x1eb>
    3163:	48 8b 7c 24 10       	mov    0x10(%rsp),%rdi
    3168:	44 89 fb             	mov    %r15d,%ebx
    316b:	e8 a0 e0 ff ff       	call   1210 <free@plt>
    3170:	8b bc 24 88 00 00 00 	mov    0x88(%rsp),%edi
    3177:	85 ff                	test   %edi,%edi
    3179:	0f 84 81 fd ff ff    	je     2f00 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x2c0>
    317f:	e9 dc fe ff ff       	jmp    3060 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x420>
    3184:	45 31 e4             	xor    %r12d,%r12d
    3187:	48 8b 54 24 08       	mov    0x8(%rsp),%rdx
    318c:	4c 89 ff             	mov    %r15,%rdi
    318f:	31 f6                	xor    %esi,%esi
    3191:	41 ff c4             	inc    %r12d
    3194:	49 01 ef             	add    %rbp,%r15
    3197:	e8 e4 df ff ff       	call   1180 <memset@plt>
    319c:	44 39 e3             	cmp    %r12d,%ebx
    319f:	75 e6                	jne    3187 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x547>
    31a1:	8b 4c 24 18          	mov    0x18(%rsp),%ecx
    31a5:	85 c9                	test   %ecx,%ecx
    31a7:	0f 8f b3 fe ff ff    	jg     3060 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x420>
    31ad:	e9 4e fd ff ff       	jmp    2f00 <apply_rev_avx512_fma_auto_mv_seq_ALL+0x2c0>
    31b2:	e8 a9 e0 ff ff       	call   1260 <__stack_chk_fail@plt>
    31b7:	66 0f 1f 84 00 00 00 	nopw   0x0(%rax,%rax,1)
    31be:	00 00 

00000000000031c0 <dmatrix_vector_multiply_mt_rev_avx512_fma_seq_ALL._omp_fn.0>:
    31c0:	f3 0f 1e fa          	endbr64 
    31c4:	41 55                	push   %r13
    31c6:	41 54                	push   %r12
    31c8:	55                   	push   %rbp
    31c9:	53                   	push   %rbx
    31ca:	48 89 fb             	mov    %rdi,%rbx
    31cd:	48 83 ec 08          	sub    $0x8,%rsp
    31d1:	8b 6f 14             	mov    0x14(%rdi),%ebp
    31d4:	44 8b 6f 28          	mov    0x28(%rdi),%r13d
    31d8:	e8 b3 df ff ff       	call   1190 <omp_get_num_threads@plt>
    31dd:	41 89 c4             	mov    %eax,%r12d
    31e0:	e8 1b e0 ff ff       	call   1200 <omp_get_thread_num@plt>
    31e5:	4c 8b 43 08          	mov    0x8(%rbx),%r8
    31e9:	4c 8b 1b             	mov    (%rbx),%r11
    31ec:	89 c1                	mov    %eax,%ecx
    31ee:	44 8b 53 18          	mov    0x18(%rbx),%r10d
    31f2:	8b 7b 10             	mov    0x10(%rbx),%edi
    31f5:	42 8d 44 25 ff       	lea    -0x1(%rbp,%r12,1),%eax
    31fa:	42 8d 34 ed 00 00 00 	lea    0x0(,%r13,8),%esi
    3201:	00 
    3202:	99                   	cltd   
    3203:	41 f7 fc             	idiv   %r12d
    3206:	8d 44 06 ff          	lea    -0x1(%rsi,%rax,1),%eax
    320a:	99                   	cltd   
    320b:	f7 fe                	idiv   %esi
    320d:	41 0f af c5          	imul   %r13d,%eax
    3211:	c1 e0 03             	shl    $0x3,%eax
    3214:	0f af c8             	imul   %eax,%ecx
    3217:	89 ca                	mov    %ecx,%edx
    3219:	39 cd                	cmp    %ecx,%ebp
    321b:	8d 34 10             	lea    (%rax,%rdx,1),%esi
    321e:	0f 4e cd             	cmovle %ebp,%ecx
    3221:	44 89 d2             	mov    %r10d,%edx
    3224:	39 ee                	cmp    %ebp,%esi
    3226:	4c 63 e1             	movslq %ecx,%r12
    3229:	0f 4f f5             	cmovg  %ebp,%esi
    322c:	48 83 ec 08          	sub    $0x8,%rsp
    3230:	4f 8d 04 e0          	lea    (%r8,%r12,8),%r8
    3234:	41 55                	push   %r13
    3236:	8b 43 24             	mov    0x24(%rbx),%eax
    3239:	29 ce                	sub    %ecx,%esi
    323b:	4c 89 d9             	mov    %r11,%rcx
    323e:	50                   	push   %rax
    323f:	8b 43 20             	mov    0x20(%rbx),%eax
    3242:	50                   	push   %rax
    3243:	44 8b 4b 1c          	mov    0x1c(%rbx),%r9d
    3247:	e8 f4 f9 ff ff       	call   2c40 <apply_rev_avx512_fma_auto_mv_seq_ALL>
    324c:	48 83 c4 28          	add    $0x28,%rsp
    3250:	5b                   	pop    %rbx
    3251:	5d                   	pop    %rbp
    3252:	41 5c                	pop    %r12
    3254:	41 5d                	pop    %r13
    3256:	c3                   	ret    
    3257:	66 0f 1f 84 00 00 00 	nopw   0x0(%rax,%rax,1)
    325e:	00 00 

0000000000003260 <apply_rev_avx512_auto_mv_seq_ALL>:
    3260:	f3 0f 1e fa          	endbr64 
    3264:	41 57                	push   %r15
    3266:	41 56                	push   %r14
    3268:	41 55                	push   %r13
    326a:	41 54                	push   %r12
    326c:	55                   	push   %rbp
    326d:	53                   	push   %rbx
    326e:	48 63 ea             	movslq %edx,%rbp
    3271:	48 81 ec b8 00 00 00 	sub    $0xb8,%rsp
    3278:	48 89 eb             	mov    %rbp,%rbx
    327b:	8b 84 24 f0 00 00 00 	mov    0xf0(%rsp),%eax
    3282:	48 89 4c 24 48       	mov    %rcx,0x48(%rsp)
    3287:	8b 8c 24 00 01 00 00 	mov    0x100(%rsp),%ecx
    328e:	89 7c 24 18          	mov    %edi,0x18(%rsp)
    3292:	89 74 24 58          	mov    %esi,0x58(%rsp)
    3296:	4c 89 84 24 80 00 00 	mov    %r8,0x80(%rsp)
    329d:	00 
    329e:	44 89 8c 24 8c 00 00 	mov    %r9d,0x8c(%rsp)
    32a5:	00 
    32a6:	48 8d bc 24 a0 00 00 	lea    0xa0(%rsp),%rdi
    32ad:	00 
    32ae:	89 44 24 5c          	mov    %eax,0x5c(%rsp)
    32b2:	8b 84 24 f8 00 00 00 	mov    0xf8(%rsp),%eax
    32b9:	8d 14 cd 00 00 00 00 	lea    0x0(,%rcx,8),%edx
    32c0:	89 44 24 1c          	mov    %eax,0x1c(%rsp)
    32c4:	64 48 8b 04 25 28 00 	mov    %fs:0x28,%rax
    32cb:	00 00 
    32cd:	48 89 84 24 a8 00 00 	mov    %rax,0xa8(%rsp)
    32d4:	00 
    32d5:	31 c0                	xor    %eax,%eax
    32d7:	89 54 24 50          	mov    %edx,0x50(%rsp)
    32db:	89 f0                	mov    %esi,%eax
    32dd:	89 d6                	mov    %edx,%esi
    32df:	99                   	cltd   
    32e0:	f7 fe                	idiv   %esi
    32e2:	0f af c1             	imul   %ecx,%eax
    32e5:	89 94 24 88 00 00 00 	mov    %edx,0x88(%rsp)
    32ec:	c1 e0 03             	shl    $0x3,%eax
    32ef:	89 44 24 54          	mov    %eax,0x54(%rsp)
    32f3:	48 63 c6             	movslq %esi,%rax
    32f6:	be 40 00 00 00       	mov    $0x40,%esi
    32fb:	48 0f af e8          	imul   %rax,%rbp
    32ff:	48 89 44 24 78       	mov    %rax,0x78(%rsp)
    3304:	48 c1 e5 03          	shl    $0x3,%rbp
    3308:	48 89 ea             	mov    %rbp,%rdx
    330b:	e8 90 de ff ff       	call   11a0 <posix_memalign@plt>
    3310:	48 c7 44 24 10 00 00 	movq   $0x0,0x10(%rsp)
    3317:	00 00 
    3319:	85 c0                	test   %eax,%eax
    331b:	75 0d                	jne    332a <apply_rev_avx512_auto_mv_seq_ALL+0xca>
    331d:	48 8b 84 24 a0 00 00 	mov    0xa0(%rsp),%rax
    3324:	00 
    3325:	48 89 44 24 10       	mov    %rax,0x10(%rsp)
    332a:	48 8d bc 24 98 00 00 	lea    0x98(%rsp),%rdi
    3331:	00 
    3332:	48 89 ea             	mov    %rbp,%rdx
    3335:	be 40 00 00 00       	mov    $0x40,%esi
    333a:	e8 61 de ff ff       	call   11a0 <posix_memalign@plt>
    333f:	48 c7 44 24 68 00 00 	movq   $0x0,0x68(%rsp)
    3346:	00 00 
    3348:	85 c0                	test   %eax,%eax
    334a:	75 0d                	jne    3359 <apply_rev_avx512_auto_mv_seq_ALL+0xf9>
    334c:	48 8b 84 24 98 00 00 	mov    0x98(%rsp),%rax
    3353:	00 
    3354:	48 89 44 24 68       	mov    %rax,0x68(%rsp)
    3359:	8b 6c 24 54          	mov    0x54(%rsp),%ebp
    335d:	85 ed                	test   %ebp,%ebp
    335f:	0f 8e 16 02 00 00    	jle    357b <apply_rev_avx512_auto_mv_seq_ALL+0x31b>
    3365:	48 8b 44 24 78       	mov    0x78(%rsp),%rax
    336a:	44 8b 7c 24 5c       	mov    0x5c(%rsp),%r15d
    336f:	c7 44 24 20 00 00 00 	movl   $0x0,0x20(%rsp)
    3376:	00 
    3377:	48 8d 2c c5 00 00 00 	lea    0x0(,%rax,8),%rbp
    337e:	00 
    337f:	48 8b 84 24 80 00 00 	mov    0x80(%rsp),%rax
    3386:	00 
    3387:	48 89 44 24 28       	mov    %rax,0x28(%rsp)
    338c:	48 63 84 24 8c 00 00 	movslq 0x8c(%rsp),%rax
    3393:	00 
    3394:	4c 8d 2c c5 00 00 00 	lea    0x0(,%rax,8),%r13
    339b:	00 
    339c:	48 89 44 24 70       	mov    %rax,0x70(%rsp)
    33a1:	8b 44 24 50          	mov    0x50(%rsp),%eax
    33a5:	44 8d 60 f8          	lea    -0x8(%rax),%r12d
    33a9:	41 c1 ec 03          	shr    $0x3,%r12d
    33ad:	41 ff c4             	inc    %r12d
    33b0:	49 c1 e4 06          	shl    $0x6,%r12
    33b4:	83 f8 07             	cmp    $0x7,%eax
    33b7:	b8 40 00 00 00       	mov    $0x40,%eax
    33bc:	4c 0f 4e e0          	cmovle %rax,%r12
    33c0:	8b 44 24 1c          	mov    0x1c(%rsp),%eax
    33c4:	44 0f af f8          	imul   %eax,%r15d
    33c8:	4d 63 ff             	movslq %r15d,%r15
    33cb:	4a 8d 04 fd 00 00 00 	lea    0x0(,%r15,8),%rax
    33d2:	00 
    33d3:	48 89 44 24 60       	mov    %rax,0x60(%rsp)
    33d8:	85 db                	test   %ebx,%ebx
    33da:	0f 8e 72 01 00 00    	jle    3552 <apply_rev_avx512_auto_mv_seq_ALL+0x2f2>
    33e0:	44 8b 44 24 50       	mov    0x50(%rsp),%r8d
    33e5:	45 85 c0             	test   %r8d,%r8d
    33e8:	0f 8e 64 01 00 00    	jle    3552 <apply_rev_avx512_auto_mv_seq_ALL+0x2f2>
    33ee:	66 90                	xchg   %ax,%ax
    33f0:	48 8b 7c 24 10       	mov    0x10(%rsp),%rdi
    33f5:	4c 8b 74 24 28       	mov    0x28(%rsp),%r14
    33fa:	45 31 ff             	xor    %r15d,%r15d
    33fd:	0f 1f 00             	nopl   (%rax)
    3400:	4c 89 f6             	mov    %r14,%rsi
    3403:	4c 89 e2             	mov    %r12,%rdx
    3406:	e8 85 de ff ff       	call   1290 <memcpy@plt>
    340b:	41 ff c7             	inc    %r15d
    340e:	4d 01 ee             	add    %r13,%r14
    3411:	48 89 c7             	mov    %rax,%rdi
    3414:	48 01 ef             	add    %rbp,%rdi
    3417:	44 39 fb             	cmp    %r15d,%ebx
    341a:	75 e4                	jne    3400 <apply_rev_avx512_auto_mv_seq_ALL+0x1a0>
    341c:	44 8b 54 24 18       	mov    0x18(%rsp),%r10d
    3421:	45 85 d2             	test   %r10d,%r10d
    3424:	0f 8e 94 00 00 00    	jle    34be <apply_rev_avx512_auto_mv_seq_ALL+0x25e>
    342a:	4c 89 6c 24 38       	mov    %r13,0x38(%rsp)
    342f:	48 89 6c 24 30       	mov    %rbp,0x30(%rsp)
    3434:	4c 8b 6c 24 60       	mov    0x60(%rsp),%r13
    3439:	44 8b 74 24 58       	mov    0x58(%rsp),%r14d
    343e:	48 8b 6c 24 48       	mov    0x48(%rsp),%rbp
    3443:	41 89 df             	mov    %ebx,%r15d
    3446:	4c 89 64 24 40       	mov    %r12,0x40(%rsp)
    344b:	44 8b 4c 24 5c       	mov    0x5c(%rsp),%r9d
    3450:	45 31 e4             	xor    %r12d,%r12d
    3453:	44 89 e3             	mov    %r12d,%ebx
    3456:	49 89 ec             	mov    %rbp,%r12
    3459:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)
    3460:	4c 8b 44 24 10       	mov    0x10(%rsp),%r8
    3465:	31 c0                	xor    %eax,%eax
    3467:	89 df                	mov    %ebx,%edi
    3469:	48 89 e9             	mov    %rbp,%rcx
    346c:	44 89 fa             	mov    %r15d,%edx
    346f:	44 89 f6             	mov    %r14d,%esi
    3472:	41 0f 18 0c 24       	prefetcht0 (%r12)
    3477:	44 89 4c 24 08       	mov    %r9d,0x8(%rsp)
    347c:	4d 01 ec             	add    %r13,%r12
    347f:	e8 8c 17 00 00       	call   4c10 <apply_rev_avx_mv_seq>
    3484:	8b 44 24 1c          	mov    0x1c(%rsp),%eax
    3488:	44 8b 4c 24 08       	mov    0x8(%rsp),%r9d
    348d:	01 c3                	add    %eax,%ebx
    348f:	39 5c 24 18          	cmp    %ebx,0x18(%rsp)
    3493:	7f cb                	jg     3460 <apply_rev_avx512_auto_mv_seq_ALL+0x200>
    3495:	45 85 ff             	test   %r15d,%r15d
    3498:	0f 8e c5 02 00 00    	jle    3763 <apply_rev_avx512_auto_mv_seq_ALL+0x503>
    349e:	44 8b 4c 24 50       	mov    0x50(%rsp),%r9d
    34a3:	4c 8b 6c 24 38       	mov    0x38(%rsp),%r13
    34a8:	4c 8b 64 24 40       	mov    0x40(%rsp),%r12
    34ad:	44 89 fb             	mov    %r15d,%ebx
    34b0:	48 8b 6c 24 30       	mov    0x30(%rsp),%rbp
    34b5:	45 85 c9             	test   %r9d,%r9d
    34b8:	0f 8e a2 00 00 00    	jle    3560 <apply_rev_avx512_auto_mv_seq_ALL+0x300>
    34be:	4c 8b 7c 24 10       	mov    0x10(%rsp),%r15
    34c3:	48 8b 7c 24 28       	mov    0x28(%rsp),%rdi
    34c8:	45 31 f6             	xor    %r14d,%r14d
    34cb:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)
    34d0:	4c 89 fe             	mov    %r15,%rsi
    34d3:	4c 89 e2             	mov    %r12,%rdx
    34d6:	e8 b5 dd ff ff       	call   1290 <memcpy@plt>
    34db:	41 ff c6             	inc    %r14d
    34de:	49 01 ef             	add    %rbp,%r15
    34e1:	48 89 c7             	mov    %rax,%rdi
    34e4:	4c 01 ef             	add    %r13,%rdi
    34e7:	44 39 f3             	cmp    %r14d,%ebx
    34ea:	75 e4                	jne    34d0 <apply_rev_avx512_auto_mv_seq_ALL+0x270>
    34ec:	8b 4c 24 50          	mov    0x50(%rsp),%ecx
    34f0:	48 01 6c 24 28       	add    %rbp,0x28(%rsp)
    34f5:	01 4c 24 20          	add    %ecx,0x20(%rsp)
    34f9:	8b 44 24 20          	mov    0x20(%rsp),%eax
    34fd:	39 44 24 54          	cmp    %eax,0x54(%rsp)
    3501:	0f 8f e9 fe ff ff    	jg     33f0 <apply_rev_avx512_auto_mv_seq_ALL+0x190>
    3507:	48 8b 7c 24 10       	mov    0x10(%rsp),%rdi
    350c:	e8 ff dc ff ff       	call   1210 <free@plt>
    3511:	8b 84 24 88 00 00 00 	mov    0x88(%rsp),%eax
    3518:	85 c0                	test   %eax,%eax
    351a:	0f 85 92 00 00 00    	jne    35b2 <apply_rev_avx512_auto_mv_seq_ALL+0x352>
    3520:	48 8b 84 24 a8 00 00 	mov    0xa8(%rsp),%rax
    3527:	00 
    3528:	64 48 2b 04 25 28 00 	sub    %fs:0x28,%rax
    352f:	00 00 
    3531:	0f 85 9b 02 00 00    	jne    37d2 <apply_rev_avx512_auto_mv_seq_ALL+0x572>
    3537:	48 8b 7c 24 68       	mov    0x68(%rsp),%rdi
    353c:	48 81 c4 b8 00 00 00 	add    $0xb8,%rsp
    3543:	5b                   	pop    %rbx
    3544:	5d                   	pop    %rbp
    3545:	41 5c                	pop    %r12
    3547:	41 5d                	pop    %r13
    3549:	41 5e                	pop    %r14
    354b:	41 5f                	pop    %r15
    354d:	e9 be dc ff ff       	jmp    1210 <free@plt>
    3552:	44 8b 5c 24 18       	mov    0x18(%rsp),%r11d
    3557:	45 85 db             	test   %r11d,%r11d
    355a:	0f 8f ca fe ff ff    	jg     342a <apply_rev_avx512_auto_mv_seq_ALL+0x1ca>
    3560:	8b 4c 24 50          	mov    0x50(%rsp),%ecx
    3564:	48 01 6c 24 28       	add    %rbp,0x28(%rsp)
    3569:	01 4c 24 20          	add    %ecx,0x20(%rsp)
    356d:	8b 44 24 20          	mov    0x20(%rsp),%eax
    3571:	39 44 24 54          	cmp    %eax,0x54(%rsp)
    3575:	0f 8f 5d fe ff ff    	jg     33d8 <apply_rev_avx512_auto_mv_seq_ALL+0x178>
    357b:	48 8b 7c 24 10       	mov    0x10(%rsp),%rdi
    3580:	e8 8b dc ff ff       	call   1210 <free@plt>
    3585:	8b b4 24 88 00 00 00 	mov    0x88(%rsp),%esi
    358c:	85 f6                	test   %esi,%esi
    358e:	74 90                	je     3520 <apply_rev_avx512_auto_mv_seq_ALL+0x2c0>
    3590:	85 db                	test   %ebx,%ebx
    3592:	0f 8e 29 02 00 00    	jle    37c1 <apply_rev_avx512_auto_mv_seq_ALL+0x561>
    3598:	48 8b 44 24 78       	mov    0x78(%rsp),%rax
    359d:	48 8d 2c c5 00 00 00 	lea    0x0(,%rax,8),%rbp
    35a4:	00 
    35a5:	48 63 84 24 8c 00 00 	movslq 0x8c(%rsp),%rax
    35ac:	00 
    35ad:	48 89 44 24 70       	mov    %rax,0x70(%rsp)
    35b2:	8b 8c 24 88 00 00 00 	mov    0x88(%rsp),%ecx
    35b9:	8b 44 24 50          	mov    0x50(%rsp),%eax
    35bd:	48 8b 74 24 68       	mov    0x68(%rsp),%rsi
    35c2:	29 c8                	sub    %ecx,%eax
    35c4:	48 98                	cltq   
    35c6:	48 c1 e0 03          	shl    $0x3,%rax
    35ca:	48 89 44 24 08       	mov    %rax,0x8(%rsp)
    35cf:	48 63 c1             	movslq %ecx,%rax
    35d2:	48 c1 e0 03          	shl    $0x3,%rax
    35d6:	4c 8d 3c 06          	lea    (%rsi,%rax,1),%r15
    35da:	48 89 44 24 10       	mov    %rax,0x10(%rsp)
    35df:	48 8b 44 24 70       	mov    0x70(%rsp),%rax
    35e4:	48 63 74 24 54       	movslq 0x54(%rsp),%rsi
    35e9:	4c 8d 34 c5 00 00 00 	lea    0x0(,%rax,8),%r14
    35f0:	00 
    35f1:	48 8b 84 24 80 00 00 	mov    0x80(%rsp),%rax
    35f8:	00 
    35f9:	4c 8d 24 f0          	lea    (%rax,%rsi,8),%r12
    35fd:	8d 41 ff             	lea    -0x1(%rcx),%eax
    3600:	89 c2                	mov    %eax,%edx
    3602:	c1 ea 03             	shr    $0x3,%edx
    3605:	ff c2                	inc    %edx
    3607:	48 c1 e2 06          	shl    $0x6,%rdx
    360b:	48 89 54 24 20       	mov    %rdx,0x20(%rsp)
    3610:	85 c9                	test   %ecx,%ecx
    3612:	0f 8e 8c 01 00 00    	jle    37a4 <apply_rev_avx512_auto_mv_seq_ALL+0x544>
    3618:	45 31 ed             	xor    %r13d,%r13d
    361b:	89 d9                	mov    %ebx,%ecx
    361d:	48 89 74 24 28       	mov    %rsi,0x28(%rsp)
    3622:	89 44 24 50          	mov    %eax,0x50(%rsp)
    3626:	44 89 eb             	mov    %r13d,%ebx
    3629:	4d 89 e5             	mov    %r12,%r13
    362c:	41 89 cc             	mov    %ecx,%r12d
    362f:	48 8b 44 24 10       	mov    0x10(%rsp),%rax
    3634:	48 8b 54 24 20       	mov    0x20(%rsp),%rdx
    3639:	4c 89 ff             	mov    %r15,%rdi
    363c:	4c 89 ee             	mov    %r13,%rsi
    363f:	ff c3                	inc    %ebx
    3641:	4d 01 f5             	add    %r14,%r13
    3644:	48 29 c7             	sub    %rax,%rdi
    3647:	e8 44 dc ff ff       	call   1290 <memcpy@plt>
    364c:	48 8b 54 24 08       	mov    0x8(%rsp),%rdx
    3651:	4c 89 ff             	mov    %r15,%rdi
    3654:	31 f6                	xor    %esi,%esi
    3656:	49 01 ef             	add    %rbp,%r15
    3659:	e8 22 db ff ff       	call   1180 <memset@plt>
    365e:	41 39 dc             	cmp    %ebx,%r12d
    3661:	75 cc                	jne    362f <apply_rev_avx512_auto_mv_seq_ALL+0x3cf>
    3663:	8b 54 24 18          	mov    0x18(%rsp),%edx
    3667:	48 8b 74 24 28       	mov    0x28(%rsp),%rsi
    366c:	44 89 e3             	mov    %r12d,%ebx
    366f:	8b 44 24 50          	mov    0x50(%rsp),%eax
    3673:	4c 8b 6c 24 70       	mov    0x70(%rsp),%r13
    3678:	85 d2                	test   %edx,%edx
    367a:	0f 8e 9a 00 00 00    	jle    371a <apply_rev_avx512_auto_mv_seq_ALL+0x4ba>
    3680:	44 8b 4c 24 5c       	mov    0x5c(%rsp),%r9d
    3685:	8b 44 24 1c          	mov    0x1c(%rsp),%eax
    3689:	4c 8b 6c 24 48       	mov    0x48(%rsp),%r13
    368e:	45 31 e4             	xor    %r12d,%r12d
    3691:	44 8b 74 24 18       	mov    0x18(%rsp),%r14d
    3696:	44 89 cd             	mov    %r9d,%ebp
    3699:	4d 89 ef             	mov    %r13,%r15
    369c:	45 89 e5             	mov    %r12d,%r13d
    369f:	41 89 c4             	mov    %eax,%r12d
    36a2:	0f af e8             	imul   %eax,%ebp
    36a5:	48 63 ed             	movslq %ebp,%rbp
    36a8:	48 c1 e5 03          	shl    $0x3,%rbp
    36ac:	41 0f 18 0f          	prefetcht0 (%r15)
    36b0:	44 89 4c 24 08       	mov    %r9d,0x8(%rsp)
    36b5:	4c 8b 44 24 68       	mov    0x68(%rsp),%r8
    36ba:	48 8b 4c 24 48       	mov    0x48(%rsp),%rcx
    36bf:	8b 74 24 58          	mov    0x58(%rsp),%esi
    36c3:	44 89 ef             	mov    %r13d,%edi
    36c6:	31 c0                	xor    %eax,%eax
    36c8:	89 da                	mov    %ebx,%edx
    36ca:	45 01 e5             	add    %r12d,%r13d
    36cd:	49 01 ef             	add    %rbp,%r15
    36d0:	e8 3b 15 00 00       	call   4c10 <apply_rev_avx_mv_seq>
    36d5:	45 39 ee             	cmp    %r13d,%r14d
    36d8:	44 8b 4c 24 08       	mov    0x8(%rsp),%r9d
    36dd:	7f cd                	jg     36ac <apply_rev_avx512_auto_mv_seq_ALL+0x44c>
    36df:	85 db                	test   %ebx,%ebx
    36e1:	0f 8e 39 fe ff ff    	jle    3520 <apply_rev_avx512_auto_mv_seq_ALL+0x2c0>
    36e7:	8b 84 24 88 00 00 00 	mov    0x88(%rsp),%eax
    36ee:	85 c0                	test   %eax,%eax
    36f0:	0f 8e 2a fe ff ff    	jle    3520 <apply_rev_avx512_auto_mv_seq_ALL+0x2c0>
    36f6:	48 8b 4c 24 78       	mov    0x78(%rsp),%rcx
    36fb:	48 63 74 24 54       	movslq 0x54(%rsp),%rsi
    3700:	ff c8                	dec    %eax
    3702:	48 8d 2c cd 00 00 00 	lea    0x0(,%rcx,8),%rbp
    3709:	00 
    370a:	48 63 8c 24 8c 00 00 	movslq 0x8c(%rsp),%rcx
    3711:	00 
    3712:	49 89 cd             	mov    %rcx,%r13
    3715:	48 89 4c 24 70       	mov    %rcx,0x70(%rsp)
    371a:	48 8b 8c 24 80 00 00 	mov    0x80(%rsp),%rcx
    3721:	00 
    3722:	4c 8b 7c 24 68       	mov    0x68(%rsp),%r15
    3727:	45 31 f6             	xor    %r14d,%r14d
    372a:	c1 e8 03             	shr    $0x3,%eax
    372d:	41 89 c4             	mov    %eax,%r12d
    3730:	41 ff c4             	inc    %r12d
    3733:	48 8d 0c f1          	lea    (%rcx,%rsi,8),%rcx
    3737:	49 c1 e5 03          	shl    $0x3,%r13
    373b:	49 c1 e4 06          	shl    $0x6,%r12
    373f:	4c 89 fe             	mov    %r15,%rsi
    3742:	48 89 cf             	mov    %rcx,%rdi
    3745:	4c 89 e2             	mov    %r12,%rdx
    3748:	41 ff c6             	inc    %r14d
    374b:	e8 40 db ff ff       	call   1290 <memcpy@plt>
    3750:	49 01 ef             	add    %rbp,%r15
    3753:	48 89 c1             	mov    %rax,%rcx
    3756:	4c 01 e9             	add    %r13,%rcx
    3759:	44 39 f3             	cmp    %r14d,%ebx
    375c:	75 e1                	jne    373f <apply_rev_avx512_auto_mv_seq_ALL+0x4df>
    375e:	e9 bd fd ff ff       	jmp    3520 <apply_rev_avx512_auto_mv_seq_ALL+0x2c0>
    3763:	8b 4c 24 50          	mov    0x50(%rsp),%ecx
    3767:	48 8b 74 24 30       	mov    0x30(%rsp),%rsi
    376c:	01 4c 24 20          	add    %ecx,0x20(%rsp)
    3770:	8b 44 24 20          	mov    0x20(%rsp),%eax
    3774:	48 01 74 24 28       	add    %rsi,0x28(%rsp)
    3779:	39 44 24 54          	cmp    %eax,0x54(%rsp)
    377d:	0f 8f c8 fc ff ff    	jg     344b <apply_rev_avx512_auto_mv_seq_ALL+0x1eb>
    3783:	48 8b 7c 24 10       	mov    0x10(%rsp),%rdi
    3788:	44 89 fb             	mov    %r15d,%ebx
    378b:	e8 80 da ff ff       	call   1210 <free@plt>
    3790:	8b bc 24 88 00 00 00 	mov    0x88(%rsp),%edi
    3797:	85 ff                	test   %edi,%edi
    3799:	0f 84 81 fd ff ff    	je     3520 <apply_rev_avx512_auto_mv_seq_ALL+0x2c0>
    379f:	e9 dc fe ff ff       	jmp    3680 <apply_rev_avx512_auto_mv_seq_ALL+0x420>
    37a4:	45 31 e4             	xor    %r12d,%r12d
    37a7:	48 8b 54 24 08       	mov    0x8(%rsp),%rdx
    37ac:	4c 89 ff             	mov    %r15,%rdi
    37af:	31 f6                	xor    %esi,%esi
    37b1:	41 ff c4             	inc    %r12d
    37b4:	49 01 ef             	add    %rbp,%r15
    37b7:	e8 c4 d9 ff ff       	call   1180 <memset@plt>
    37bc:	44 39 e3             	cmp    %r12d,%ebx
    37bf:	75 e6                	jne    37a7 <apply_rev_avx512_auto_mv_seq_ALL+0x547>
    37c1:	8b 4c 24 18          	mov    0x18(%rsp),%ecx
    37c5:	85 c9                	test   %ecx,%ecx
    37c7:	0f 8f b3 fe ff ff    	jg     3680 <apply_rev_avx512_auto_mv_seq_ALL+0x420>
    37cd:	e9 4e fd ff ff       	jmp    3520 <apply_rev_avx512_auto_mv_seq_ALL+0x2c0>
    37d2:	e8 89 da ff ff       	call   1260 <__stack_chk_fail@plt>
    37d7:	66 0f 1f 84 00 00 00 	nopw   0x0(%rax,%rax,1)
    37de:	00 00 

00000000000037e0 <dmatrix_vector_multiply_mt_rev_avx512_seq_ALL._omp_fn.0>:
    37e0:	f3 0f 1e fa          	endbr64 
    37e4:	41 55                	push   %r13
    37e6:	41 54                	push   %r12
    37e8:	55                   	push   %rbp
    37e9:	53                   	push   %rbx
    37ea:	48 89 fb             	mov    %rdi,%rbx
    37ed:	48 83 ec 08          	sub    $0x8,%rsp
    37f1:	8b 6f 14             	mov    0x14(%rdi),%ebp
    37f4:	44 8b 6f 28          	mov    0x28(%rdi),%r13d
    37f8:	e8 93 d9 ff ff       	call   1190 <omp_get_num_threads@plt>
    37fd:	41 89 c4             	mov    %eax,%r12d
    3800:	e8 fb d9 ff ff       	call   1200 <omp_get_thread_num@plt>
    3805:	4c 8b 43 08          	mov    0x8(%rbx),%r8
    3809:	4c 8b 1b             	mov    (%rbx),%r11
    380c:	89 c1                	mov    %eax,%ecx
    380e:	44 8b 53 18          	mov    0x18(%rbx),%r10d
    3812:	8b 7b 10             	mov    0x10(%rbx),%edi
    3815:	42 8d 44 25 ff       	lea    -0x1(%rbp,%r12,1),%eax
    381a:	42 8d 34 ed 00 00 00 	lea    0x0(,%r13,8),%esi
    3821:	00 
    3822:	99                   	cltd   
    3823:	41 f7 fc             	idiv   %r12d
    3826:	8d 44 06 ff          	lea    -0x1(%rsi,%rax,1),%eax
    382a:	99                   	cltd   
    382b:	f7 fe                	idiv   %esi
    382d:	41 0f af c5          	imul   %r13d,%eax
    3831:	c1 e0 03             	shl    $0x3,%eax
    3834:	0f af c8             	imul   %eax,%ecx
    3837:	89 ca                	mov    %ecx,%edx
    3839:	39 cd                	cmp    %ecx,%ebp
    383b:	8d 34 10             	lea    (%rax,%rdx,1),%esi
    383e:	0f 4e cd             	cmovle %ebp,%ecx
    3841:	44 89 d2             	mov    %r10d,%edx
    3844:	39 ee                	cmp    %ebp,%esi
    3846:	4c 63 e1             	movslq %ecx,%r12
    3849:	0f 4f f5             	cmovg  %ebp,%esi
    384c:	48 83 ec 08          	sub    $0x8,%rsp
    3850:	4f 8d 04 e0          	lea    (%r8,%r12,8),%r8
    3854:	41 55                	push   %r13
    3856:	8b 43 24             	mov    0x24(%rbx),%eax
    3859:	29 ce                	sub    %ecx,%esi
    385b:	4c 89 d9             	mov    %r11,%rcx
    385e:	50                   	push   %rax
    385f:	8b 43 20             	mov    0x20(%rbx),%eax
    3862:	50                   	push   %rax
    3863:	44 8b 4b 1c          	mov    0x1c(%rbx),%r9d
    3867:	e8 f4 f9 ff ff       	call   3260 <apply_rev_avx512_auto_mv_seq_ALL>
    386c:	48 83 c4 28          	add    $0x28,%rsp
    3870:	5b                   	pop    %rbx
    3871:	5d                   	pop    %rbp
    3872:	41 5c                	pop    %r12
    3874:	41 5d                	pop    %r13
    3876:	c3                   	ret    
    3877:	66 0f 1f 84 00 00 00 	nopw   0x0(%rax,%rax,1)
    387e:	00 00 

0000000000003880 <apply_rev_avx256_auto_mv_seq_ALL>:
    3880:	f3 0f 1e fa          	endbr64 
    3884:	41 57                	push   %r15
    3886:	41 56                	push   %r14
    3888:	41 55                	push   %r13
    388a:	41 54                	push   %r12
    388c:	55                   	push   %rbp
    388d:	53                   	push   %rbx
    388e:	48 63 ea             	movslq %edx,%rbp
    3891:	48 81 ec b8 00 00 00 	sub    $0xb8,%rsp
    3898:	48 89 eb             	mov    %rbp,%rbx
    389b:	8b 84 24 f0 00 00 00 	mov    0xf0(%rsp),%eax
    38a2:	48 89 4c 24 48       	mov    %rcx,0x48(%rsp)
    38a7:	8b 8c 24 00 01 00 00 	mov    0x100(%rsp),%ecx
    38ae:	89 7c 24 1c          	mov    %edi,0x1c(%rsp)
    38b2:	89 74 24 58          	mov    %esi,0x58(%rsp)
    38b6:	4c 89 84 24 80 00 00 	mov    %r8,0x80(%rsp)
    38bd:	00 
    38be:	44 89 8c 24 8c 00 00 	mov    %r9d,0x8c(%rsp)
    38c5:	00 
    38c6:	48 8d bc 24 a0 00 00 	lea    0xa0(%rsp),%rdi
    38cd:	00 
    38ce:	89 44 24 5c          	mov    %eax,0x5c(%rsp)
    38d2:	8b 84 24 f8 00 00 00 	mov    0xf8(%rsp),%eax
    38d9:	44 8d 34 8d 00 00 00 	lea    0x0(,%rcx,4),%r14d
    38e0:	00 
    38e1:	89 44 24 28          	mov    %eax,0x28(%rsp)
    38e5:	64 48 8b 04 25 28 00 	mov    %fs:0x28,%rax
    38ec:	00 00 
    38ee:	48 89 84 24 a8 00 00 	mov    %rax,0xa8(%rsp)
    38f5:	00 
    38f6:	31 c0                	xor    %eax,%eax
    38f8:	89 f0                	mov    %esi,%eax
    38fa:	be 40 00 00 00       	mov    $0x40,%esi
    38ff:	99                   	cltd   
    3900:	41 f7 fe             	idiv   %r14d
    3903:	0f af c1             	imul   %ecx,%eax
    3906:	89 94 24 88 00 00 00 	mov    %edx,0x88(%rsp)
    390d:	c1 e0 02             	shl    $0x2,%eax
    3910:	89 44 24 54          	mov    %eax,0x54(%rsp)
    3914:	49 63 c6             	movslq %r14d,%rax
    3917:	48 0f af e8          	imul   %rax,%rbp
    391b:	48 89 44 24 78       	mov    %rax,0x78(%rsp)
    3920:	48 c1 e5 03          	shl    $0x3,%rbp
    3924:	48 89 ea             	mov    %rbp,%rdx
    3927:	e8 74 d8 ff ff       	call   11a0 <posix_memalign@plt>
    392c:	48 c7 44 24 10 00 00 	movq   $0x0,0x10(%rsp)
    3933:	00 00 
    3935:	85 c0                	test   %eax,%eax
    3937:	75 0d                	jne    3946 <apply_rev_avx256_auto_mv_seq_ALL+0xc6>
    3939:	48 8b 84 24 a0 00 00 	mov    0xa0(%rsp),%rax
    3940:	00 
    3941:	48 89 44 24 10       	mov    %rax,0x10(%rsp)
    3946:	48 8d bc 24 98 00 00 	lea    0x98(%rsp),%rdi
    394d:	00 
    394e:	48 89 ea             	mov    %rbp,%rdx
    3951:	be 40 00 00 00       	mov    $0x40,%esi
    3956:	e8 45 d8 ff ff       	call   11a0 <posix_memalign@plt>
    395b:	48 c7 44 24 68 00 00 	movq   $0x0,0x68(%rsp)
    3962:	00 00 
    3964:	85 c0                	test   %eax,%eax
    3966:	75 0d                	jne    3975 <apply_rev_avx256_auto_mv_seq_ALL+0xf5>
    3968:	48 8b 84 24 98 00 00 	mov    0x98(%rsp),%rax
    396f:	00 
    3970:	48 89 44 24 68       	mov    %rax,0x68(%rsp)
    3975:	44 8b 7c 24 54       	mov    0x54(%rsp),%r15d
    397a:	45 85 ff             	test   %r15d,%r15d
    397d:	0f 8e 17 02 00 00    	jle    3b9a <apply_rev_avx256_auto_mv_seq_ALL+0x31a>
    3983:	48 8b 44 24 78       	mov    0x78(%rsp),%rax
    3988:	45 8d 6e fc          	lea    -0x4(%r14),%r13d
    398c:	8b 4c 24 28          	mov    0x28(%rsp),%ecx
    3990:	c7 44 24 2c 00 00 00 	movl   $0x0,0x2c(%rsp)
    3997:	00 
    3998:	41 c1 ed 02          	shr    $0x2,%r13d
    399c:	41 ff c5             	inc    %r13d
    399f:	48 8d 2c c5 00 00 00 	lea    0x0(,%rax,8),%rbp
    39a6:	00 
    39a7:	48 8b 84 24 80 00 00 	mov    0x80(%rsp),%rax
    39ae:	00 
    39af:	49 c1 e5 05          	shl    $0x5,%r13
    39b3:	41 83 fe 03          	cmp    $0x3,%r14d
    39b7:	48 89 44 24 30       	mov    %rax,0x30(%rsp)
    39bc:	48 63 84 24 8c 00 00 	movslq 0x8c(%rsp),%rax
    39c3:	00 
    39c4:	4c 8d 24 c5 00 00 00 	lea    0x0(,%rax,8),%r12
    39cb:	00 
    39cc:	48 89 44 24 70       	mov    %rax,0x70(%rsp)
    39d1:	b8 20 00 00 00       	mov    $0x20,%eax
    39d6:	49 0f 4f c5          	cmovg  %r13,%rax
    39da:	48 89 44 24 20       	mov    %rax,0x20(%rsp)
    39df:	8b 44 24 5c          	mov    0x5c(%rsp),%eax
    39e3:	0f af c1             	imul   %ecx,%eax
    39e6:	48 98                	cltq   
    39e8:	48 c1 e0 03          	shl    $0x3,%rax
    39ec:	48 89 44 24 60       	mov    %rax,0x60(%rsp)
    39f1:	85 db                	test   %ebx,%ebx
    39f3:	0f 8e 7b 01 00 00    	jle    3b74 <apply_rev_avx256_auto_mv_seq_ALL+0x2f4>
    39f9:	48 8b 7c 24 10       	mov    0x10(%rsp),%rdi
    39fe:	4c 8b 7c 24 30       	mov    0x30(%rsp),%r15
    3a03:	45 31 ed             	xor    %r13d,%r13d
    3a06:	66 2e 0f 1f 84 00 00 	cs nopw 0x0(%rax,%rax,1)
    3a0d:	00 00 00 
    3a10:	41 0f 18 0f          	prefetcht0 (%r15)
    3a14:	45 85 f6             	test   %r14d,%r14d
    3a17:	7e 10                	jle    3a29 <apply_rev_avx256_auto_mv_seq_ALL+0x1a9>
    3a19:	48 8b 54 24 20       	mov    0x20(%rsp),%rdx
    3a1e:	4c 89 fe             	mov    %r15,%rsi
    3a21:	e8 6a d8 ff ff       	call   1290 <memcpy@plt>
    3a26:	48 89 c7             	mov    %rax,%rdi
    3a29:	41 ff c5             	inc    %r13d
    3a2c:	4d 01 e7             	add    %r12,%r15
    3a2f:	48 01 ef             	add    %rbp,%rdi
    3a32:	44 39 eb             	cmp    %r13d,%ebx
    3a35:	75 d9                	jne    3a10 <apply_rev_avx256_auto_mv_seq_ALL+0x190>
    3a37:	44 8b 5c 24 1c       	mov    0x1c(%rsp),%r11d
    3a3c:	45 85 db             	test   %r11d,%r11d
    3a3f:	7e 7f                	jle    3ac0 <apply_rev_avx256_auto_mv_seq_ALL+0x240>
    3a41:	44 89 74 24 50       	mov    %r14d,0x50(%rsp)
    3a46:	48 89 6c 24 38       	mov    %rbp,0x38(%rsp)
    3a4b:	4c 8b 6c 24 60       	mov    0x60(%rsp),%r13
    3a50:	44 8b 74 24 58       	mov    0x58(%rsp),%r14d
    3a55:	48 8b 6c 24 48       	mov    0x48(%rsp),%rbp
    3a5a:	41 89 df             	mov    %ebx,%r15d
    3a5d:	4c 89 64 24 40       	mov    %r12,0x40(%rsp)
    3a62:	44 8b 4c 24 5c       	mov    0x5c(%rsp),%r9d
    3a67:	45 31 e4             	xor    %r12d,%r12d
    3a6a:	44 89 e3             	mov    %r12d,%ebx
    3a6d:	49 89 ec             	mov    %rbp,%r12
    3a70:	4c 8b 44 24 10       	mov    0x10(%rsp),%r8
    3a75:	31 c0                	xor    %eax,%eax
    3a77:	89 df                	mov    %ebx,%edi
    3a79:	48 89 e9             	mov    %rbp,%rcx
    3a7c:	44 89 fa             	mov    %r15d,%edx
    3a7f:	44 89 f6             	mov    %r14d,%esi
    3a82:	41 0f 18 0c 24       	prefetcht0 (%r12)
    3a87:	44 89 4c 24 08       	mov    %r9d,0x8(%rsp)
    3a8c:	4d 01 ec             	add    %r13,%r12
    3a8f:	e8 8c 0e 00 00       	call   4920 <apply_rev_avx_mv_seq_avx256>
    3a94:	8b 44 24 28          	mov    0x28(%rsp),%eax
    3a98:	44 8b 4c 24 08       	mov    0x8(%rsp),%r9d
    3a9d:	01 c3                	add    %eax,%ebx
    3a9f:	39 5c 24 1c          	cmp    %ebx,0x1c(%rsp)
    3aa3:	7f cb                	jg     3a70 <apply_rev_avx256_auto_mv_seq_ALL+0x1f0>
    3aa5:	45 85 ff             	test   %r15d,%r15d
    3aa8:	0f 8e e5 02 00 00    	jle    3d93 <apply_rev_avx256_auto_mv_seq_ALL+0x513>
    3aae:	44 8b 74 24 50       	mov    0x50(%rsp),%r14d
    3ab3:	4c 8b 64 24 40       	mov    0x40(%rsp),%r12
    3ab8:	48 8b 6c 24 38       	mov    0x38(%rsp),%rbp
    3abd:	44 89 fb             	mov    %r15d,%ebx
    3ac0:	45 85 f6             	test   %r14d,%r14d
    3ac3:	0f 8e b9 00 00 00    	jle    3b82 <apply_rev_avx256_auto_mv_seq_ALL+0x302>
    3ac9:	45 31 ff             	xor    %r15d,%r15d
    3acc:	44 89 74 24 08       	mov    %r14d,0x8(%rsp)
    3ad1:	4c 8b 6c 24 10       	mov    0x10(%rsp),%r13
    3ad6:	48 8b 7c 24 30       	mov    0x30(%rsp),%rdi
    3adb:	45 89 fe             	mov    %r15d,%r14d
    3ade:	4c 8b 7c 24 20       	mov    0x20(%rsp),%r15
    3ae3:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    3aea:	00 00 00 00 
    3aee:	66 90                	xchg   %ax,%ax
    3af0:	4c 89 ee             	mov    %r13,%rsi
    3af3:	4c 89 fa             	mov    %r15,%rdx
    3af6:	41 ff c6             	inc    %r14d
    3af9:	e8 92 d7 ff ff       	call   1290 <memcpy@plt>
    3afe:	49 01 ed             	add    %rbp,%r13
    3b01:	48 89 c7             	mov    %rax,%rdi
    3b04:	4c 01 e7             	add    %r12,%rdi
    3b07:	44 39 f3             	cmp    %r14d,%ebx
    3b0a:	75 e4                	jne    3af0 <apply_rev_avx256_auto_mv_seq_ALL+0x270>
    3b0c:	44 8b 74 24 08       	mov    0x8(%rsp),%r14d
    3b11:	48 01 6c 24 30       	add    %rbp,0x30(%rsp)
    3b16:	44 01 74 24 2c       	add    %r14d,0x2c(%rsp)
    3b1b:	8b 44 24 2c          	mov    0x2c(%rsp),%eax
    3b1f:	39 44 24 54          	cmp    %eax,0x54(%rsp)
    3b23:	0f 8f d0 fe ff ff    	jg     39f9 <apply_rev_avx256_auto_mv_seq_ALL+0x179>
    3b29:	48 8b 7c 24 10       	mov    0x10(%rsp),%rdi
    3b2e:	e8 dd d6 ff ff       	call   1210 <free@plt>
    3b33:	8b 84 24 88 00 00 00 	mov    0x88(%rsp),%eax
    3b3a:	85 c0                	test   %eax,%eax
    3b3c:	0f 85 91 00 00 00    	jne    3bd3 <apply_rev_avx256_auto_mv_seq_ALL+0x353>
    3b42:	48 8b 84 24 a8 00 00 	mov    0xa8(%rsp),%rax
    3b49:	00 
    3b4a:	64 48 2b 04 25 28 00 	sub    %fs:0x28,%rax
    3b51:	00 00 
    3b53:	0f 85 d2 02 00 00    	jne    3e2b <apply_rev_avx256_auto_mv_seq_ALL+0x5ab>
    3b59:	48 8b 7c 24 68       	mov    0x68(%rsp),%rdi
    3b5e:	48 81 c4 b8 00 00 00 	add    $0xb8,%rsp
    3b65:	5b                   	pop    %rbx
    3b66:	5d                   	pop    %rbp
    3b67:	41 5c                	pop    %r12
    3b69:	41 5d                	pop    %r13
    3b6b:	41 5e                	pop    %r14
    3b6d:	41 5f                	pop    %r15
    3b6f:	e9 9c d6 ff ff       	jmp    1210 <free@plt>
    3b74:	44 8b 6c 24 1c       	mov    0x1c(%rsp),%r13d
    3b79:	45 85 ed             	test   %r13d,%r13d
    3b7c:	0f 8f bf fe ff ff    	jg     3a41 <apply_rev_avx256_auto_mv_seq_ALL+0x1c1>
    3b82:	44 01 74 24 2c       	add    %r14d,0x2c(%rsp)
    3b87:	8b 44 24 2c          	mov    0x2c(%rsp),%eax
    3b8b:	48 01 6c 24 30       	add    %rbp,0x30(%rsp)
    3b90:	39 44 24 54          	cmp    %eax,0x54(%rsp)
    3b94:	0f 8f 57 fe ff ff    	jg     39f1 <apply_rev_avx256_auto_mv_seq_ALL+0x171>
    3b9a:	48 8b 7c 24 10       	mov    0x10(%rsp),%rdi
    3b9f:	e8 6c d6 ff ff       	call   1210 <free@plt>
    3ba4:	44 8b 94 24 88 00 00 	mov    0x88(%rsp),%r10d
    3bab:	00 
    3bac:	45 85 d2             	test   %r10d,%r10d
    3baf:	74 91                	je     3b42 <apply_rev_avx256_auto_mv_seq_ALL+0x2c2>
    3bb1:	85 db                	test   %ebx,%ebx
    3bb3:	0f 8e 5f 02 00 00    	jle    3e18 <apply_rev_avx256_auto_mv_seq_ALL+0x598>
    3bb9:	48 8b 44 24 78       	mov    0x78(%rsp),%rax
    3bbe:	48 8d 2c c5 00 00 00 	lea    0x0(,%rax,8),%rbp
    3bc5:	00 
    3bc6:	48 63 84 24 8c 00 00 	movslq 0x8c(%rsp),%rax
    3bcd:	00 
    3bce:	48 89 44 24 70       	mov    %rax,0x70(%rsp)
    3bd3:	8b 8c 24 88 00 00 00 	mov    0x88(%rsp),%ecx
    3bda:	44 89 f0             	mov    %r14d,%eax
    3bdd:	48 63 54 24 54       	movslq 0x54(%rsp),%rdx
    3be2:	48 8b 7c 24 68       	mov    0x68(%rsp),%rdi
    3be7:	45 31 e4             	xor    %r12d,%r12d
    3bea:	29 c8                	sub    %ecx,%eax
    3bec:	48 98                	cltq   
    3bee:	48 c1 e0 03          	shl    $0x3,%rax
    3bf2:	48 89 44 24 10       	mov    %rax,0x10(%rsp)
    3bf7:	48 8b 44 24 70       	mov    0x70(%rsp),%rax
    3bfc:	48 c1 e0 03          	shl    $0x3,%rax
    3c00:	48 89 44 24 08       	mov    %rax,0x8(%rsp)
    3c05:	48 8b 84 24 80 00 00 	mov    0x80(%rsp),%rax
    3c0c:	00 
    3c0d:	48 8d 34 d0          	lea    (%rax,%rdx,8),%rsi
    3c11:	48 63 c1             	movslq %ecx,%rax
    3c14:	48 c1 e0 03          	shl    $0x3,%rax
    3c18:	0f 18 0e             	prefetcht0 (%rsi)
    3c1b:	4c 8d 2c 07          	lea    (%rdi,%rax,1),%r13
    3c1f:	48 89 44 24 20       	mov    %rax,0x20(%rsp)
    3c24:	8d 41 ff             	lea    -0x1(%rcx),%eax
    3c27:	49 89 f6             	mov    %rsi,%r14
    3c2a:	89 44 24 2c          	mov    %eax,0x2c(%rsp)
    3c2e:	c1 e8 02             	shr    $0x2,%eax
    3c31:	ff c0                	inc    %eax
    3c33:	48 c1 e0 05          	shl    $0x5,%rax
    3c37:	49 89 c7             	mov    %rax,%r15
    3c3a:	85 c9                	test   %ecx,%ecx
    3c3c:	0f 8e 92 01 00 00    	jle    3dd4 <apply_rev_avx256_auto_mv_seq_ALL+0x554>
    3c42:	89 d8                	mov    %ebx,%eax
    3c44:	48 89 54 24 30       	mov    %rdx,0x30(%rsp)
    3c49:	48 89 f3             	mov    %rsi,%rbx
    3c4c:	41 89 c6             	mov    %eax,%r14d
    3c4f:	eb 06                	jmp    3c57 <apply_rev_avx256_auto_mv_seq_ALL+0x3d7>
    3c51:	48 89 de             	mov    %rbx,%rsi
    3c54:	0f 18 0b             	prefetcht0 (%rbx)
    3c57:	48 8b 44 24 20       	mov    0x20(%rsp),%rax
    3c5c:	4c 89 ef             	mov    %r13,%rdi
    3c5f:	4c 89 fa             	mov    %r15,%rdx
    3c62:	41 ff c4             	inc    %r12d
    3c65:	48 29 c7             	sub    %rax,%rdi
    3c68:	e8 23 d6 ff ff       	call   1290 <memcpy@plt>
    3c6d:	48 8b 54 24 10       	mov    0x10(%rsp),%rdx
    3c72:	4c 89 ef             	mov    %r13,%rdi
    3c75:	31 f6                	xor    %esi,%esi
    3c77:	49 01 ed             	add    %rbp,%r13
    3c7a:	e8 01 d5 ff ff       	call   1180 <memset@plt>
    3c7f:	48 8b 44 24 08       	mov    0x8(%rsp),%rax
    3c84:	48 01 c3             	add    %rax,%rbx
    3c87:	45 39 e6             	cmp    %r12d,%r14d
    3c8a:	75 c5                	jne    3c51 <apply_rev_avx256_auto_mv_seq_ALL+0x3d1>
    3c8c:	44 8b 44 24 1c       	mov    0x1c(%rsp),%r8d
    3c91:	48 8b 54 24 30       	mov    0x30(%rsp),%rdx
    3c96:	44 89 f3             	mov    %r14d,%ebx
    3c99:	45 85 c0             	test   %r8d,%r8d
    3c9c:	0f 8e 6c 01 00 00    	jle    3e0e <apply_rev_avx256_auto_mv_seq_ALL+0x58e>
    3ca2:	44 8b 4c 24 5c       	mov    0x5c(%rsp),%r9d
    3ca7:	8b 44 24 28          	mov    0x28(%rsp),%eax
    3cab:	4c 8b 6c 24 48       	mov    0x48(%rsp),%r13
    3cb0:	45 31 e4             	xor    %r12d,%r12d
    3cb3:	44 8b 74 24 1c       	mov    0x1c(%rsp),%r14d
    3cb8:	44 89 cd             	mov    %r9d,%ebp
    3cbb:	4d 89 ef             	mov    %r13,%r15
    3cbe:	45 89 e5             	mov    %r12d,%r13d
    3cc1:	41 89 c4             	mov    %eax,%r12d
    3cc4:	0f af e8             	imul   %eax,%ebp
    3cc7:	48 63 ed             	movslq %ebp,%rbp
    3cca:	48 c1 e5 03          	shl    $0x3,%rbp
    3cce:	41 0f 18 0f          	prefetcht0 (%r15)
    3cd2:	44 89 4c 24 08       	mov    %r9d,0x8(%rsp)
    3cd7:	4c 8b 44 24 68       	mov    0x68(%rsp),%r8
    3cdc:	48 8b 4c 24 48       	mov    0x48(%rsp),%rcx
    3ce1:	8b 74 24 58          	mov    0x58(%rsp),%esi
    3ce5:	44 89 ef             	mov    %r13d,%edi
    3ce8:	31 c0                	xor    %eax,%eax
    3cea:	89 da                	mov    %ebx,%edx
    3cec:	45 01 e5             	add    %r12d,%r13d
    3cef:	49 01 ef             	add    %rbp,%r15
    3cf2:	e8 29 0c 00 00       	call   4920 <apply_rev_avx_mv_seq_avx256>
    3cf7:	45 39 ee             	cmp    %r13d,%r14d
    3cfa:	44 8b 4c 24 08       	mov    0x8(%rsp),%r9d
    3cff:	7f cd                	jg     3cce <apply_rev_avx256_auto_mv_seq_ALL+0x44e>
    3d01:	85 db                	test   %ebx,%ebx
    3d03:	0f 8e 39 fe ff ff    	jle    3b42 <apply_rev_avx256_auto_mv_seq_ALL+0x2c2>
    3d09:	48 8b 44 24 78       	mov    0x78(%rsp),%rax
    3d0e:	48 63 54 24 54       	movslq 0x54(%rsp),%rdx
    3d13:	48 8d 2c c5 00 00 00 	lea    0x0(,%rax,8),%rbp
    3d1a:	00 
    3d1b:	48 63 84 24 8c 00 00 	movslq 0x8c(%rsp),%rax
    3d22:	00 
    3d23:	48 89 44 24 70       	mov    %rax,0x70(%rsp)
    3d28:	8b 84 24 88 00 00 00 	mov    0x88(%rsp),%eax
    3d2f:	ff c8                	dec    %eax
    3d31:	41 89 c5             	mov    %eax,%r13d
    3d34:	89 44 24 2c          	mov    %eax,0x2c(%rsp)
    3d38:	4c 8b 64 24 70       	mov    0x70(%rsp),%r12
    3d3d:	48 8b 84 24 80 00 00 	mov    0x80(%rsp),%rax
    3d44:	00 
    3d45:	4c 8b 74 24 68       	mov    0x68(%rsp),%r14
    3d4a:	45 31 ff             	xor    %r15d,%r15d
    3d4d:	41 c1 ed 02          	shr    $0x2,%r13d
    3d51:	41 ff c5             	inc    %r13d
    3d54:	49 c1 e4 03          	shl    $0x3,%r12
    3d58:	49 c1 e5 05          	shl    $0x5,%r13
    3d5c:	48 8d 0c d0          	lea    (%rax,%rdx,8),%rcx
    3d60:	8b b4 24 88 00 00 00 	mov    0x88(%rsp),%esi
    3d67:	41 0f 18 0e          	prefetcht0 (%r14)
    3d6b:	85 f6                	test   %esi,%esi
    3d6d:	7e 11                	jle    3d80 <apply_rev_avx256_auto_mv_seq_ALL+0x500>
    3d6f:	48 89 cf             	mov    %rcx,%rdi
    3d72:	4c 89 ea             	mov    %r13,%rdx
    3d75:	4c 89 f6             	mov    %r14,%rsi
    3d78:	e8 13 d5 ff ff       	call   1290 <memcpy@plt>
    3d7d:	48 89 c1             	mov    %rax,%rcx
    3d80:	41 ff c7             	inc    %r15d
    3d83:	49 01 ee             	add    %rbp,%r14
    3d86:	4c 01 e1             	add    %r12,%rcx
    3d89:	44 39 fb             	cmp    %r15d,%ebx
    3d8c:	75 d2                	jne    3d60 <apply_rev_avx256_auto_mv_seq_ALL+0x4e0>
    3d8e:	e9 af fd ff ff       	jmp    3b42 <apply_rev_avx256_auto_mv_seq_ALL+0x2c2>
    3d93:	8b 4c 24 50          	mov    0x50(%rsp),%ecx
    3d97:	48 8b 54 24 38       	mov    0x38(%rsp),%rdx
    3d9c:	01 4c 24 2c          	add    %ecx,0x2c(%rsp)
    3da0:	8b 44 24 2c          	mov    0x2c(%rsp),%eax
    3da4:	48 01 54 24 30       	add    %rdx,0x30(%rsp)
    3da9:	39 44 24 54          	cmp    %eax,0x54(%rsp)
    3dad:	0f 8f af fc ff ff    	jg     3a62 <apply_rev_avx256_auto_mv_seq_ALL+0x1e2>
    3db3:	48 8b 7c 24 10       	mov    0x10(%rsp),%rdi
    3db8:	44 89 fb             	mov    %r15d,%ebx
    3dbb:	e8 50 d4 ff ff       	call   1210 <free@plt>
    3dc0:	8b 94 24 88 00 00 00 	mov    0x88(%rsp),%edx
    3dc7:	85 d2                	test   %edx,%edx
    3dc9:	0f 84 73 fd ff ff    	je     3b42 <apply_rev_avx256_auto_mv_seq_ALL+0x2c2>
    3dcf:	e9 ce fe ff ff       	jmp    3ca2 <apply_rev_avx256_auto_mv_seq_ALL+0x422>
    3dd4:	49 89 d7             	mov    %rdx,%r15
    3dd7:	eb 04                	jmp    3ddd <apply_rev_avx256_auto_mv_seq_ALL+0x55d>
    3dd9:	41 0f 18 0e          	prefetcht0 (%r14)
    3ddd:	48 8b 54 24 10       	mov    0x10(%rsp),%rdx
    3de2:	4c 89 ef             	mov    %r13,%rdi
    3de5:	31 f6                	xor    %esi,%esi
    3de7:	41 ff c4             	inc    %r12d
    3dea:	49 01 ed             	add    %rbp,%r13
    3ded:	e8 8e d3 ff ff       	call   1180 <memset@plt>
    3df2:	48 8b 44 24 08       	mov    0x8(%rsp),%rax
    3df7:	49 01 c6             	add    %rax,%r14
    3dfa:	44 39 e3             	cmp    %r12d,%ebx
    3dfd:	75 da                	jne    3dd9 <apply_rev_avx256_auto_mv_seq_ALL+0x559>
    3dff:	8b 7c 24 1c          	mov    0x1c(%rsp),%edi
    3e03:	4c 89 fa             	mov    %r15,%rdx
    3e06:	85 ff                	test   %edi,%edi
    3e08:	0f 8f 94 fe ff ff    	jg     3ca2 <apply_rev_avx256_auto_mv_seq_ALL+0x422>
    3e0e:	44 8b 6c 24 2c       	mov    0x2c(%rsp),%r13d
    3e13:	e9 20 ff ff ff       	jmp    3d38 <apply_rev_avx256_auto_mv_seq_ALL+0x4b8>
    3e18:	44 8b 4c 24 1c       	mov    0x1c(%rsp),%r9d
    3e1d:	45 85 c9             	test   %r9d,%r9d
    3e20:	0f 8e 1c fd ff ff    	jle    3b42 <apply_rev_avx256_auto_mv_seq_ALL+0x2c2>
    3e26:	e9 77 fe ff ff       	jmp    3ca2 <apply_rev_avx256_auto_mv_seq_ALL+0x422>
    3e2b:	e8 30 d4 ff ff       	call   1260 <__stack_chk_fail@plt>

0000000000003e30 <dmatrix_vector_multiply_mt_rev_avx256_seq_ALL._omp_fn.0>:
    3e30:	f3 0f 1e fa          	endbr64 
    3e34:	41 55                	push   %r13
    3e36:	41 54                	push   %r12
    3e38:	55                   	push   %rbp
    3e39:	53                   	push   %rbx
    3e3a:	48 89 fb             	mov    %rdi,%rbx
    3e3d:	48 83 ec 08          	sub    $0x8,%rsp
    3e41:	8b 6f 14             	mov    0x14(%rdi),%ebp
    3e44:	44 8b 6f 28          	mov    0x28(%rdi),%r13d
    3e48:	e8 43 d3 ff ff       	call   1190 <omp_get_num_threads@plt>
    3e4d:	41 89 c4             	mov    %eax,%r12d
    3e50:	e8 ab d3 ff ff       	call   1200 <omp_get_thread_num@plt>
    3e55:	4c 8b 43 08          	mov    0x8(%rbx),%r8
    3e59:	4c 8b 1b             	mov    (%rbx),%r11
    3e5c:	89 c1                	mov    %eax,%ecx
    3e5e:	44 8b 53 18          	mov    0x18(%rbx),%r10d
    3e62:	8b 7b 10             	mov    0x10(%rbx),%edi
    3e65:	42 8d 44 25 ff       	lea    -0x1(%rbp,%r12,1),%eax
    3e6a:	42 8d 34 ad 00 00 00 	lea    0x0(,%r13,4),%esi
    3e71:	00 
    3e72:	99                   	cltd   
    3e73:	41 f7 fc             	idiv   %r12d
    3e76:	8d 44 06 ff          	lea    -0x1(%rsi,%rax,1),%eax
    3e7a:	99                   	cltd   
    3e7b:	f7 fe                	idiv   %esi
    3e7d:	41 0f af c5          	imul   %r13d,%eax
    3e81:	c1 e0 02             	shl    $0x2,%eax
    3e84:	0f af c8             	imul   %eax,%ecx
    3e87:	89 ca                	mov    %ecx,%edx
    3e89:	39 cd                	cmp    %ecx,%ebp
    3e8b:	8d 34 10             	lea    (%rax,%rdx,1),%esi
    3e8e:	0f 4e cd             	cmovle %ebp,%ecx
    3e91:	44 89 d2             	mov    %r10d,%edx
    3e94:	39 ee                	cmp    %ebp,%esi
    3e96:	4c 63 e1             	movslq %ecx,%r12
    3e99:	0f 4f f5             	cmovg  %ebp,%esi
    3e9c:	48 83 ec 08          	sub    $0x8,%rsp
    3ea0:	4f 8d 04 e0          	lea    (%r8,%r12,8),%r8
    3ea4:	41 55                	push   %r13
    3ea6:	8b 43 24             	mov    0x24(%rbx),%eax
    3ea9:	29 ce                	sub    %ecx,%esi
    3eab:	4c 89 d9             	mov    %r11,%rcx
    3eae:	50                   	push   %rax
    3eaf:	8b 43 20             	mov    0x20(%rbx),%eax
    3eb2:	50                   	push   %rax
    3eb3:	44 8b 4b 1c          	mov    0x1c(%rbx),%r9d
    3eb7:	e8 c4 f9 ff ff       	call   3880 <apply_rev_avx256_auto_mv_seq_ALL>
    3ebc:	48 83 c4 28          	add    $0x28,%rsp
    3ec0:	5b                   	pop    %rbx
    3ec1:	5d                   	pop    %rbp
    3ec2:	41 5c                	pop    %r12
    3ec4:	41 5d                	pop    %r13
    3ec6:	c3                   	ret    
    3ec7:	66 0f 1f 84 00 00 00 	nopw   0x0(%rax,%rax,1)
    3ece:	00 00 

0000000000003ed0 <dmatrix_vector_multiply_mt_rev_avx512_seq_ALL>:
    3ed0:	f3 0f 1e fa          	endbr64 
    3ed4:	48 83 ec 48          	sub    $0x48,%rsp
    3ed8:	c5 f9 6e f2          	vmovd  %edx,%xmm6
    3edc:	c5 f9 6e ff          	vmovd  %edi,%xmm7
    3ee0:	31 d2                	xor    %edx,%edx
    3ee2:	c5 f9 6e 64 24 50    	vmovd  0x50(%rsp),%xmm4
    3ee8:	c4 e3 59 22 5c 24 58 	vpinsrd $0x1,0x58(%rsp),%xmm4,%xmm3
    3eef:	01 
    3ef0:	c4 e1 f9 6e e9       	vmovq  %rcx,%xmm5
    3ef5:	c4 e3 41 22 c6 01    	vpinsrd $0x1,%esi,%xmm7,%xmm0
    3efb:	64 48 8b 04 25 28 00 	mov    %fs:0x28,%rax
    3f02:	00 00 
    3f04:	48 89 44 24 38       	mov    %rax,0x38(%rsp)
    3f09:	8b 44 24 60          	mov    0x60(%rsp),%eax
    3f0d:	c4 c3 49 22 c9 01    	vpinsrd $0x1,%r9d,%xmm6,%xmm1
    3f13:	c4 c3 d1 22 d0 01    	vpinsrq $0x1,%r8,%xmm5,%xmm2
    3f19:	c5 f9 6c c1          	vpunpcklqdq %xmm1,%xmm0,%xmm0
    3f1d:	c5 f9 7f 14 24       	vmovdqa %xmm2,(%rsp)
    3f22:	c5 f9 7f 44 24 10    	vmovdqa %xmm0,0x10(%rsp)
    3f28:	31 c9                	xor    %ecx,%ecx
    3f2a:	48 89 e6             	mov    %rsp,%rsi
    3f2d:	48 8d 3d ac f8 ff ff 	lea    -0x754(%rip),%rdi        # 37e0 <dmatrix_vector_multiply_mt_rev_avx512_seq_ALL._omp_fn.0>
    3f34:	89 44 24 28          	mov    %eax,0x28(%rsp)
    3f38:	c5 f9 d6 5c 24 20    	vmovq  %xmm3,0x20(%rsp)
    3f3e:	e8 ed d2 ff ff       	call   1230 <GOMP_parallel@plt>
    3f43:	48 8b 44 24 38       	mov    0x38(%rsp),%rax
    3f48:	64 48 2b 04 25 28 00 	sub    %fs:0x28,%rax
    3f4f:	00 00 
    3f51:	75 05                	jne    3f58 <dmatrix_vector_multiply_mt_rev_avx512_seq_ALL+0x88>
    3f53:	48 83 c4 48          	add    $0x48,%rsp
    3f57:	c3                   	ret    
    3f58:	e8 03 d3 ff ff       	call   1260 <__stack_chk_fail@plt>
    3f5d:	0f 1f 00             	nopl   (%rax)

0000000000003f60 <dmatrix_vector_multiply_mt_rev_avx512_fma_seq_ALL>:
    3f60:	f3 0f 1e fa          	endbr64 
    3f64:	48 83 ec 48          	sub    $0x48,%rsp
    3f68:	c5 f9 6e f2          	vmovd  %edx,%xmm6
    3f6c:	c5 f9 6e ff          	vmovd  %edi,%xmm7
    3f70:	31 d2                	xor    %edx,%edx
    3f72:	c5 f9 6e 64 24 50    	vmovd  0x50(%rsp),%xmm4
    3f78:	c4 e3 59 22 5c 24 58 	vpinsrd $0x1,0x58(%rsp),%xmm4,%xmm3
    3f7f:	01 
    3f80:	c4 e1 f9 6e e9       	vmovq  %rcx,%xmm5
    3f85:	c4 e3 41 22 c6 01    	vpinsrd $0x1,%esi,%xmm7,%xmm0
    3f8b:	64 48 8b 04 25 28 00 	mov    %fs:0x28,%rax
    3f92:	00 00 
    3f94:	48 89 44 24 38       	mov    %rax,0x38(%rsp)
    3f99:	8b 44 24 60          	mov    0x60(%rsp),%eax
    3f9d:	c4 c3 49 22 c9 01    	vpinsrd $0x1,%r9d,%xmm6,%xmm1
    3fa3:	c4 c3 d1 22 d0 01    	vpinsrq $0x1,%r8,%xmm5,%xmm2
    3fa9:	c5 f9 6c c1          	vpunpcklqdq %xmm1,%xmm0,%xmm0
    3fad:	c5 f9 7f 14 24       	vmovdqa %xmm2,(%rsp)
    3fb2:	c5 f9 7f 44 24 10    	vmovdqa %xmm0,0x10(%rsp)
    3fb8:	31 c9                	xor    %ecx,%ecx
    3fba:	48 89 e6             	mov    %rsp,%rsi
    3fbd:	48 8d 3d fc f1 ff ff 	lea    -0xe04(%rip),%rdi        # 31c0 <dmatrix_vector_multiply_mt_rev_avx512_fma_seq_ALL._omp_fn.0>
    3fc4:	89 44 24 28          	mov    %eax,0x28(%rsp)
    3fc8:	c5 f9 d6 5c 24 20    	vmovq  %xmm3,0x20(%rsp)
    3fce:	e8 5d d2 ff ff       	call   1230 <GOMP_parallel@plt>
    3fd3:	48 8b 44 24 38       	mov    0x38(%rsp),%rax
    3fd8:	64 48 2b 04 25 28 00 	sub    %fs:0x28,%rax
    3fdf:	00 00 
    3fe1:	75 05                	jne    3fe8 <dmatrix_vector_multiply_mt_rev_avx512_fma_seq_ALL+0x88>
    3fe3:	48 83 c4 48          	add    $0x48,%rsp
    3fe7:	c3                   	ret    
    3fe8:	e8 73 d2 ff ff       	call   1260 <__stack_chk_fail@plt>
    3fed:	0f 1f 00             	nopl   (%rax)

0000000000003ff0 <dmatrix_vector_multiply_mt_rev_avx256_seq_ALL>:
    3ff0:	f3 0f 1e fa          	endbr64 
    3ff4:	48 83 ec 48          	sub    $0x48,%rsp
    3ff8:	c5 f9 6e f2          	vmovd  %edx,%xmm6
    3ffc:	c5 f9 6e ff          	vmovd  %edi,%xmm7
    4000:	31 d2                	xor    %edx,%edx
    4002:	c5 f9 6e 64 24 50    	vmovd  0x50(%rsp),%xmm4
    4008:	c4 e3 59 22 5c 24 58 	vpinsrd $0x1,0x58(%rsp),%xmm4,%xmm3
    400f:	01 
    4010:	c4 e1 f9 6e e9       	vmovq  %rcx,%xmm5
    4015:	c4 e3 41 22 c6 01    	vpinsrd $0x1,%esi,%xmm7,%xmm0
    401b:	64 48 8b 04 25 28 00 	mov    %fs:0x28,%rax
    4022:	00 00 
    4024:	48 89 44 24 38       	mov    %rax,0x38(%rsp)
    4029:	8b 44 24 60          	mov    0x60(%rsp),%eax
    402d:	c4 c3 49 22 c9 01    	vpinsrd $0x1,%r9d,%xmm6,%xmm1
    4033:	c4 c3 d1 22 d0 01    	vpinsrq $0x1,%r8,%xmm5,%xmm2
    4039:	c5 f9 6c c1          	vpunpcklqdq %xmm1,%xmm0,%xmm0
    403d:	c5 f9 7f 14 24       	vmovdqa %xmm2,(%rsp)
    4042:	c5 f9 7f 44 24 10    	vmovdqa %xmm0,0x10(%rsp)
    4048:	31 c9                	xor    %ecx,%ecx
    404a:	48 89 e6             	mov    %rsp,%rsi
    404d:	48 8d 3d dc fd ff ff 	lea    -0x224(%rip),%rdi        # 3e30 <dmatrix_vector_multiply_mt_rev_avx256_seq_ALL._omp_fn.0>
    4054:	89 44 24 28          	mov    %eax,0x28(%rsp)
    4058:	c5 f9 d6 5c 24 20    	vmovq  %xmm3,0x20(%rsp)
    405e:	e8 cd d1 ff ff       	call   1230 <GOMP_parallel@plt>
    4063:	48 8b 44 24 38       	mov    0x38(%rsp),%rax
    4068:	64 48 2b 04 25 28 00 	sub    %fs:0x28,%rax
    406f:	00 00 
    4071:	75 05                	jne    4078 <dmatrix_vector_multiply_mt_rev_avx256_seq_ALL+0x88>
    4073:	48 83 c4 48          	add    $0x48,%rsp
    4077:	c3                   	ret    
    4078:	e8 e3 d1 ff ff       	call   1260 <__stack_chk_fail@plt>
    407d:	0f 1f 00             	nopl   (%rax)

0000000000004080 <applywave_avx>:
    4080:	f3 0f 1e fa          	endbr64 
    4084:	41 57                	push   %r15
    4086:	41 56                	push   %r14
    4088:	41 55                	push   %r13
    408a:	44 89 c8             	mov    %r9d,%eax
    408d:	41 54                	push   %r12
    408f:	55                   	push   %rbp
    4090:	53                   	push   %rbx
    4091:	89 f3                	mov    %esi,%ebx
    4093:	48 83 ec 58          	sub    $0x58,%rsp
    4097:	89 7c 24 44          	mov    %edi,0x44(%rsp)
    409b:	89 54 24 48          	mov    %edx,0x48(%rsp)
    409f:	48 89 4c 24 10       	mov    %rcx,0x10(%rsp)
    40a4:	4c 89 44 24 08       	mov    %r8,0x8(%rsp)
    40a9:	39 fa                	cmp    %edi,%edx
    40ab:	0f 8c 11 03 00 00    	jl     43c2 <applywave_avx+0x342>
    40b1:	83 ff 01             	cmp    $0x1,%edi
    40b4:	0f 84 08 03 00 00    	je     43c2 <applywave_avx+0x342>
    40ba:	44 8d 57 ff          	lea    -0x1(%rdi),%r10d
    40be:	45 89 d6             	mov    %r10d,%r14d
    40c1:	45 85 d2             	test   %r10d,%r10d
    40c4:	0f 8e 7e 03 00 00    	jle    4448 <applywave_avx+0x3c8>
    40ca:	48 63 b4 24 90 00 00 	movslq 0x90(%rsp),%rsi
    40d1:	00 
    40d2:	41 89 c3             	mov    %eax,%r11d
    40d5:	44 89 d1             	mov    %r10d,%ecx
    40d8:	4c 63 c8             	movslq %eax,%r9
    40db:	41 f7 db             	neg    %r11d
    40de:	31 ff                	xor    %edi,%edi
    40e0:	45 31 e4             	xor    %r12d,%r12d
    40e3:	48 89 4c 24 30       	mov    %rcx,0x30(%rsp)
    40e8:	4d 63 db             	movslq %r11d,%r11
    40eb:	44 89 54 24 4c       	mov    %r10d,0x4c(%rsp)
    40f0:	4c 89 c9             	mov    %r9,%rcx
    40f3:	4d 89 e2             	mov    %r12,%r10
    40f6:	49 c1 e3 03          	shl    $0x3,%r11
    40fa:	4c 89 4c 24 18       	mov    %r9,0x18(%rsp)
    40ff:	44 89 74 24 38       	mov    %r14d,0x38(%rsp)
    4104:	89 44 24 40          	mov    %eax,0x40(%rsp)
    4108:	4c 8d 3c f5 f0 ff ff 	lea    -0x10(,%rsi,8),%r15
    410f:	ff 
    4110:	62 e1 fd 08 6e ce    	vmovq  %rsi,%xmm17
    4116:	48 89 fe             	mov    %rdi,%rsi
    4119:	62 c1 fd 08 6e d7    	vmovq  %r15,%xmm18
    411f:	90                   	nop
    4120:	48 8b 7c 24 10       	mov    0x10(%rsp),%rdi
    4125:	4c 89 d0             	mov    %r10,%rax
    4128:	48 89 cd             	mov    %rcx,%rbp
    412b:	45 31 ff             	xor    %r15d,%r15d
    412e:	48 29 f5             	sub    %rsi,%rbp
    4131:	62 c1 fd 08 7e d5    	vmovq  %xmm18,%r13
    4137:	48 89 74 24 20       	mov    %rsi,0x20(%rsp)
    413c:	48 89 4c 24 28       	mov    %rcx,0x28(%rsp)
    4141:	48 c1 e0 04          	shl    $0x4,%rax
    4145:	48 c1 e5 03          	shl    $0x3,%rbp
    4149:	4c 8d 34 07          	lea    (%rdi,%rax,1),%r14
    414d:	48 8b 44 24 08       	mov    0x8(%rsp),%rax
    4152:	4c 8d 24 f0          	lea    (%rax,%rsi,8),%r12
    4156:	66 2e 0f 1f 84 00 00 	cs nopw 0x0(%rax,%rax,1)
    415d:	00 00 00 
    4160:	4a 8d 54 25 00       	lea    0x0(%rbp,%r12,1),%rdx
    4165:	4c 89 e6             	mov    %r12,%rsi
    4168:	89 df                	mov    %ebx,%edi
    416a:	41 ff c7             	inc    %r15d
    416d:	c4 c1 7b 10 06       	vmovsd (%r14),%xmm0
    4172:	c4 c1 7b 10 4e 08    	vmovsd 0x8(%r14),%xmm1
    4178:	4d 01 dc             	add    %r11,%r12
    417b:	e8 b0 dd ff ff       	call   1f30 <applywavemx2_avx>
    4180:	4d 01 ee             	add    %r13,%r14
    4183:	45 39 d7             	cmp    %r10d,%r15d
    4186:	7e d8                	jle    4160 <applywave_avx+0xe0>
    4188:	48 8b 44 24 18       	mov    0x18(%rsp),%rax
    418d:	48 8b 74 24 20       	mov    0x20(%rsp),%rsi
    4192:	48 8b 4c 24 28       	mov    0x28(%rsp),%rcx
    4197:	49 ff c2             	inc    %r10
    419a:	48 01 c1             	add    %rax,%rcx
    419d:	48 01 c6             	add    %rax,%rsi
    41a0:	4c 39 54 24 30       	cmp    %r10,0x30(%rsp)
    41a5:	0f 85 75 ff ff ff    	jne    4120 <applywave_avx+0xa0>
    41ab:	8b 4c 24 48          	mov    0x48(%rsp),%ecx
    41af:	8b 7c 24 44          	mov    0x44(%rsp),%edi
    41b3:	44 8b 74 24 38       	mov    0x38(%rsp),%r14d
    41b8:	62 e1 fd 08 7e ce    	vmovq  %xmm17,%rsi
    41be:	8b 44 24 40          	mov    0x40(%rsp),%eax
    41c2:	44 8b 54 24 4c       	mov    0x4c(%rsp),%r10d
    41c7:	8d 51 ff             	lea    -0x1(%rcx),%edx
    41ca:	39 f9                	cmp    %edi,%ecx
    41cc:	0f 8e 6e 02 00 00    	jle    4440 <applywave_avx+0x3c0>
    41d2:	48 8d 0c f5 00 00 00 	lea    0x0(,%rsi,8),%rcx
    41d9:	00 
    41da:	48 8b 7c 24 10       	mov    0x10(%rsp),%rdi
    41df:	44 8b 5c 24 44       	mov    0x44(%rsp),%r11d
    41e4:	41 89 c4             	mov    %eax,%r12d
    41e7:	62 e1 fd 08 6e c1    	vmovq  %rcx,%xmm16
    41ed:	8b 8c 24 90 00 00 00 	mov    0x90(%rsp),%ecx
    41f4:	41 bd 02 00 00 00    	mov    $0x2,%r13d
    41fa:	41 f7 dc             	neg    %r12d
    41fd:	49 29 f5             	sub    %rsi,%r13
    4200:	4d 63 e4             	movslq %r12d,%r12
    4203:	89 44 24 4c          	mov    %eax,0x4c(%rsp)
    4207:	89 54 24 40          	mov    %edx,0x40(%rsp)
    420b:	49 c1 e5 03          	shl    $0x3,%r13
    420f:	49 c1 e4 03          	shl    $0x3,%r12
    4213:	41 0f af ca          	imul   %r10d,%ecx
    4217:	48 63 c9             	movslq %ecx,%rcx
    421a:	4c 8d 0c cf          	lea    (%rdi,%rcx,8),%r9
    421e:	44 89 d9             	mov    %r11d,%ecx
    4221:	0f af c8             	imul   %eax,%ecx
    4224:	4c 63 c1             	movslq %ecx,%r8
    4227:	29 c1                	sub    %eax,%ecx
    4229:	48 63 c9             	movslq %ecx,%rcx
    422c:	4c 89 c0             	mov    %r8,%rax
    422f:	48 89 ce             	mov    %rcx,%rsi
    4232:	44 89 f1             	mov    %r14d,%ecx
    4235:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    423c:	00 00 00 00 
    4240:	48 8b 7c 24 08       	mov    0x8(%rsp),%rdi
    4245:	49 89 c2             	mov    %rax,%r10
    4248:	4d 89 cf             	mov    %r9,%r15
    424b:	31 ed                	xor    %ebp,%ebp
    424d:	49 29 f2             	sub    %rsi,%r10
    4250:	89 4c 24 20          	mov    %ecx,0x20(%rsp)
    4254:	48 89 74 24 28       	mov    %rsi,0x28(%rsp)
    4259:	48 89 44 24 30       	mov    %rax,0x30(%rsp)
    425e:	49 c1 e2 03          	shl    $0x3,%r10
    4262:	4c 89 4c 24 38       	mov    %r9,0x38(%rsp)
    4267:	4c 8d 34 f7          	lea    (%rdi,%rsi,8),%r14
    426b:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)
    4270:	4b 8d 14 32          	lea    (%r10,%r14,1),%rdx
    4274:	4c 89 f6             	mov    %r14,%rsi
    4277:	89 df                	mov    %ebx,%edi
    4279:	ff c5                	inc    %ebp
    427b:	c4 c1 7b 10 07       	vmovsd (%r15),%xmm0
    4280:	c4 c1 7b 10 4f 08    	vmovsd 0x8(%r15),%xmm1
    4286:	4d 01 e6             	add    %r12,%r14
    4289:	e8 a2 dc ff ff       	call   1f30 <applywavemx2_avx>
    428e:	4d 01 ef             	add    %r13,%r15
    4291:	41 39 eb             	cmp    %ebp,%r11d
    4294:	75 da                	jne    4270 <applywave_avx+0x1f0>
    4296:	4c 8b 4c 24 38       	mov    0x38(%rsp),%r9
    429b:	62 e1 fd 08 7e c7    	vmovq  %xmm16,%rdi
    42a1:	48 8b 74 24 28       	mov    0x28(%rsp),%rsi
    42a6:	48 8b 44 24 30       	mov    0x30(%rsp),%rax
    42ab:	8b 4c 24 20          	mov    0x20(%rsp),%ecx
    42af:	49 01 f9             	add    %rdi,%r9
    42b2:	48 8b 7c 24 18       	mov    0x18(%rsp),%rdi
    42b7:	ff c1                	inc    %ecx
    42b9:	48 01 f8             	add    %rdi,%rax
    42bc:	48 01 fe             	add    %rdi,%rsi
    42bf:	8b 7c 24 40          	mov    0x40(%rsp),%edi
    42c3:	39 f9                	cmp    %edi,%ecx
    42c5:	0f 85 75 ff ff ff    	jne    4240 <applywave_avx+0x1c0>
    42cb:	8b 44 24 4c          	mov    0x4c(%rsp),%eax
    42cf:	41 89 ce             	mov    %ecx,%r14d
    42d2:	89 fa                	mov    %edi,%edx
    42d4:	8b 74 24 48          	mov    0x48(%rsp),%esi
    42d8:	8b 6c 24 44          	mov    0x44(%rsp),%ebp
    42dc:	89 f1                	mov    %esi,%ecx
    42de:	29 e9                	sub    %ebp,%ecx
    42e0:	44 39 f1             	cmp    %r14d,%ecx
    42e3:	0f 8d ca 00 00 00    	jge    43b3 <applywave_avx+0x333>
    42e9:	48 63 8c 24 90 00 00 	movslq 0x90(%rsp),%rcx
    42f0:	00 
    42f1:	41 ba 02 00 00 00    	mov    $0x2,%r10d
    42f7:	83 ee 02             	sub    $0x2,%esi
    42fa:	41 89 c3             	mov    %eax,%r11d
    42fd:	0f af d0             	imul   %eax,%edx
    4300:	41 f7 db             	neg    %r11d
    4303:	4d 63 db             	movslq %r11d,%r11
    4306:	49 c1 e3 03          	shl    $0x3,%r11
    430a:	49 29 ca             	sub    %rcx,%r10
    430d:	8b 8c 24 90 00 00 00 	mov    0x90(%rsp),%ecx
    4314:	4c 63 ea             	movslq %edx,%r13
    4317:	49 c1 e2 03          	shl    $0x3,%r10
    431b:	0f af ce             	imul   %esi,%ecx
    431e:	0f af f0             	imul   %eax,%esi
    4321:	48 63 c9             	movslq %ecx,%rcx
    4324:	62 e1 fd 08 6e c1    	vmovq  %rcx,%xmm16
    432a:	48 8b 4c 24 08       	mov    0x8(%rsp),%rcx
    432f:	48 63 f6             	movslq %esi,%rsi
    4332:	c7 44 24 08 01 00 00 	movl   $0x1,0x8(%rsp)
    4339:	00 
    433a:	49 29 f5             	sub    %rsi,%r13
    433d:	49 c1 e5 03          	shl    $0x3,%r13
    4341:	4c 8d 34 f1          	lea    (%rcx,%rsi,8),%r14
    4345:	4c 89 74 24 18       	mov    %r14,0x18(%rsp)
    434a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)
    4350:	8b 44 24 08          	mov    0x8(%rsp),%eax
    4354:	41 89 c4             	mov    %eax,%r12d
    4357:	39 c5                	cmp    %eax,%ebp
    4359:	7e 4c                	jle    43a7 <applywave_avx+0x327>
    435b:	01 c0                	add    %eax,%eax
    435d:	62 e1 fd 08 7e c1    	vmovq  %xmm16,%rcx
    4363:	4c 8b 74 24 18       	mov    0x18(%rsp),%r14
    4368:	48 98                	cltq   
    436a:	48 01 c8             	add    %rcx,%rax
    436d:	48 8b 4c 24 10       	mov    0x10(%rsp),%rcx
    4372:	4c 8d 3c c1          	lea    (%rcx,%rax,8),%r15
    4376:	66 2e 0f 1f 84 00 00 	cs nopw 0x0(%rax,%rax,1)
    437d:	00 00 00 
    4380:	4b 8d 14 2e          	lea    (%r14,%r13,1),%rdx
    4384:	4c 89 f6             	mov    %r14,%rsi
    4387:	89 df                	mov    %ebx,%edi
    4389:	41 ff c4             	inc    %r12d
    438c:	c4 c1 7b 10 07       	vmovsd (%r15),%xmm0
    4391:	c4 c1 7b 10 4f 08    	vmovsd 0x8(%r15),%xmm1
    4397:	4d 01 de             	add    %r11,%r14
    439a:	e8 91 db ff ff       	call   1f30 <applywavemx2_avx>
    439f:	4d 01 d7             	add    %r10,%r15
    43a2:	44 39 e5             	cmp    %r12d,%ebp
    43a5:	75 d9                	jne    4380 <applywave_avx+0x300>
    43a7:	ff 44 24 08          	incl   0x8(%rsp)
    43ab:	8b 44 24 08          	mov    0x8(%rsp),%eax
    43af:	39 e8                	cmp    %ebp,%eax
    43b1:	75 9d                	jne    4350 <applywave_avx+0x2d0>
    43b3:	48 83 c4 58          	add    $0x58,%rsp
    43b7:	5b                   	pop    %rbx
    43b8:	5d                   	pop    %rbp
    43b9:	41 5c                	pop    %r12
    43bb:	41 5d                	pop    %r13
    43bd:	41 5e                	pop    %r14
    43bf:	41 5f                	pop    %r15
    43c1:	c3                   	ret    
    43c2:	48 83 ec 08          	sub    $0x8,%rsp
    43c6:	41 89 c1             	mov    %eax,%r9d
    43c9:	89 de                	mov    %ebx,%esi
    43cb:	8b 8c 24 98 00 00 00 	mov    0x98(%rsp),%ecx
    43d2:	51                   	push   %rcx
    43d3:	44 8b 7c 24 54       	mov    0x54(%rsp),%r15d
    43d8:	4c 8b 44 24 18       	mov    0x18(%rsp),%r8
    43dd:	48 8b 4c 24 20       	mov    0x20(%rsp),%rcx
    43e2:	8b 54 24 58          	mov    0x58(%rsp),%edx
    43e6:	89 44 24 28          	mov    %eax,0x28(%rsp)
    43ea:	44 89 ff             	mov    %r15d,%edi
    43ed:	e8 0e df ff ff       	call   2300 <applysingle_avx>
    43f2:	45 8d 57 ff          	lea    -0x1(%r15),%r10d
    43f6:	58                   	pop    %rax
    43f7:	5a                   	pop    %rdx
    43f8:	45 85 d2             	test   %r10d,%r10d
    43fb:	8b 44 24 18          	mov    0x18(%rsp),%eax
    43ff:	45 89 d6             	mov    %r10d,%r14d
    4402:	0f 8f c2 fc ff ff    	jg     40ca <applywave_avx+0x4a>
    4408:	8b 4c 24 48          	mov    0x48(%rsp),%ecx
    440c:	8b 74 24 44          	mov    0x44(%rsp),%esi
    4410:	8d 51 ff             	lea    -0x1(%rcx),%edx
    4413:	39 f1                	cmp    %esi,%ecx
    4415:	7e 29                	jle    4440 <applywave_avx+0x3c0>
    4417:	83 fe 01             	cmp    $0x1,%esi
    441a:	75 24                	jne    4440 <applywave_avx+0x3c0>
    441c:	48 63 c8             	movslq %eax,%rcx
    441f:	48 63 b4 24 90 00 00 	movslq 0x90(%rsp),%rsi
    4426:	00 
    4427:	48 89 4c 24 18       	mov    %rcx,0x18(%rsp)
    442c:	e9 a1 fd ff ff       	jmp    41d2 <applywave_avx+0x152>
    4431:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    4438:	00 00 00 00 
    443c:	0f 1f 40 00          	nopl   0x0(%rax)
    4440:	41 89 d6             	mov    %edx,%r14d
    4443:	e9 8c fe ff ff       	jmp    42d4 <applywave_avx+0x254>
    4448:	8d 52 ff             	lea    -0x1(%rdx),%edx
    444b:	41 89 d6             	mov    %edx,%r14d
    444e:	e9 81 fe ff ff       	jmp    42d4 <applywave_avx+0x254>
    4453:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    445a:	00 00 00 00 
    445e:	66 90                	xchg   %ax,%ax

0000000000004460 <dmatrix_vector_multiply_mt_avx>:
    4460:	f3 0f 1e fa          	endbr64 
    4464:	48 83 ec 38          	sub    $0x38,%rsp
    4468:	c5 f9 6e e2          	vmovd  %edx,%xmm4
    446c:	c5 f9 6e ef          	vmovd  %edi,%xmm5
    4470:	31 d2                	xor    %edx,%edx
    4472:	64 48 8b 04 25 28 00 	mov    %fs:0x28,%rax
    4479:	00 00 
    447b:	48 89 44 24 28       	mov    %rax,0x28(%rsp)
    4480:	8b 44 24 40          	mov    0x40(%rsp),%eax
    4484:	c4 e1 f9 6e d9       	vmovq  %rcx,%xmm3
    4489:	c4 e3 51 22 c6 01    	vpinsrd $0x1,%esi,%xmm5,%xmm0
    448f:	c4 c3 59 22 c9 01    	vpinsrd $0x1,%r9d,%xmm4,%xmm1
    4495:	c4 c3 e1 22 d0 01    	vpinsrq $0x1,%r8,%xmm3,%xmm2
    449b:	c5 f9 6c c1          	vpunpcklqdq %xmm1,%xmm0,%xmm0
    449f:	c5 f9 7f 14 24       	vmovdqa %xmm2,(%rsp)
    44a4:	c5 f9 7f 44 24 10    	vmovdqa %xmm0,0x10(%rsp)
    44aa:	31 c9                	xor    %ecx,%ecx
    44ac:	48 89 e6             	mov    %rsp,%rsi
    44af:	48 8d 3d 7a e1 ff ff 	lea    -0x1e86(%rip),%rdi        # 2630 <dmatrix_vector_multiply_mt_avx._omp_fn.0>
    44b6:	89 44 24 20          	mov    %eax,0x20(%rsp)
    44ba:	e8 71 cd ff ff       	call   1230 <GOMP_parallel@plt>
    44bf:	48 8b 44 24 28       	mov    0x28(%rsp),%rax
    44c4:	64 48 2b 04 25 28 00 	sub    %fs:0x28,%rax
    44cb:	00 00 
    44cd:	75 05                	jne    44d4 <dmatrix_vector_multiply_mt_avx+0x74>
    44cf:	48 83 c4 38          	add    $0x38,%rsp
    44d3:	c3                   	ret    
    44d4:	e8 87 cd ff ff       	call   1260 <__stack_chk_fail@plt>
    44d9:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)

00000000000044e0 <copyMatrix>:
    44e0:	f3 0f 1e fa          	endbr64 
    44e4:	41 56                	push   %r14
    44e6:	41 55                	push   %r13
    44e8:	41 54                	push   %r12
    44ea:	4c 63 ea             	movslq %edx,%r13
    44ed:	55                   	push   %rbp
    44ee:	53                   	push   %rbx
    44ef:	48 63 d9             	movslq %ecx,%rbx
    44f2:	49 89 fc             	mov    %rdi,%r12
    44f5:	48 89 df             	mov    %rbx,%rdi
    44f8:	89 f5                	mov    %esi,%ebp
    44fa:	49 0f af fd          	imul   %r13,%rdi
    44fe:	48 c1 e7 03          	shl    $0x3,%rdi
    4502:	e8 e9 cc ff ff       	call   11f0 <malloc@plt>
    4507:	45 85 ed             	test   %r13d,%r13d
    450a:	7e 40                	jle    454c <copyMatrix+0x6c>
    450c:	85 ed                	test   %ebp,%ebp
    450e:	7e 3c                	jle    454c <copyMatrix+0x6c>
    4510:	48 8d 34 dd 00 00 00 	lea    0x0(,%rbx,8),%rsi
    4517:	00 
    4518:	31 ff                	xor    %edi,%edi
    451a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)
    4520:	48 8d 14 fd 00 00 00 	lea    0x0(,%rdi,8),%rdx
    4527:	00 
    4528:	31 c9                	xor    %ecx,%ecx
    452a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)
    4530:	ff c1                	inc    %ecx
    4532:	c4 c1 7b 10 04 14    	vmovsd (%r12,%rdx,1),%xmm0
    4538:	c5 fb 11 04 10       	vmovsd %xmm0,(%rax,%rdx,1)
    453d:	48 01 f2             	add    %rsi,%rdx
    4540:	39 cd                	cmp    %ecx,%ebp
    4542:	75 ec                	jne    4530 <copyMatrix+0x50>
    4544:	48 ff c7             	inc    %rdi
    4547:	49 39 fd             	cmp    %rdi,%r13
    454a:	75 d4                	jne    4520 <copyMatrix+0x40>
    454c:	5b                   	pop    %rbx
    454d:	5d                   	pop    %rbp
    454e:	41 5c                	pop    %r12
    4550:	41 5d                	pop    %r13
    4552:	41 5e                	pop    %r14
    4554:	c3                   	ret    
    4555:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    455c:	00 00 00 00 

0000000000004560 <Check>:
    4560:	f3 0f 1e fa          	endbr64 
    4564:	41 89 c9             	mov    %ecx,%r9d
    4567:	85 c9                	test   %ecx,%ecx
    4569:	7e 60                	jle    45cb <Check+0x6b>
    456b:	45 31 d2             	xor    %r10d,%r10d
    456e:	45 31 db             	xor    %r11d,%r11d
    4571:	85 d2                	test   %edx,%edx
    4573:	7e 6b                	jle    45e0 <Check+0x80>
    4575:	48 63 d2             	movslq %edx,%rdx
    4578:	c5 fa 7e 15 70 1b 00 	vmovq  0x1b70(%rip),%xmm2        # 60f0 <__PRETTY_FUNCTION__.0+0xb0>
    457f:	00 
    4580:	c5 fb 10 0d 50 1b 00 	vmovsd 0x1b50(%rip),%xmm1        # 60d8 <__PRETTY_FUNCTION__.0+0x98>
    4587:	00 
    4588:	49 63 ca             	movslq %r10d,%rcx
    458b:	48 8d 04 cd 00 00 00 	lea    0x0(,%rcx,8),%rax
    4592:	00 
    4593:	48 01 d1             	add    %rdx,%rcx
    4596:	48 c1 e1 03          	shl    $0x3,%rcx
    459a:	eb 0d                	jmp    45a9 <Check+0x49>
    459c:	0f 1f 40 00          	nopl   0x0(%rax)
    45a0:	48 83 c0 08          	add    $0x8,%rax
    45a4:	48 39 c1             	cmp    %rax,%rcx
    45a7:	74 17                	je     45c0 <Check+0x60>
    45a9:	c5 fb 10 04 07       	vmovsd (%rdi,%rax,1),%xmm0
    45ae:	c5 fb 5c 04 06       	vsubsd (%rsi,%rax,1),%xmm0,%xmm0
    45b3:	c5 f9 54 c2          	vandpd %xmm2,%xmm0,%xmm0
    45b7:	c5 f9 2f c1          	vcomisd %xmm1,%xmm0
    45bb:	76 e3                	jbe    45a0 <Check+0x40>
    45bd:	31 c0                	xor    %eax,%eax
    45bf:	c3                   	ret    
    45c0:	41 ff c3             	inc    %r11d
    45c3:	45 01 c2             	add    %r8d,%r10d
    45c6:	45 39 d9             	cmp    %r11d,%r9d
    45c9:	75 bd                	jne    4588 <Check+0x28>
    45cb:	b8 01 00 00 00       	mov    $0x1,%eax
    45d0:	c3                   	ret    
    45d1:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    45d8:	00 00 00 00 
    45dc:	0f 1f 40 00          	nopl   0x0(%rax)
    45e0:	41 ff c3             	inc    %r11d
    45e3:	45 01 c2             	add    %r8d,%r10d
    45e6:	45 39 d9             	cmp    %r11d,%r9d
    45e9:	75 86                	jne    4571 <Check+0x11>
    45eb:	eb de                	jmp    45cb <Check+0x6b>
    45ed:	0f 1f 00             	nopl   (%rax)

00000000000045f0 <apply_rev_avx_mv>:
    45f0:	f3 0f 1e fa          	endbr64 
    45f4:	55                   	push   %rbp
    45f5:	41 89 d2             	mov    %edx,%r10d
    45f8:	48 89 e5             	mov    %rsp,%rbp
    45fb:	41 57                	push   %r15
    45fd:	41 56                	push   %r14
    45ff:	41 55                	push   %r13
    4601:	48 63 55 18          	movslq 0x18(%rbp),%rdx
    4605:	44 8b 6d 10          	mov    0x10(%rbp),%r13d
    4609:	41 54                	push   %r12
    460b:	53                   	push   %rbx
    460c:	48 89 cb             	mov    %rcx,%rbx
    460f:	48 c1 e2 03          	shl    $0x3,%rdx
    4613:	c4 41 7d 10 44 10 20 	vmovupd 0x20(%r8,%rdx,1),%ymm8
    461a:	49 8d 04 10          	lea    (%r8,%rdx,1),%rax
    461e:	8b 55 18             	mov    0x18(%rbp),%edx
    4621:	41 0f af fd          	imul   %r13d,%edi
    4625:	41 89 fc             	mov    %edi,%r12d
    4628:	48 63 ff             	movslq %edi,%rdi
    462b:	c4 e2 7d 19 1c fb    	vbroadcastsd (%rbx,%rdi,8),%ymm3
    4631:	c5 e5 59 28          	vmulpd (%rax),%ymm3,%ymm5
    4635:	c4 e2 7d 19 54 fb 08 	vbroadcastsd 0x8(%rbx,%rdi,8),%ymm2
    463c:	44 01 ca             	add    %r9d,%edx
    463f:	48 63 ca             	movslq %edx,%rcx
    4642:	44 01 ca             	add    %r9d,%edx
    4645:	48 c1 e1 03          	shl    $0x3,%rcx
    4649:	c4 c1 7d 10 44 08 20 	vmovupd 0x20(%r8,%rcx,1),%ymm0
    4650:	48 63 d2             	movslq %edx,%rdx
    4653:	c4 c1 7d 10 24 08    	vmovupd (%r8,%rcx,1),%ymm4
    4659:	48 c1 e2 03          	shl    $0x3,%rdx
    465d:	c5 3d 59 d3          	vmulpd %ymm3,%ymm8,%ymm10
    4661:	c4 c1 7d 10 7c 10 20 	vmovupd 0x20(%r8,%rdx,1),%ymm7
    4668:	c4 c1 7d 10 0c 10    	vmovupd (%r8,%rdx,1),%ymm1
    466e:	41 8d 54 24 02       	lea    0x2(%r12),%edx
    4673:	45 01 ec             	add    %r13d,%r12d
    4676:	48 63 d2             	movslq %edx,%rdx
    4679:	49 63 cc             	movslq %r12d,%rcx
    467c:	45 01 e5             	add    %r12d,%r13d
    467f:	c4 62 fd b8 d2       	vfmadd231pd %ymm2,%ymm0,%ymm10
    4684:	c5 fd 59 c3          	vmulpd %ymm3,%ymm0,%ymm0
    4688:	c4 e2 dd b8 ea       	vfmadd231pd %ymm2,%ymm4,%ymm5
    468d:	c5 dd 59 e3          	vmulpd %ymm3,%ymm4,%ymm4
    4691:	c4 e2 7d 19 5c fb 18 	vbroadcastsd 0x18(%rbx,%rdi,8),%ymm3
    4698:	c4 62 fd 9c c2       	vfnmadd132pd %ymm2,%ymm0,%ymm8
    469d:	c4 e2 7d 19 04 d3    	vbroadcastsd (%rbx,%rdx,8),%ymm0
    46a3:	c5 fd 28 f4          	vmovapd %ymm4,%ymm6
    46a7:	c4 e2 ed bc 30       	vfnmadd231pd (%rax),%ymm2,%ymm6
    46ac:	c4 e2 7d 19 24 cb    	vbroadcastsd (%rbx,%rcx,8),%ymm4
    46b2:	c5 cd 59 d0          	vmulpd %ymm0,%ymm6,%ymm2
    46b6:	c5 2d 59 cc          	vmulpd %ymm4,%ymm10,%ymm9
    46ba:	c4 e2 e5 b8 d1       	vfmadd231pd %ymm1,%ymm3,%ymm2
    46bf:	c5 fd 59 c9          	vmulpd %ymm1,%ymm0,%ymm1
    46c3:	c4 e2 f5 9c f3       	vfnmadd132pd %ymm3,%ymm1,%ymm6
    46c8:	c5 bd 59 c8          	vmulpd %ymm0,%ymm8,%ymm1
    46cc:	c5 fd 59 c7          	vmulpd %ymm7,%ymm0,%ymm0
    46d0:	c4 e2 e5 b8 cf       	vfmadd231pd %ymm7,%ymm3,%ymm1
    46d5:	c4 62 fd 9c c3       	vfnmadd132pd %ymm3,%ymm0,%ymm8
    46da:	c4 e2 7d 19 5c cb 08 	vbroadcastsd 0x8(%rbx,%rcx,8),%ymm3
    46e1:	c5 dd 59 c5          	vmulpd %ymm5,%ymm4,%ymm0
    46e5:	c5 fd 28 f8          	vmovapd %ymm0,%ymm7
    46e9:	c4 e2 ed b8 fb       	vfmadd231pd %ymm3,%ymm2,%ymm7
    46ee:	c4 62 f5 b8 cb       	vfmadd231pd %ymm3,%ymm1,%ymm9
    46f3:	c5 ed 59 d4          	vmulpd %ymm4,%ymm2,%ymm2
    46f7:	c5 f5 59 cc          	vmulpd %ymm4,%ymm1,%ymm1
    46fb:	c4 e2 ed 9c eb       	vfnmadd132pd %ymm3,%ymm2,%ymm5
    4700:	c4 62 f5 9c d3       	vfnmadd132pd %ymm3,%ymm1,%ymm10
    4705:	41 83 fa 03          	cmp    $0x3,%r10d
    4709:	0f 8e e9 00 00 00    	jle    47f8 <apply_rev_avx_mv+0x208>
    470f:	45 8d 72 fc          	lea    -0x4(%r10),%r14d
    4713:	4d 63 d9             	movslq %r9d,%r11
    4716:	48 8d 54 fb 20       	lea    0x20(%rbx,%rdi,8),%rdx
    471b:	48 8d 74 cb 10       	lea    0x10(%rbx,%rcx,8),%rsi
    4720:	4a 8d 3c 77          	lea    (%rdi,%r14,2),%rdi
    4724:	49 63 cd             	movslq %r13d,%rcx
    4727:	4e 8d 3c dd 00 00 00 	lea    0x0(,%r11,8),%r15
    472e:	00 
    472f:	4c 8d 74 fb 30       	lea    0x30(%rbx,%rdi,8),%r14
    4734:	4b 8d 3c 5b          	lea    (%r11,%r11,2),%rdi
    4738:	48 8d 0c cb          	lea    (%rbx,%rcx,8),%rcx
    473c:	48 c1 e7 03          	shl    $0x3,%rdi
    4740:	c4 e2 7d 19 0a       	vbroadcastsd (%rdx),%ymm1
    4745:	c5 f5 59 14 38       	vmulpd (%rax,%rdi,1),%ymm1,%ymm2
    474a:	c4 e2 7d 19 5a 08    	vbroadcastsd 0x8(%rdx),%ymm3
    4750:	48 83 c2 10          	add    $0x10,%rdx
    4754:	c4 e2 7d 19 26       	vbroadcastsd (%rsi),%ymm4
    4759:	48 83 c1 10          	add    $0x10,%rcx
    475d:	48 83 c6 10          	add    $0x10,%rsi
    4761:	c5 f5 59 c6          	vmulpd %ymm6,%ymm1,%ymm0
    4765:	c4 e2 e5 b8 04 38    	vfmadd231pd (%rax,%rdi,1),%ymm3,%ymm0
    476b:	c4 e2 ed 9c f3       	vfnmadd132pd %ymm3,%ymm2,%ymm6
    4770:	c4 c1 75 59 d0       	vmulpd %ymm8,%ymm1,%ymm2
    4775:	c5 f5 59 4c 38 20    	vmulpd 0x20(%rax,%rdi,1),%ymm1,%ymm1
    477b:	c4 e2 e5 b8 54 38 20 	vfmadd231pd 0x20(%rax,%rdi,1),%ymm3,%ymm2
    4782:	c4 62 f5 9c c3       	vfnmadd132pd %ymm3,%ymm1,%ymm8
    4787:	c4 e2 7d 19 5e f8    	vbroadcastsd -0x8(%rsi),%ymm3
    478d:	c5 dd 59 cd          	vmulpd %ymm5,%ymm4,%ymm1
    4791:	c4 e2 fd b8 cb       	vfmadd231pd %ymm3,%ymm0,%ymm1
    4796:	c5 fd 59 c4          	vmulpd %ymm4,%ymm0,%ymm0
    479a:	c4 e2 fd 9c eb       	vfnmadd132pd %ymm3,%ymm0,%ymm5
    479f:	c4 c1 5d 59 c2       	vmulpd %ymm10,%ymm4,%ymm0
    47a4:	c4 e2 ed b8 c3       	vfmadd231pd %ymm3,%ymm2,%ymm0
    47a9:	c5 ed 59 d4          	vmulpd %ymm4,%ymm2,%ymm2
    47ad:	c4 62 ed 9c d3       	vfnmadd132pd %ymm3,%ymm2,%ymm10
    47b2:	c4 e2 7d 19 59 f0    	vbroadcastsd -0x10(%rcx),%ymm3
    47b8:	c4 e2 7d 19 51 f8    	vbroadcastsd -0x8(%rcx),%ymm2
    47be:	c5 e5 59 e7          	vmulpd %ymm7,%ymm3,%ymm4
    47c2:	c4 e2 f5 b8 e2       	vfmadd231pd %ymm2,%ymm1,%ymm4
    47c7:	c5 f5 59 cb          	vmulpd %ymm3,%ymm1,%ymm1
    47cb:	c4 e2 f5 9c fa       	vfnmadd132pd %ymm2,%ymm1,%ymm7
    47d0:	c4 c1 65 59 c9       	vmulpd %ymm9,%ymm3,%ymm1
    47d5:	c5 fd 11 20          	vmovupd %ymm4,(%rax)
    47d9:	c4 e2 fd b8 ca       	vfmadd231pd %ymm2,%ymm0,%ymm1
    47de:	c5 fd 59 c3          	vmulpd %ymm3,%ymm0,%ymm0
    47e2:	c4 62 fd 9c ca       	vfnmadd132pd %ymm2,%ymm0,%ymm9
    47e7:	c5 fd 11 48 20       	vmovupd %ymm1,0x20(%rax)
    47ec:	4c 01 f8             	add    %r15,%rax
    47ef:	49 39 d6             	cmp    %rdx,%r14
    47f2:	0f 85 48 ff ff ff    	jne    4740 <apply_rev_avx_mv+0x150>
    47f8:	43 8d 44 12 fc       	lea    -0x4(%r10,%r10,1),%eax
    47fd:	41 83 ea 03          	sub    $0x3,%r10d
    4801:	41 01 c4             	add    %eax,%r12d
    4804:	45 0f af d1          	imul   %r9d,%r10d
    4808:	42 8d 54 28 fe       	lea    -0x2(%rax,%r13,1),%edx
    480d:	44 01 e8             	add    %r13d,%eax
    4810:	4d 63 e4             	movslq %r12d,%r12
    4813:	48 63 d2             	movslq %edx,%rdx
    4816:	48 98                	cltq   
    4818:	c4 a2 7d 19 0c e3    	vbroadcastsd (%rbx,%r12,8),%ymm1
    481e:	c4 a2 7d 19 44 e3 08 	vbroadcastsd 0x8(%rbx,%r12,8),%ymm0
    4825:	c4 e2 7d 19 1c d3    	vbroadcastsd (%rbx,%rdx,8),%ymm3
    482b:	c5 f5 59 e5          	vmulpd %ymm5,%ymm1,%ymm4
    482f:	c5 fd 28 d0          	vmovapd %ymm0,%ymm2
    4833:	c4 e2 fd b8 e6       	vfmadd231pd %ymm6,%ymm0,%ymm4
    4838:	c5 f5 59 f6          	vmulpd %ymm6,%ymm1,%ymm6
    483c:	c4 e2 cd 9c e8       	vfnmadd132pd %ymm0,%ymm6,%ymm5
    4841:	c4 c1 75 59 f2       	vmulpd %ymm10,%ymm1,%ymm6
    4846:	c4 c1 75 59 c8       	vmulpd %ymm8,%ymm1,%ymm1
    484b:	c4 c2 fd b8 f0       	vfmadd231pd %ymm8,%ymm0,%ymm6
    4850:	c5 65 59 c7          	vmulpd %ymm7,%ymm3,%ymm8
    4854:	c4 c2 f5 9c d2       	vfnmadd132pd %ymm10,%ymm1,%ymm2
    4859:	c4 e2 7d 19 4c d3 08 	vbroadcastsd 0x8(%rbx,%rdx,8),%ymm1
    4860:	c4 62 f5 b8 c4       	vfmadd231pd %ymm4,%ymm1,%ymm8
    4865:	c5 e5 59 e4          	vmulpd %ymm4,%ymm3,%ymm4
    4869:	c4 e2 dd 9c f9       	vfnmadd132pd %ymm1,%ymm4,%ymm7
    486e:	c4 e2 7d 19 64 c3 08 	vbroadcastsd 0x8(%rbx,%rax,8),%ymm4
    4875:	c5 fd 28 c7          	vmovapd %ymm7,%ymm0
    4879:	c4 c1 65 59 f9       	vmulpd %ymm9,%ymm3,%ymm7
    487e:	c5 e5 59 de          	vmulpd %ymm6,%ymm3,%ymm3
    4882:	c4 e2 f5 b8 fe       	vfmadd231pd %ymm6,%ymm1,%ymm7
    4887:	c4 c2 e5 9c c9       	vfnmadd132pd %ymm9,%ymm3,%ymm1
    488c:	c4 e2 7d 19 1c c3    	vbroadcastsd (%rbx,%rax,8),%ymm3
    4892:	8b 45 18             	mov    0x18(%rbp),%eax
    4895:	44 01 d0             	add    %r10d,%eax
    4898:	45 01 ca             	add    %r9d,%r10d
    489b:	c5 fd 59 f3          	vmulpd %ymm3,%ymm0,%ymm6
    489f:	48 98                	cltq   
    48a1:	48 c1 e0 03          	shl    $0x3,%rax
    48a5:	c4 e2 dd b8 f5       	vfmadd231pd %ymm5,%ymm4,%ymm6
    48aa:	c5 e5 59 ed          	vmulpd %ymm5,%ymm3,%ymm5
    48ae:	c4 41 7d 11 04 00    	vmovupd %ymm8,(%r8,%rax,1)
    48b4:	c4 c1 7d 11 7c 00 20 	vmovupd %ymm7,0x20(%r8,%rax,1)
    48bb:	8b 45 18             	mov    0x18(%rbp),%eax
    48be:	c4 e2 d5 9c c4       	vfnmadd132pd %ymm4,%ymm5,%ymm0
    48c3:	c5 f5 59 eb          	vmulpd %ymm3,%ymm1,%ymm5
    48c7:	c5 e5 59 da          	vmulpd %ymm2,%ymm3,%ymm3
    48cb:	c4 e2 dd b8 ea       	vfmadd231pd %ymm2,%ymm4,%ymm5
    48d0:	44 01 d0             	add    %r10d,%eax
    48d3:	48 98                	cltq   
    48d5:	c4 e2 e5 9c cc       	vfnmadd132pd %ymm4,%ymm3,%ymm1
    48da:	48 c1 e0 03          	shl    $0x3,%rax
    48de:	c4 c1 7d 11 34 00    	vmovupd %ymm6,(%r8,%rax,1)
    48e4:	c4 c1 7d 11 6c 00 20 	vmovupd %ymm5,0x20(%r8,%rax,1)
    48eb:	43 8d 04 0a          	lea    (%r10,%r9,1),%eax
    48ef:	03 45 18             	add    0x18(%rbp),%eax
    48f2:	48 98                	cltq   
    48f4:	48 c1 e0 03          	shl    $0x3,%rax
    48f8:	c4 c1 7d 11 04 00    	vmovupd %ymm0,(%r8,%rax,1)
    48fe:	c4 c1 7d 11 4c 00 20 	vmovupd %ymm1,0x20(%r8,%rax,1)
    4905:	c5 f8 77             	vzeroupper 
    4908:	5b                   	pop    %rbx
    4909:	41 5c                	pop    %r12
    490b:	41 5d                	pop    %r13
    490d:	41 5e                	pop    %r14
    490f:	41 5f                	pop    %r15
    4911:	5d                   	pop    %rbp
    4912:	c3                   	ret    
    4913:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    491a:	00 00 00 00 
    491e:	66 90                	xchg   %ax,%ax

0000000000004920 <apply_rev_avx_mv_seq_avx256>:
    4920:	f3 0f 1e fa          	endbr64 
    4924:	41 0f af f9          	imul   %r9d,%edi
    4928:	55                   	push   %rbp
    4929:	41 89 d3             	mov    %edx,%r11d
    492c:	49 89 ca             	mov    %rcx,%r10
    492f:	48 89 e5             	mov    %rsp,%rbp
    4932:	41 54                	push   %r12
    4934:	53                   	push   %rbx
    4935:	41 8d 5b fd          	lea    -0x3(%r11),%ebx
    4939:	48 63 d7             	movslq %edi,%rdx
    493c:	8d 47 02             	lea    0x2(%rdi),%eax
    493f:	44 01 cf             	add    %r9d,%edi
    4942:	c4 e2 7d 19 04 d1    	vbroadcastsd (%rcx,%rdx,8),%ymm0
    4948:	c4 c1 7d 59 50 40    	vmulpd 0x40(%r8),%ymm0,%ymm2
    494e:	48 98                	cltq   
    4950:	c4 e2 7d 19 4c d1 08 	vbroadcastsd 0x8(%rcx,%rdx,8),%ymm1
    4957:	c4 c1 7d 59 28       	vmulpd (%r8),%ymm0,%ymm5
    495c:	c4 41 7d 59 50 20    	vmulpd 0x20(%r8),%ymm0,%ymm10
    4962:	c4 e2 7d 19 5c d1 18 	vbroadcastsd 0x18(%rcx,%rdx,8),%ymm3
    4969:	46 8d 24 0f          	lea    (%rdi,%r9,1),%r12d
    496d:	c4 c1 7d 59 40 60    	vmulpd 0x60(%r8),%ymm0,%ymm0
    4973:	c4 c2 f5 b8 68 40    	vfmadd231pd 0x40(%r8),%ymm1,%ymm5
    4979:	c4 42 f5 b8 50 60    	vfmadd231pd 0x60(%r8),%ymm1,%ymm10
    497f:	c5 fd 28 f2          	vmovapd %ymm2,%ymm6
    4983:	c4 c2 f5 bc 30       	vfnmadd231pd (%r8),%ymm1,%ymm6
    4988:	c4 c2 fd 9c 48 20    	vfnmadd132pd 0x20(%r8),%ymm0,%ymm1
    498e:	c4 e2 7d 19 04 c1    	vbroadcastsd (%rcx,%rax,8),%ymm0
    4994:	c5 7d 28 c1          	vmovapd %ymm1,%ymm8
    4998:	c4 c1 7d 59 88 80 00 	vmulpd 0x80(%r8),%ymm0,%ymm1
    499f:	00 00 
    49a1:	48 63 cf             	movslq %edi,%rcx
    49a4:	c4 c2 7d 19 24 ca    	vbroadcastsd (%r10,%rcx,8),%ymm4
    49aa:	c5 cd 59 d0          	vmulpd %ymm0,%ymm6,%ymm2
    49ae:	c4 c2 e5 b8 90 80 00 	vfmadd231pd 0x80(%r8),%ymm3,%ymm2
    49b5:	00 00 
    49b7:	c5 2d 59 cc          	vmulpd %ymm4,%ymm10,%ymm9
    49bb:	c4 e2 f5 9c f3       	vfnmadd132pd %ymm3,%ymm1,%ymm6
    49c0:	c5 bd 59 c8          	vmulpd %ymm0,%ymm8,%ymm1
    49c4:	c4 c1 7d 59 80 a0 00 	vmulpd 0xa0(%r8),%ymm0,%ymm0
    49cb:	00 00 
    49cd:	c4 c2 e5 b8 88 a0 00 	vfmadd231pd 0xa0(%r8),%ymm3,%ymm1
    49d4:	00 00 
    49d6:	c4 62 fd 9c c3       	vfnmadd132pd %ymm3,%ymm0,%ymm8
    49db:	c4 c2 7d 19 5c ca 08 	vbroadcastsd 0x8(%r10,%rcx,8),%ymm3
    49e2:	c5 dd 59 c5          	vmulpd %ymm5,%ymm4,%ymm0
    49e6:	c5 fd 28 f8          	vmovapd %ymm0,%ymm7
    49ea:	c4 e2 ed b8 fb       	vfmadd231pd %ymm3,%ymm2,%ymm7
    49ef:	c4 62 f5 b8 cb       	vfmadd231pd %ymm3,%ymm1,%ymm9
    49f4:	c5 ed 59 d4          	vmulpd %ymm4,%ymm2,%ymm2
    49f8:	c5 f5 59 cc          	vmulpd %ymm4,%ymm1,%ymm1
    49fc:	c4 e2 ed 9c eb       	vfnmadd132pd %ymm3,%ymm2,%ymm5
    4a01:	c4 62 f5 9c d3       	vfnmadd132pd %ymm3,%ymm1,%ymm10
    4a06:	41 83 fb 03          	cmp    $0x3,%r11d
    4a0a:	0f 8e f5 00 00 00    	jle    4b05 <apply_rev_avx_mv_seq_avx256+0x1e5>
    4a10:	45 8d 4b fd          	lea    -0x3(%r11),%r9d
    4a14:	49 8d 74 d2 28       	lea    0x28(%r10,%rdx,8),%rsi
    4a19:	49 63 d4             	movslq %r12d,%rdx
    4a1c:	4c 89 c0             	mov    %r8,%rax
    4a1f:	4c 89 cb             	mov    %r9,%rbx
    4a22:	49 8d 4c ca 18       	lea    0x18(%r10,%rcx,8),%rcx
    4a27:	49 8d 54 d2 08       	lea    0x8(%r10,%rdx,8),%rdx
    4a2c:	49 c1 e1 06          	shl    $0x6,%r9
    4a30:	4d 01 c1             	add    %r8,%r9
    4a33:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    4a3a:	00 00 00 00 
    4a3e:	66 90                	xchg   %ax,%ax
    4a40:	c4 e2 7d 19 4e f8    	vbroadcastsd -0x8(%rsi),%ymm1
    4a46:	c5 f5 59 90 c0 00 00 	vmulpd 0xc0(%rax),%ymm1,%ymm2
    4a4d:	00 
    4a4e:	c4 e2 7d 19 1e       	vbroadcastsd (%rsi),%ymm3
    4a53:	48 83 c0 40          	add    $0x40,%rax
    4a57:	c4 e2 7d 19 61 f8    	vbroadcastsd -0x8(%rcx),%ymm4
    4a5d:	48 83 c6 10          	add    $0x10,%rsi
    4a61:	48 83 c1 10          	add    $0x10,%rcx
    4a65:	48 83 c2 10          	add    $0x10,%rdx
    4a69:	c5 f5 59 c6          	vmulpd %ymm6,%ymm1,%ymm0
    4a6d:	c4 e2 e5 b8 80 80 00 	vfmadd231pd 0x80(%rax),%ymm3,%ymm0
    4a74:	00 00 
    4a76:	c4 e2 ed 9c f3       	vfnmadd132pd %ymm3,%ymm2,%ymm6
    4a7b:	c4 c1 75 59 d0       	vmulpd %ymm8,%ymm1,%ymm2
    4a80:	c5 f5 59 88 a0 00 00 	vmulpd 0xa0(%rax),%ymm1,%ymm1
    4a87:	00 
    4a88:	c4 e2 e5 b8 90 a0 00 	vfmadd231pd 0xa0(%rax),%ymm3,%ymm2
    4a8f:	00 00 
    4a91:	c4 62 f5 9c c3       	vfnmadd132pd %ymm3,%ymm1,%ymm8
    4a96:	c4 e2 7d 19 59 f0    	vbroadcastsd -0x10(%rcx),%ymm3
    4a9c:	c5 dd 59 cd          	vmulpd %ymm5,%ymm4,%ymm1
    4aa0:	c4 e2 fd b8 cb       	vfmadd231pd %ymm3,%ymm0,%ymm1
    4aa5:	c5 fd 59 c4          	vmulpd %ymm4,%ymm0,%ymm0
    4aa9:	c4 e2 fd 9c eb       	vfnmadd132pd %ymm3,%ymm0,%ymm5
    4aae:	c4 c1 5d 59 c2       	vmulpd %ymm10,%ymm4,%ymm0
    4ab3:	c4 e2 ed b8 c3       	vfmadd231pd %ymm3,%ymm2,%ymm0
    4ab8:	c5 ed 59 d4          	vmulpd %ymm4,%ymm2,%ymm2
    4abc:	c4 62 ed 9c d3       	vfnmadd132pd %ymm3,%ymm2,%ymm10
    4ac1:	c4 e2 7d 19 5a e8    	vbroadcastsd -0x18(%rdx),%ymm3
    4ac7:	c4 e2 7d 19 52 f0    	vbroadcastsd -0x10(%rdx),%ymm2
    4acd:	c5 e5 59 e7          	vmulpd %ymm7,%ymm3,%ymm4
    4ad1:	c4 e2 f5 b8 e2       	vfmadd231pd %ymm2,%ymm1,%ymm4
    4ad6:	c5 f5 59 cb          	vmulpd %ymm3,%ymm1,%ymm1
    4ada:	c4 e2 f5 9c fa       	vfnmadd132pd %ymm2,%ymm1,%ymm7
    4adf:	c4 c1 65 59 c9       	vmulpd %ymm9,%ymm3,%ymm1
    4ae4:	c5 fd 11 60 c0       	vmovupd %ymm4,-0x40(%rax)
    4ae9:	c4 e2 fd b8 ca       	vfmadd231pd %ymm2,%ymm0,%ymm1
    4aee:	c5 fd 59 c3          	vmulpd %ymm3,%ymm0,%ymm0
    4af2:	c4 62 fd 9c ca       	vfnmadd132pd %ymm2,%ymm0,%ymm9
    4af7:	c5 fd 11 48 e0       	vmovupd %ymm1,-0x20(%rax)
    4afc:	49 39 c1             	cmp    %rax,%r9
    4aff:	0f 85 3b ff ff ff    	jne    4a40 <apply_rev_avx_mv_seq_avx256+0x120>
    4b05:	43 8d 44 1b fc       	lea    -0x4(%r11,%r11,1),%eax
    4b0a:	01 c7                	add    %eax,%edi
    4b0c:	42 8d 54 20 fe       	lea    -0x2(%rax,%r12,1),%edx
    4b11:	44 01 e0             	add    %r12d,%eax
    4b14:	48 63 ff             	movslq %edi,%rdi
    4b17:	48 63 d2             	movslq %edx,%rdx
    4b1a:	48 98                	cltq   
    4b1c:	c4 c2 7d 19 0c fa    	vbroadcastsd (%r10,%rdi,8),%ymm1
    4b22:	c4 c2 7d 19 44 fa 08 	vbroadcastsd 0x8(%r10,%rdi,8),%ymm0
    4b29:	c4 c2 7d 19 1c d2    	vbroadcastsd (%r10,%rdx,8),%ymm3
    4b2f:	c5 f5 59 e5          	vmulpd %ymm5,%ymm1,%ymm4
    4b33:	c5 fd 28 d0          	vmovapd %ymm0,%ymm2
    4b37:	c4 e2 fd b8 e6       	vfmadd231pd %ymm6,%ymm0,%ymm4
    4b3c:	c5 f5 59 f6          	vmulpd %ymm6,%ymm1,%ymm6
    4b40:	c4 e2 cd 9c e8       	vfnmadd132pd %ymm0,%ymm6,%ymm5
    4b45:	c4 c1 75 59 f2       	vmulpd %ymm10,%ymm1,%ymm6
    4b4a:	c4 c1 75 59 c8       	vmulpd %ymm8,%ymm1,%ymm1
    4b4f:	c4 c2 fd b8 f0       	vfmadd231pd %ymm8,%ymm0,%ymm6
    4b54:	c5 65 59 c7          	vmulpd %ymm7,%ymm3,%ymm8
    4b58:	c4 c2 f5 9c d2       	vfnmadd132pd %ymm10,%ymm1,%ymm2
    4b5d:	c4 c2 7d 19 4c d2 08 	vbroadcastsd 0x8(%r10,%rdx,8),%ymm1
    4b64:	c4 62 f5 b8 c4       	vfmadd231pd %ymm4,%ymm1,%ymm8
    4b69:	c5 e5 59 e4          	vmulpd %ymm4,%ymm3,%ymm4
    4b6d:	c4 e2 dd 9c f9       	vfnmadd132pd %ymm1,%ymm4,%ymm7
    4b72:	c4 c2 7d 19 64 c2 08 	vbroadcastsd 0x8(%r10,%rax,8),%ymm4
    4b79:	c5 fd 28 c7          	vmovapd %ymm7,%ymm0
    4b7d:	c4 c1 65 59 f9       	vmulpd %ymm9,%ymm3,%ymm7
    4b82:	c5 e5 59 de          	vmulpd %ymm6,%ymm3,%ymm3
    4b86:	c4 e2 f5 b8 fe       	vfmadd231pd %ymm6,%ymm1,%ymm7
    4b8b:	c4 c2 e5 9c c9       	vfnmadd132pd %ymm9,%ymm3,%ymm1
    4b90:	c4 c2 7d 19 1c c2    	vbroadcastsd (%r10,%rax,8),%ymm3
    4b96:	8d 04 dd 00 00 00 00 	lea    0x0(,%rbx,8),%eax
    4b9d:	48 63 c8             	movslq %eax,%rcx
    4ba0:	48 8d 14 cd 00 00 00 	lea    0x0(,%rcx,8),%rdx
    4ba7:	00 
    4ba8:	c4 41 7d 11 04 10    	vmovupd %ymm8,(%r8,%rdx,1)
    4bae:	c4 c1 7d 11 7c c8 20 	vmovupd %ymm7,0x20(%r8,%rcx,8)
    4bb5:	8d 48 0c             	lea    0xc(%rax),%ecx
    4bb8:	83 c0 14             	add    $0x14,%eax
    4bbb:	48 63 c9             	movslq %ecx,%rcx
    4bbe:	48 98                	cltq   
    4bc0:	c5 fd 59 f3          	vmulpd %ymm3,%ymm0,%ymm6
    4bc4:	c4 e2 dd b8 f5       	vfmadd231pd %ymm5,%ymm4,%ymm6
    4bc9:	c5 e5 59 ed          	vmulpd %ymm5,%ymm3,%ymm5
    4bcd:	c4 e2 d5 9c c4       	vfnmadd132pd %ymm4,%ymm5,%ymm0
    4bd2:	c5 f5 59 eb          	vmulpd %ymm3,%ymm1,%ymm5
    4bd6:	c5 e5 59 da          	vmulpd %ymm2,%ymm3,%ymm3
    4bda:	c4 c1 7d 11 74 10 40 	vmovupd %ymm6,0x40(%r8,%rdx,1)
    4be1:	c4 e2 dd b8 ea       	vfmadd231pd %ymm2,%ymm4,%ymm5
    4be6:	c4 e2 e5 9c cc       	vfnmadd132pd %ymm4,%ymm3,%ymm1
    4beb:	c4 c1 7d 11 2c c8    	vmovupd %ymm5,(%r8,%rcx,8)
    4bf1:	c4 c1 7d 11 84 10 80 	vmovupd %ymm0,0x80(%r8,%rdx,1)
    4bf8:	00 00 00 
    4bfb:	c4 c1 7d 11 0c c0    	vmovupd %ymm1,(%r8,%rax,8)
    4c01:	c5 f8 77             	vzeroupper 
    4c04:	5b                   	pop    %rbx
    4c05:	41 5c                	pop    %r12
    4c07:	5d                   	pop    %rbp
    4c08:	c3                   	ret    
    4c09:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)

0000000000004c10 <apply_rev_avx_mv_seq>:
    4c10:	f3 0f 1e fa          	endbr64 
    4c14:	41 0f af f9          	imul   %r9d,%edi
    4c18:	55                   	push   %rbp
    4c19:	41 89 d3             	mov    %edx,%r11d
    4c1c:	48 89 ce             	mov    %rcx,%rsi
    4c1f:	48 89 e5             	mov    %rsp,%rbp
    4c22:	41 54                	push   %r12
    4c24:	53                   	push   %rbx
    4c25:	41 8d 5b fd          	lea    -0x3(%r11),%ebx
    4c29:	48 63 c7             	movslq %edi,%rax
    4c2c:	8d 57 02             	lea    0x2(%rdi),%edx
    4c2f:	44 01 cf             	add    %r9d,%edi
    4c32:	62 f2 fd 48 19 04 c1 	vbroadcastsd (%rcx,%rax,8),%zmm0
    4c39:	62 d1 fd 48 59 48 02 	vmulpd 0x80(%r8),%zmm0,%zmm1
    4c40:	48 63 d2             	movslq %edx,%rdx
    4c43:	62 f2 fd 48 19 7c c1 	vbroadcastsd 0x8(%rcx,%rax,8),%zmm7
    4c4a:	01 
    4c4b:	62 d1 fd 48 59 28    	vmulpd (%r8),%zmm0,%zmm5
    4c51:	62 f2 fd 48 19 5c c1 	vbroadcastsd 0x18(%rcx,%rax,8),%zmm3
    4c58:	03 
    4c59:	48 63 c7             	movslq %edi,%rax
    4c5c:	46 8d 24 0f          	lea    (%rdi,%r9,1),%r12d
    4c60:	62 51 fd 48 59 50 01 	vmulpd 0x40(%r8),%zmm0,%zmm10
    4c67:	62 f2 fd 48 19 24 c1 	vbroadcastsd (%rcx,%rax,8),%zmm4
    4c6e:	62 d1 fd 48 59 40 03 	vmulpd 0xc0(%r8),%zmm0,%zmm0
    4c75:	62 d2 c5 48 b8 68 02 	vfmadd231pd 0x80(%r8),%zmm7,%zmm5
    4c7c:	62 52 c5 48 b8 50 03 	vfmadd231pd 0xc0(%r8),%zmm7,%zmm10
    4c83:	62 71 ad 48 59 cc    	vmulpd %zmm4,%zmm10,%zmm9
    4c89:	62 f1 fd 48 28 f1    	vmovapd %zmm1,%zmm6
    4c8f:	62 d2 c5 48 bc 30    	vfnmadd231pd (%r8),%zmm7,%zmm6
    4c95:	62 d2 fd 48 9c 78 01 	vfnmadd132pd 0x40(%r8),%zmm0,%zmm7
    4c9c:	62 f2 fd 48 19 04 d1 	vbroadcastsd (%rcx,%rdx,8),%zmm0
    4ca3:	62 d1 fd 48 59 48 04 	vmulpd 0x100(%r8),%zmm0,%zmm1
    4caa:	62 f1 cd 48 59 d0    	vmulpd %zmm0,%zmm6,%zmm2
    4cb0:	62 d2 e5 48 b8 50 04 	vfmadd231pd 0x100(%r8),%zmm3,%zmm2
    4cb7:	62 f2 f5 48 9c f3    	vfnmadd132pd %zmm3,%zmm1,%zmm6
    4cbd:	62 f1 c5 48 59 c8    	vmulpd %zmm0,%zmm7,%zmm1
    4cc3:	62 d2 e5 48 b8 48 05 	vfmadd231pd 0x140(%r8),%zmm3,%zmm1
    4cca:	62 d1 fd 48 59 40 05 	vmulpd 0x140(%r8),%zmm0,%zmm0
    4cd1:	62 f2 fd 48 9c fb    	vfnmadd132pd %zmm3,%zmm0,%zmm7
    4cd7:	62 f1 d5 48 59 c4    	vmulpd %zmm4,%zmm5,%zmm0
    4cdd:	62 f2 fd 48 19 5c c1 	vbroadcastsd 0x8(%rcx,%rax,8),%zmm3
    4ce4:	01 
    4ce5:	62 f2 ed 48 b8 c3    	vfmadd231pd %zmm3,%zmm2,%zmm0
    4ceb:	62 72 f5 48 b8 cb    	vfmadd231pd %zmm3,%zmm1,%zmm9
    4cf1:	62 f1 ed 48 59 d4    	vmulpd %zmm4,%zmm2,%zmm2
    4cf7:	62 f1 f5 48 59 cc    	vmulpd %zmm4,%zmm1,%zmm1
    4cfd:	62 71 fd 48 28 c0    	vmovapd %zmm0,%zmm8
    4d03:	62 f2 ed 48 9c eb    	vfnmadd132pd %zmm3,%zmm2,%zmm5
    4d09:	62 72 f5 48 9c d3    	vfnmadd132pd %zmm3,%zmm1,%zmm10
    4d0f:	41 83 fb 03          	cmp    $0x3,%r11d
    4d13:	0f 8e 07 01 00 00    	jle    4e20 <apply_rev_avx_mv_seq+0x210>
    4d19:	45 8d 53 fd          	lea    -0x3(%r11),%r10d
    4d1d:	4d 63 c9             	movslq %r9d,%r9
    4d20:	48 8d 44 c1 10       	lea    0x10(%rcx,%rax,8),%rax
    4d25:	4c 89 c2             	mov    %r8,%rdx
    4d28:	4c 89 d3             	mov    %r10,%rbx
    4d2b:	4c 89 c9             	mov    %r9,%rcx
    4d2e:	49 c1 e2 07          	shl    $0x7,%r10
    4d32:	48 f7 d9             	neg    %rcx
    4d35:	4d 01 c2             	add    %r8,%r10
    4d38:	0f 1f 84 00 00 00 00 	nopl   0x0(%rax,%rax,1)
    4d3f:	00 
    4d40:	62 f2 fd 48 19 4c c8 	vbroadcastsd 0x10(%rax,%rcx,8),%zmm1
    4d47:	02 
    4d48:	62 f1 f5 48 59 52 06 	vmulpd 0x180(%rdx),%zmm1,%zmm2
    4d4f:	62 f2 fd 48 19 5c c8 	vbroadcastsd 0x18(%rax,%rcx,8),%zmm3
    4d56:	03 
    4d57:	48 83 ea 80          	sub    $0xffffffffffffff80,%rdx
    4d5b:	62 f2 fd 48 19 20    	vbroadcastsd (%rax),%zmm4
    4d61:	62 f1 f5 48 59 c6    	vmulpd %zmm6,%zmm1,%zmm0
    4d67:	62 f2 e5 48 b8 42 04 	vfmadd231pd 0x100(%rdx),%zmm3,%zmm0
    4d6e:	62 f2 ed 48 9c f3    	vfnmadd132pd %zmm3,%zmm2,%zmm6
    4d74:	62 f1 f5 48 59 d7    	vmulpd %zmm7,%zmm1,%zmm2
    4d7a:	62 f2 e5 48 b8 52 05 	vfmadd231pd 0x140(%rdx),%zmm3,%zmm2
    4d81:	62 f1 f5 48 59 4a 05 	vmulpd 0x140(%rdx),%zmm1,%zmm1
    4d88:	62 f2 f5 48 9c fb    	vfnmadd132pd %zmm3,%zmm1,%zmm7
    4d8e:	62 f1 dd 48 59 cd    	vmulpd %zmm5,%zmm4,%zmm1
    4d94:	62 f2 fd 48 19 58 01 	vbroadcastsd 0x8(%rax),%zmm3
    4d9b:	62 f2 fd 48 b8 cb    	vfmadd231pd %zmm3,%zmm0,%zmm1
    4da1:	62 f1 fd 48 59 c4    	vmulpd %zmm4,%zmm0,%zmm0
    4da7:	62 f2 fd 48 9c eb    	vfnmadd132pd %zmm3,%zmm0,%zmm5
    4dad:	62 d1 dd 48 59 c2    	vmulpd %zmm10,%zmm4,%zmm0
    4db3:	62 f2 ed 48 b8 c3    	vfmadd231pd %zmm3,%zmm2,%zmm0
    4db9:	62 f1 ed 48 59 d4    	vmulpd %zmm4,%zmm2,%zmm2
    4dbf:	62 72 ed 48 9c d3    	vfnmadd132pd %zmm3,%zmm2,%zmm10
    4dc5:	62 b2 fd 48 19 5c c8 	vbroadcastsd -0x10(%rax,%r9,8),%zmm3
    4dcc:	fe 
    4dcd:	62 b2 fd 48 19 54 c8 	vbroadcastsd -0x8(%rax,%r9,8),%zmm2
    4dd4:	ff 
    4dd5:	48 83 c0 10          	add    $0x10,%rax
    4dd9:	62 d1 e5 48 59 e0    	vmulpd %zmm8,%zmm3,%zmm4
    4ddf:	62 f2 f5 48 b8 e2    	vfmadd231pd %zmm2,%zmm1,%zmm4
    4de5:	62 f1 f5 48 59 cb    	vmulpd %zmm3,%zmm1,%zmm1
    4deb:	62 72 f5 48 9c c2    	vfnmadd132pd %zmm2,%zmm1,%zmm8
    4df1:	62 d1 e5 48 59 c9    	vmulpd %zmm9,%zmm3,%zmm1
    4df7:	62 f1 fd 48 11 62 fe 	vmovupd %zmm4,-0x80(%rdx)
    4dfe:	62 f2 fd 48 b8 ca    	vfmadd231pd %zmm2,%zmm0,%zmm1
    4e04:	62 f1 fd 48 59 c3    	vmulpd %zmm3,%zmm0,%zmm0
    4e0a:	62 72 fd 48 9c ca    	vfnmadd132pd %zmm2,%zmm0,%zmm9
    4e10:	62 f1 fd 48 11 4a ff 	vmovupd %zmm1,-0x40(%rdx)
    4e17:	49 39 d2             	cmp    %rdx,%r10
    4e1a:	0f 85 20 ff ff ff    	jne    4d40 <apply_rev_avx_mv_seq+0x130>
    4e20:	43 8d 44 1b fc       	lea    -0x4(%r11,%r11,1),%eax
    4e25:	01 c7                	add    %eax,%edi
    4e27:	42 8d 54 20 fe       	lea    -0x2(%rax,%r12,1),%edx
    4e2c:	44 01 e0             	add    %r12d,%eax
    4e2f:	48 63 ff             	movslq %edi,%rdi
    4e32:	48 63 d2             	movslq %edx,%rdx
    4e35:	48 98                	cltq   
    4e37:	62 f2 fd 48 19 0c fe 	vbroadcastsd (%rsi,%rdi,8),%zmm1
    4e3e:	62 f2 fd 48 19 44 fe 	vbroadcastsd 0x8(%rsi,%rdi,8),%zmm0
    4e45:	01 
    4e46:	62 f1 f5 48 59 e5    	vmulpd %zmm5,%zmm1,%zmm4
    4e4c:	62 d1 f5 48 59 da    	vmulpd %zmm10,%zmm1,%zmm3
    4e52:	62 f1 fd 48 28 d0    	vmovapd %zmm0,%zmm2
    4e58:	62 f2 fd 48 b8 e6    	vfmadd231pd %zmm6,%zmm0,%zmm4
    4e5e:	62 f1 f5 48 59 f6    	vmulpd %zmm6,%zmm1,%zmm6
    4e64:	62 f1 f5 48 59 cf    	vmulpd %zmm7,%zmm1,%zmm1
    4e6a:	62 f2 fd 48 b8 df    	vfmadd231pd %zmm7,%zmm0,%zmm3
    4e70:	62 f2 cd 48 9c e8    	vfnmadd132pd %zmm0,%zmm6,%zmm5
    4e76:	62 f2 fd 48 19 34 d6 	vbroadcastsd (%rsi,%rdx,8),%zmm6
    4e7d:	62 d1 fd 48 28 c0    	vmovapd %zmm8,%zmm0
    4e83:	62 d2 f5 48 9c d2    	vfnmadd132pd %zmm10,%zmm1,%zmm2
    4e89:	62 f2 fd 48 19 4c d6 	vbroadcastsd 0x8(%rsi,%rdx,8),%zmm1
    4e90:	01 
    4e91:	62 51 cd 48 59 d0    	vmulpd %zmm8,%zmm6,%zmm10
    4e97:	62 d1 cd 48 59 f9    	vmulpd %zmm9,%zmm6,%zmm7
    4e9d:	62 72 dd 48 b8 d1    	vfmadd231pd %zmm1,%zmm4,%zmm10
    4ea3:	62 f1 dd 48 59 e6    	vmulpd %zmm6,%zmm4,%zmm4
    4ea9:	62 f2 e5 48 b8 f9    	vfmadd231pd %zmm1,%zmm3,%zmm7
    4eaf:	62 f1 e5 48 59 de    	vmulpd %zmm6,%zmm3,%zmm3
    4eb5:	62 f2 dd 48 9c c1    	vfnmadd132pd %zmm1,%zmm4,%zmm0
    4ebb:	62 f2 fd 48 19 24 c6 	vbroadcastsd (%rsi,%rax,8),%zmm4
    4ec2:	62 d2 e5 48 9c c9    	vfnmadd132pd %zmm9,%zmm3,%zmm1
    4ec8:	62 f2 fd 48 19 5c c6 	vbroadcastsd 0x8(%rsi,%rax,8),%zmm3
    4ecf:	01 
    4ed0:	89 d8                	mov    %ebx,%eax
    4ed2:	c1 e0 04             	shl    $0x4,%eax
    4ed5:	48 63 c8             	movslq %eax,%rcx
    4ed8:	62 f1 fd 48 59 f4    	vmulpd %zmm4,%zmm0,%zmm6
    4ede:	48 8d 14 cd 00 00 00 	lea    0x0(,%rcx,8),%rdx
    4ee5:	00 
    4ee6:	62 51 fd 48 11 14 10 	vmovupd %zmm10,(%r8,%rdx,1)
    4eed:	62 d1 fd 48 11 7c c8 	vmovupd %zmm7,0x40(%r8,%rcx,8)
    4ef4:	01 
    4ef5:	8d 48 18             	lea    0x18(%rax),%ecx
    4ef8:	83 c0 28             	add    $0x28,%eax
    4efb:	62 f2 d5 48 b8 f3    	vfmadd231pd %zmm3,%zmm5,%zmm6
    4f01:	62 f1 d5 48 59 ec    	vmulpd %zmm4,%zmm5,%zmm5
    4f07:	48 63 c9             	movslq %ecx,%rcx
    4f0a:	48 98                	cltq   
    4f0c:	62 f2 d5 48 9c c3    	vfnmadd132pd %zmm3,%zmm5,%zmm0
    4f12:	62 f1 f5 48 59 ec    	vmulpd %zmm4,%zmm1,%zmm5
    4f18:	62 d1 fd 48 11 74 10 	vmovupd %zmm6,0x80(%r8,%rdx,1)
    4f1f:	02 
    4f20:	62 f2 ed 48 b8 eb    	vfmadd231pd %zmm3,%zmm2,%zmm5
    4f26:	62 f1 ed 48 59 d4    	vmulpd %zmm4,%zmm2,%zmm2
    4f2c:	62 f2 ed 48 9c cb    	vfnmadd132pd %zmm3,%zmm2,%zmm1
    4f32:	62 d1 fd 48 11 2c c8 	vmovupd %zmm5,(%r8,%rcx,8)
    4f39:	62 d1 fd 48 11 44 10 	vmovupd %zmm0,0x100(%r8,%rdx,1)
    4f40:	04 
    4f41:	62 d1 fd 48 11 0c c0 	vmovupd %zmm1,(%r8,%rax,8)
    4f48:	c5 f8 77             	vzeroupper 
    4f4b:	5b                   	pop    %rbx
    4f4c:	41 5c                	pop    %r12
    4f4e:	5d                   	pop    %rbp
    4f4f:	c3                   	ret    

0000000000004f50 <apply_rev_avx_mv_seq_fma>:
    4f50:	f3 0f 1e fa          	endbr64 
    4f54:	41 0f af f9          	imul   %r9d,%edi
    4f58:	55                   	push   %rbp
    4f59:	41 89 d3             	mov    %edx,%r11d
    4f5c:	48 89 ce             	mov    %rcx,%rsi
    4f5f:	48 89 e5             	mov    %rsp,%rbp
    4f62:	41 54                	push   %r12
    4f64:	53                   	push   %rbx
    4f65:	41 8d 5b fd          	lea    -0x3(%r11),%ebx
    4f69:	48 63 c7             	movslq %edi,%rax
    4f6c:	8d 57 02             	lea    0x2(%rdi),%edx
    4f6f:	44 01 cf             	add    %r9d,%edi
    4f72:	62 f2 fd 48 19 54 c1 	vbroadcastsd 0x8(%rcx,%rax,8),%zmm2
    4f79:	01 
    4f7a:	62 d1 ed 48 59 60 02 	vmulpd 0x80(%r8),%zmm2,%zmm4
    4f81:	62 f2 fd 48 19 74 c1 	vbroadcastsd 0x18(%rcx,%rax,8),%zmm6
    4f88:	03 
    4f89:	48 63 d2             	movslq %edx,%rdx
    4f8c:	62 d1 ed 48 59 08    	vmulpd (%r8),%zmm2,%zmm1
    4f92:	62 f2 fd 48 19 04 c1 	vbroadcastsd (%rcx,%rax,8),%zmm0
    4f99:	62 72 fd 48 19 04 d1 	vbroadcastsd (%rcx,%rdx,8),%zmm8
    4fa0:	48 63 c7             	movslq %edi,%rax
    4fa3:	62 d1 ed 48 59 58 03 	vmulpd 0xc0(%r8),%zmm2,%zmm3
    4faa:	62 d2 fd 48 b8 20    	vfmadd231pd (%r8),%zmm0,%zmm4
    4fb0:	62 72 fd 48 19 0c c1 	vbroadcastsd (%rcx,%rax,8),%zmm9
    4fb7:	46 8d 24 0f          	lea    (%rdi,%r9,1),%r12d
    4fbb:	62 d1 ed 48 59 50 01 	vmulpd 0x40(%r8),%zmm2,%zmm2
    4fc2:	62 d2 fd 48 ba 48 02 	vfmsub231pd 0x80(%r8),%zmm0,%zmm1
    4fc9:	62 d2 fd 48 b8 58 01 	vfmadd231pd 0x40(%r8),%zmm0,%zmm3
    4fd0:	62 d1 cd 48 59 68 05 	vmulpd 0x140(%r8),%zmm6,%zmm5
    4fd7:	62 d2 ed 48 9a 40 03 	vfmsub132pd 0xc0(%r8),%zmm2,%zmm0
    4fde:	62 d1 cd 48 59 50 04 	vmulpd 0x100(%r8),%zmm6,%zmm2
    4fe5:	62 f2 bd 48 b8 e8    	vfmadd231pd %zmm0,%zmm8,%zmm5
    4feb:	62 f1 fd 48 59 c6    	vmulpd %zmm6,%zmm0,%zmm0
    4ff1:	62 f2 bd 48 b8 d1    	vfmadd231pd %zmm1,%zmm8,%zmm2
    4ff7:	62 f1 f5 48 59 ce    	vmulpd %zmm6,%zmm1,%zmm1
    4ffd:	62 f2 fd 48 19 74 c1 	vbroadcastsd 0x8(%rcx,%rax,8),%zmm6
    5004:	01 
    5005:	62 d2 bd 48 ba 48 04 	vfmsub231pd 0x100(%r8),%zmm8,%zmm1
    500c:	62 52 fd 48 9a 40 05 	vfmsub132pd 0x140(%r8),%zmm0,%zmm8
    5013:	62 f1 ed 48 59 fe    	vmulpd %zmm6,%zmm2,%zmm7
    5019:	62 71 d5 48 59 d6    	vmulpd %zmm6,%zmm5,%zmm10
    501f:	62 f2 b5 48 b8 fc    	vfmadd231pd %zmm4,%zmm9,%zmm7
    5025:	62 72 b5 48 b8 d3    	vfmadd231pd %zmm3,%zmm9,%zmm10
    502b:	62 f1 dd 48 59 e6    	vmulpd %zmm6,%zmm4,%zmm4
    5031:	62 f1 e5 48 59 de    	vmulpd %zmm6,%zmm3,%zmm3
    5037:	62 d2 dd 48 9a d1    	vfmsub132pd %zmm9,%zmm4,%zmm2
    503d:	62 72 e5 48 9a cd    	vfmsub132pd %zmm5,%zmm3,%zmm9
    5043:	41 83 fb 03          	cmp    $0x3,%r11d
    5047:	0f 8e 15 01 00 00    	jle    5162 <apply_rev_avx_mv_seq_fma+0x212>
    504d:	45 8d 53 fd          	lea    -0x3(%r11),%r10d
    5051:	4d 63 c9             	movslq %r9d,%r9
    5054:	48 8d 44 c1 10       	lea    0x10(%rcx,%rax,8),%rax
    5059:	4c 89 c2             	mov    %r8,%rdx
    505c:	4c 89 d3             	mov    %r10,%rbx
    505f:	4c 89 c9             	mov    %r9,%rcx
    5062:	49 c1 e2 07          	shl    $0x7,%r10
    5066:	48 f7 d9             	neg    %rcx
    5069:	4d 01 c2             	add    %r8,%r10
    506c:	0f 1f 40 00          	nopl   0x0(%rax)
    5070:	62 f2 fd 48 19 44 c8 	vbroadcastsd 0x18(%rax,%rcx,8),%zmm0
    5077:	03 
    5078:	62 f1 fd 48 59 5a 06 	vmulpd 0x180(%rdx),%zmm0,%zmm3
    507f:	62 f2 fd 48 19 6c c8 	vbroadcastsd 0x10(%rax,%rcx,8),%zmm5
    5086:	02 
    5087:	48 83 ea 80          	sub    $0xffffffffffffff80,%rdx
    508b:	62 f1 fd 48 59 62 05 	vmulpd 0x140(%rdx),%zmm0,%zmm4
    5092:	62 f2 fd 48 19 30    	vbroadcastsd (%rax),%zmm6
    5098:	62 f2 d5 48 b8 d9    	vfmadd231pd %zmm1,%zmm5,%zmm3
    509e:	62 f1 fd 48 59 c9    	vmulpd %zmm1,%zmm0,%zmm1
    50a4:	62 f2 d5 48 ba 4a 04 	vfmsub231pd 0x100(%rdx),%zmm5,%zmm1
    50ab:	62 d2 d5 48 b8 e0    	vfmadd231pd %zmm8,%zmm5,%zmm4
    50b1:	62 d1 fd 48 59 c0    	vmulpd %zmm8,%zmm0,%zmm0
    50b7:	62 f2 fd 48 9a 6a 05 	vfmsub132pd 0x140(%rdx),%zmm0,%zmm5
    50be:	62 f2 fd 48 19 40 01 	vbroadcastsd 0x8(%rax),%zmm0
    50c5:	62 71 fd 48 28 c5    	vmovapd %zmm5,%zmm8
    50cb:	62 f1 e5 48 59 e8    	vmulpd %zmm0,%zmm3,%zmm5
    50d1:	62 f2 cd 48 b8 ea    	vfmadd231pd %zmm2,%zmm6,%zmm5
    50d7:	62 f1 fd 48 59 d2    	vmulpd %zmm2,%zmm0,%zmm2
    50dd:	62 f2 cd 48 ba d3    	vfmsub231pd %zmm3,%zmm6,%zmm2
    50e3:	62 f1 dd 48 59 d8    	vmulpd %zmm0,%zmm4,%zmm3
    50e9:	62 d1 fd 48 59 c1    	vmulpd %zmm9,%zmm0,%zmm0
    50ef:	62 d2 cd 48 b8 d9    	vfmadd231pd %zmm9,%zmm6,%zmm3
    50f5:	62 f2 fd 48 9a f4    	vfmsub132pd %zmm4,%zmm0,%zmm6
    50fb:	62 b2 fd 48 19 44 c8 	vbroadcastsd -0x8(%rax,%r9,8),%zmm0
    5102:	ff 
    5103:	62 b2 fd 48 19 64 c8 	vbroadcastsd -0x10(%rax,%r9,8),%zmm4
    510a:	fe 
    510b:	48 83 c0 10          	add    $0x10,%rax
    510f:	62 71 fd 48 28 ce    	vmovapd %zmm6,%zmm9
    5115:	62 f1 d5 48 59 f0    	vmulpd %zmm0,%zmm5,%zmm6
    511b:	62 f2 dd 48 b8 f7    	vfmadd231pd %zmm7,%zmm4,%zmm6
    5121:	62 f1 fd 48 59 ff    	vmulpd %zmm7,%zmm0,%zmm7
    5127:	62 f2 dd 48 ba fd    	vfmsub231pd %zmm5,%zmm4,%zmm7
    512d:	62 f1 e5 48 59 e8    	vmulpd %zmm0,%zmm3,%zmm5
    5133:	62 f1 fd 48 11 72 fe 	vmovupd %zmm6,-0x80(%rdx)
    513a:	62 d1 fd 48 59 c2    	vmulpd %zmm10,%zmm0,%zmm0
    5140:	62 d2 dd 48 b8 ea    	vfmadd231pd %zmm10,%zmm4,%zmm5
    5146:	62 f2 fd 48 9a e3    	vfmsub132pd %zmm3,%zmm0,%zmm4
    514c:	62 f1 fd 48 11 6a ff 	vmovupd %zmm5,-0x40(%rdx)
    5153:	62 71 fd 48 28 d4    	vmovapd %zmm4,%zmm10
    5159:	49 39 d2             	cmp    %rdx,%r10
    515c:	0f 85 0e ff ff ff    	jne    5070 <apply_rev_avx_mv_seq_fma+0x120>
    5162:	43 8d 44 1b fc       	lea    -0x4(%r11,%r11,1),%eax
    5167:	01 c7                	add    %eax,%edi
    5169:	42 8d 54 20 fe       	lea    -0x2(%rax,%r12,1),%edx
    516e:	44 01 e0             	add    %r12d,%eax
    5171:	48 63 ff             	movslq %edi,%rdi
    5174:	48 63 d2             	movslq %edx,%rdx
    5177:	48 98                	cltq   
    5179:	62 f2 fd 48 19 6c fe 	vbroadcastsd 0x8(%rsi,%rdi,8),%zmm5
    5180:	01 
    5181:	62 f2 fd 48 19 24 fe 	vbroadcastsd (%rsi,%rdi,8),%zmm4
    5188:	62 f1 d5 48 59 c1    	vmulpd %zmm1,%zmm5,%zmm0
    518e:	62 d1 d5 48 59 f0    	vmulpd %zmm8,%zmm5,%zmm6
    5194:	62 f1 fd 48 28 d8    	vmovapd %zmm0,%zmm3
    519a:	62 d2 dd 48 b8 f1    	vfmadd231pd %zmm9,%zmm4,%zmm6
    51a0:	62 f2 dd 48 b8 da    	vfmadd231pd %zmm2,%zmm4,%zmm3
    51a6:	62 f1 d5 48 59 d2    	vmulpd %zmm2,%zmm5,%zmm2
    51ac:	62 d1 d5 48 59 e9    	vmulpd %zmm9,%zmm5,%zmm5
    51b2:	62 f2 ed 48 9a cc    	vfmsub132pd %zmm4,%zmm2,%zmm1
    51b8:	62 f2 fd 48 19 14 d6 	vbroadcastsd (%rsi,%rdx,8),%zmm2
    51bf:	62 d2 d5 48 9a e0    	vfmsub132pd %zmm8,%zmm5,%zmm4
    51c5:	62 f2 fd 48 19 6c d6 	vbroadcastsd 0x8(%rsi,%rdx,8),%zmm5
    51cc:	01 
    51cd:	62 71 e5 48 59 c5    	vmulpd %zmm5,%zmm3,%zmm8
    51d3:	62 f1 d5 48 59 c7    	vmulpd %zmm7,%zmm5,%zmm0
    51d9:	62 72 ed 48 b8 c7    	vfmadd231pd %zmm7,%zmm2,%zmm8
    51df:	62 f1 cd 48 59 fd    	vmulpd %zmm5,%zmm6,%zmm7
    51e5:	62 d1 d5 48 59 ea    	vmulpd %zmm10,%zmm5,%zmm5
    51eb:	62 f2 ed 48 ba c3    	vfmsub231pd %zmm3,%zmm2,%zmm0
    51f1:	62 f2 fd 48 19 1c c6 	vbroadcastsd (%rsi,%rax,8),%zmm3
    51f8:	62 d2 ed 48 b8 fa    	vfmadd231pd %zmm10,%zmm2,%zmm7
    51fe:	62 f2 d5 48 9a d6    	vfmsub132pd %zmm6,%zmm5,%zmm2
    5204:	62 f2 fd 48 19 6c c6 	vbroadcastsd 0x8(%rsi,%rax,8),%zmm5
    520b:	01 
    520c:	89 d8                	mov    %ebx,%eax
    520e:	c1 e0 04             	shl    $0x4,%eax
    5211:	48 63 c8             	movslq %eax,%rcx
    5214:	48 8d 14 cd 00 00 00 	lea    0x0(,%rcx,8),%rdx
    521b:	00 
    521c:	62 51 fd 48 11 04 10 	vmovupd %zmm8,(%r8,%rdx,1)
    5223:	62 f1 f5 48 59 f5    	vmulpd %zmm5,%zmm1,%zmm6
    5229:	62 d1 fd 48 11 7c c8 	vmovupd %zmm7,0x40(%r8,%rcx,8)
    5230:	01 
    5231:	8d 48 18             	lea    0x18(%rax),%ecx
    5234:	83 c0 28             	add    $0x28,%eax
    5237:	48 63 c9             	movslq %ecx,%rcx
    523a:	48 98                	cltq   
    523c:	62 f2 e5 48 b8 f0    	vfmadd231pd %zmm0,%zmm3,%zmm6
    5242:	62 f1 fd 48 59 c5    	vmulpd %zmm5,%zmm0,%zmm0
    5248:	62 f2 fd 48 9a cb    	vfmsub132pd %zmm3,%zmm0,%zmm1
    524e:	62 f1 dd 48 59 c5    	vmulpd %zmm5,%zmm4,%zmm0
    5254:	62 d1 fd 48 11 74 10 	vmovupd %zmm6,0x80(%r8,%rdx,1)
    525b:	02 
    525c:	62 f2 e5 48 b8 c2    	vfmadd231pd %zmm2,%zmm3,%zmm0
    5262:	62 f1 ed 48 59 d5    	vmulpd %zmm5,%zmm2,%zmm2
    5268:	62 f2 ed 48 9a dc    	vfmsub132pd %zmm4,%zmm2,%zmm3
    526e:	62 d1 fd 48 11 04 c8 	vmovupd %zmm0,(%r8,%rcx,8)
    5275:	62 d1 fd 48 11 4c 10 	vmovupd %zmm1,0x100(%r8,%rdx,1)
    527c:	04 
    527d:	62 d1 fd 48 11 1c c0 	vmovupd %zmm3,(%r8,%rax,8)
    5284:	c5 f8 77             	vzeroupper 
    5287:	5b                   	pop    %rbx
    5288:	41 5c                	pop    %r12
    528a:	5d                   	pop    %rbp
    528b:	c3                   	ret    

セクション .fini の逆アセンブル:

000000000000528c <_fini>:
    528c:	f3 0f 1e fa          	endbr64 
    5290:	48 83 ec 08          	sub    $0x8,%rsp
    5294:	48 83 c4 08          	add    $0x8,%rsp
    5298:	c3                   	ret    
