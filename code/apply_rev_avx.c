#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <math.h>
#include <immintrin.h>
#include <pmmintrin.h>
#include "apply_rev_avx.h" 
void apply_rev_avx_mv(int k, int m, int n, double *G, double *V, int ldv, int ldg, int i)
{
__m256d  v00,  v01,  v02,  v10,  v11,  v12,  v20,  v21,  v22,  v30,  v31,  v32,  v40,  v41,  v42,  v50,  v51,  v52,  v60,  v61,  v62,  v70,  v71,  v72, gamma, sigma, tmp;
v00 = _mm256_loadu_pd(&V[i]);
v01 = _mm256_loadu_pd(&V[i + 4 * 1]);
v02 = _mm256_loadu_pd(&V[i + 4 * 2]);
v10 = _mm256_loadu_pd(&V[i + ldv]);
v11 = _mm256_loadu_pd(&V[i + ldv + 4 * 1]);
v12 = _mm256_loadu_pd(&V[i + ldv + 4 * 2]);
v20 = _mm256_loadu_pd(&V[i + 2 * ldv]);
v21 = _mm256_loadu_pd(&V[i + 2 * ldv + 4 * 1]);
v22 = _mm256_loadu_pd(&V[i + 2 * ldv + 4 * 2]);
v30 = _mm256_loadu_pd(&V[i + 3 * ldv]);
v31 = _mm256_loadu_pd(&V[i + 3 * ldv + 4 * 1]);
v32 = _mm256_loadu_pd(&V[i + 3 * ldv + 4 * 2]);
v40 = _mm256_loadu_pd(&V[i + 4 * ldv]);
v41 = _mm256_loadu_pd(&V[i + 4 * ldv + 4 * 1]);
v42 = _mm256_loadu_pd(&V[i + 4 * ldv + 4 * 2]);
v50 = _mm256_loadu_pd(&V[i + 5 * ldv]);
v51 = _mm256_loadu_pd(&V[i + 5 * ldv + 4 * 1]);
v52 = _mm256_loadu_pd(&V[i + 5 * ldv + 4 * 2]);
v60 = _mm256_loadu_pd(&V[i + 6 * ldv]);
v61 = _mm256_loadu_pd(&V[i + 6 * ldv + 4 * 1]);
v62 = _mm256_loadu_pd(&V[i + 6 * ldv + 4 * 2]);
    gamma = _mm256_broadcast_sd(&G[2 * 0 + k * ldg]);
    sigma = _mm256_broadcast_sd(&G[2 * 0 + k * ldg + 1]);
 tmp = v00;
 v00 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v10));
 v10 = _mm256_sub_pd(_mm256_mul_pd(gamma, v10), _mm256_mul_pd(sigma, tmp));
 tmp = v01;
 v01 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v11));
 v11 = _mm256_sub_pd(_mm256_mul_pd(gamma, v11), _mm256_mul_pd(sigma, tmp));
 tmp = v02;
 v02 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v12));
 v12 = _mm256_sub_pd(_mm256_mul_pd(gamma, v12), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 1  + k * ldg]);
    sigma = _mm256_broadcast_sd(&G[2 * 1  + k * ldg + 1]);
 tmp = v10;
 v10 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v20));
 v20 = _mm256_sub_pd(_mm256_mul_pd(gamma, v20), _mm256_mul_pd(sigma, tmp));
 tmp = v11;
 v11 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v21));
 v21 = _mm256_sub_pd(_mm256_mul_pd(gamma, v21), _mm256_mul_pd(sigma, tmp));
 tmp = v12;
 v12 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v22));
 v22 = _mm256_sub_pd(_mm256_mul_pd(gamma, v22), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 0 + (k + 1) * ldg ]);
    sigma = _mm256_broadcast_sd(&G[2 * 0 + (k + 1) * ldg  + 1]);
 tmp = v00;
 v00 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v10));
 v10 = _mm256_sub_pd(_mm256_mul_pd(gamma, v10), _mm256_mul_pd(sigma, tmp));
 tmp = v01;
 v01 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v11));
 v11 = _mm256_sub_pd(_mm256_mul_pd(gamma, v11), _mm256_mul_pd(sigma, tmp));
 tmp = v02;
 v02 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v12));
 v12 = _mm256_sub_pd(_mm256_mul_pd(gamma, v12), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 2  + k * ldg]);
    sigma = _mm256_broadcast_sd(&G[2 * 2  + k * ldg + 1]);
 tmp = v20;
 v20 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v30));
 v30 = _mm256_sub_pd(_mm256_mul_pd(gamma, v30), _mm256_mul_pd(sigma, tmp));
 tmp = v21;
 v21 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v31));
 v31 = _mm256_sub_pd(_mm256_mul_pd(gamma, v31), _mm256_mul_pd(sigma, tmp));
 tmp = v22;
 v22 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v32));
 v32 = _mm256_sub_pd(_mm256_mul_pd(gamma, v32), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 1  + (k + 1) * ldg ]);
    sigma = _mm256_broadcast_sd(&G[2 * 1  + (k + 1) * ldg  + 1]);
 tmp = v10;
 v10 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v20));
 v20 = _mm256_sub_pd(_mm256_mul_pd(gamma, v20), _mm256_mul_pd(sigma, tmp));
 tmp = v11;
 v11 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v21));
 v21 = _mm256_sub_pd(_mm256_mul_pd(gamma, v21), _mm256_mul_pd(sigma, tmp));
 tmp = v12;
 v12 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v22));
 v22 = _mm256_sub_pd(_mm256_mul_pd(gamma, v22), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 0 + (k + 2) * ldg ]);
    sigma = _mm256_broadcast_sd(&G[2 * 0 + (k + 2) * ldg  + 1]);
 tmp = v00;
 v00 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v10));
 v10 = _mm256_sub_pd(_mm256_mul_pd(gamma, v10), _mm256_mul_pd(sigma, tmp));
 tmp = v01;
 v01 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v11));
 v11 = _mm256_sub_pd(_mm256_mul_pd(gamma, v11), _mm256_mul_pd(sigma, tmp));
 tmp = v02;
 v02 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v12));
 v12 = _mm256_sub_pd(_mm256_mul_pd(gamma, v12), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 3  + k * ldg]);
    sigma = _mm256_broadcast_sd(&G[2 * 3  + k * ldg + 1]);
 tmp = v30;
 v30 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v40));
 v40 = _mm256_sub_pd(_mm256_mul_pd(gamma, v40), _mm256_mul_pd(sigma, tmp));
 tmp = v31;
 v31 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v41));
 v41 = _mm256_sub_pd(_mm256_mul_pd(gamma, v41), _mm256_mul_pd(sigma, tmp));
 tmp = v32;
 v32 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v42));
 v42 = _mm256_sub_pd(_mm256_mul_pd(gamma, v42), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 2  + (k + 1) * ldg ]);
    sigma = _mm256_broadcast_sd(&G[2 * 2  + (k + 1) * ldg  + 1]);
 tmp = v20;
 v20 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v30));
 v30 = _mm256_sub_pd(_mm256_mul_pd(gamma, v30), _mm256_mul_pd(sigma, tmp));
 tmp = v21;
 v21 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v31));
 v31 = _mm256_sub_pd(_mm256_mul_pd(gamma, v31), _mm256_mul_pd(sigma, tmp));
 tmp = v22;
 v22 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v32));
 v32 = _mm256_sub_pd(_mm256_mul_pd(gamma, v32), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 1  + (k + 2) * ldg ]);
    sigma = _mm256_broadcast_sd(&G[2 * 1  + (k + 2) * ldg  + 1]);
 tmp = v10;
 v10 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v20));
 v20 = _mm256_sub_pd(_mm256_mul_pd(gamma, v20), _mm256_mul_pd(sigma, tmp));
 tmp = v11;
 v11 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v21));
 v21 = _mm256_sub_pd(_mm256_mul_pd(gamma, v21), _mm256_mul_pd(sigma, tmp));
 tmp = v12;
 v12 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v22));
 v22 = _mm256_sub_pd(_mm256_mul_pd(gamma, v22), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 0 + (k + 3) * ldg ]);
    sigma = _mm256_broadcast_sd(&G[2 * 0 + (k + 3) * ldg  + 1]);
 tmp = v00;
 v00 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v10));
 v10 = _mm256_sub_pd(_mm256_mul_pd(gamma, v10), _mm256_mul_pd(sigma, tmp));
 tmp = v01;
 v01 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v11));
 v11 = _mm256_sub_pd(_mm256_mul_pd(gamma, v11), _mm256_mul_pd(sigma, tmp));
 tmp = v02;
 v02 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v12));
 v12 = _mm256_sub_pd(_mm256_mul_pd(gamma, v12), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 4  + k * ldg]);
    sigma = _mm256_broadcast_sd(&G[2 * 4  + k * ldg + 1]);
 tmp = v40;
 v40 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v50));
 v50 = _mm256_sub_pd(_mm256_mul_pd(gamma, v50), _mm256_mul_pd(sigma, tmp));
 tmp = v41;
 v41 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v51));
 v51 = _mm256_sub_pd(_mm256_mul_pd(gamma, v51), _mm256_mul_pd(sigma, tmp));
 tmp = v42;
 v42 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v52));
 v52 = _mm256_sub_pd(_mm256_mul_pd(gamma, v52), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 3  + (k + 1) * ldg ]);
    sigma = _mm256_broadcast_sd(&G[2 * 3  + (k + 1) * ldg  + 1]);
 tmp = v30;
 v30 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v40));
 v40 = _mm256_sub_pd(_mm256_mul_pd(gamma, v40), _mm256_mul_pd(sigma, tmp));
 tmp = v31;
 v31 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v41));
 v41 = _mm256_sub_pd(_mm256_mul_pd(gamma, v41), _mm256_mul_pd(sigma, tmp));
 tmp = v32;
 v32 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v42));
 v42 = _mm256_sub_pd(_mm256_mul_pd(gamma, v42), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 2  + (k + 2) * ldg ]);
    sigma = _mm256_broadcast_sd(&G[2 * 2  + (k + 2) * ldg  + 1]);
 tmp = v20;
 v20 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v30));
 v30 = _mm256_sub_pd(_mm256_mul_pd(gamma, v30), _mm256_mul_pd(sigma, tmp));
 tmp = v21;
 v21 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v31));
 v31 = _mm256_sub_pd(_mm256_mul_pd(gamma, v31), _mm256_mul_pd(sigma, tmp));
 tmp = v22;
 v22 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v32));
 v32 = _mm256_sub_pd(_mm256_mul_pd(gamma, v32), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 1  + (k + 3) * ldg ]);
    sigma = _mm256_broadcast_sd(&G[2 * 1  + (k + 3) * ldg  + 1]);
 tmp = v10;
 v10 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v20));
 v20 = _mm256_sub_pd(_mm256_mul_pd(gamma, v20), _mm256_mul_pd(sigma, tmp));
 tmp = v11;
 v11 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v21));
 v21 = _mm256_sub_pd(_mm256_mul_pd(gamma, v21), _mm256_mul_pd(sigma, tmp));
 tmp = v12;
 v12 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v22));
 v22 = _mm256_sub_pd(_mm256_mul_pd(gamma, v22), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 0 + (k + 4) * ldg ]);
    sigma = _mm256_broadcast_sd(&G[2 * 0 + (k + 4) * ldg  + 1]);
 tmp = v00;
 v00 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v10));
 v10 = _mm256_sub_pd(_mm256_mul_pd(gamma, v10), _mm256_mul_pd(sigma, tmp));
 tmp = v01;
 v01 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v11));
 v11 = _mm256_sub_pd(_mm256_mul_pd(gamma, v11), _mm256_mul_pd(sigma, tmp));
 tmp = v02;
 v02 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v12));
 v12 = _mm256_sub_pd(_mm256_mul_pd(gamma, v12), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 5  + k * ldg]);
    sigma = _mm256_broadcast_sd(&G[2 * 5  + k * ldg + 1]);
 tmp = v50;
 v50 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v60));
 v60 = _mm256_sub_pd(_mm256_mul_pd(gamma, v60), _mm256_mul_pd(sigma, tmp));
 tmp = v51;
 v51 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v61));
 v61 = _mm256_sub_pd(_mm256_mul_pd(gamma, v61), _mm256_mul_pd(sigma, tmp));
 tmp = v52;
 v52 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v62));
 v62 = _mm256_sub_pd(_mm256_mul_pd(gamma, v62), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 4  + (k + 1) * ldg ]);
    sigma = _mm256_broadcast_sd(&G[2 * 4  + (k + 1) * ldg  + 1]);
 tmp = v40;
 v40 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v50));
 v50 = _mm256_sub_pd(_mm256_mul_pd(gamma, v50), _mm256_mul_pd(sigma, tmp));
 tmp = v41;
 v41 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v51));
 v51 = _mm256_sub_pd(_mm256_mul_pd(gamma, v51), _mm256_mul_pd(sigma, tmp));
 tmp = v42;
 v42 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v52));
 v52 = _mm256_sub_pd(_mm256_mul_pd(gamma, v52), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 3  + (k + 2) * ldg ]);
    sigma = _mm256_broadcast_sd(&G[2 * 3  + (k + 2) * ldg  + 1]);
 tmp = v30;
 v30 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v40));
 v40 = _mm256_sub_pd(_mm256_mul_pd(gamma, v40), _mm256_mul_pd(sigma, tmp));
 tmp = v31;
 v31 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v41));
 v41 = _mm256_sub_pd(_mm256_mul_pd(gamma, v41), _mm256_mul_pd(sigma, tmp));
 tmp = v32;
 v32 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v42));
 v42 = _mm256_sub_pd(_mm256_mul_pd(gamma, v42), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 2  + (k + 3) * ldg ]);
    sigma = _mm256_broadcast_sd(&G[2 * 2  + (k + 3) * ldg  + 1]);
 tmp = v20;
 v20 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v30));
 v30 = _mm256_sub_pd(_mm256_mul_pd(gamma, v30), _mm256_mul_pd(sigma, tmp));
 tmp = v21;
 v21 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v31));
 v31 = _mm256_sub_pd(_mm256_mul_pd(gamma, v31), _mm256_mul_pd(sigma, tmp));
 tmp = v22;
 v22 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v32));
 v32 = _mm256_sub_pd(_mm256_mul_pd(gamma, v32), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 1  + (k + 4) * ldg ]);
    sigma = _mm256_broadcast_sd(&G[2 * 1  + (k + 4) * ldg  + 1]);
 tmp = v10;
 v10 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v20));
 v20 = _mm256_sub_pd(_mm256_mul_pd(gamma, v20), _mm256_mul_pd(sigma, tmp));
 tmp = v11;
 v11 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v21));
 v21 = _mm256_sub_pd(_mm256_mul_pd(gamma, v21), _mm256_mul_pd(sigma, tmp));
 tmp = v12;
 v12 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v22));
 v22 = _mm256_sub_pd(_mm256_mul_pd(gamma, v22), _mm256_mul_pd(sigma, tmp));
    gamma = _mm256_broadcast_sd(&G[2 * 0 + (k + 5) * ldg ]);
    sigma = _mm256_broadcast_sd(&G[2 * 0 + (k + 5) * ldg  + 1]);
 tmp = v00;
 v00 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v10));
 v10 = _mm256_sub_pd(_mm256_mul_pd(gamma, v10), _mm256_mul_pd(sigma, tmp));
 tmp = v01;
 v01 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v11));
 v11 = _mm256_sub_pd(_mm256_mul_pd(gamma, v11), _mm256_mul_pd(sigma, tmp));
 tmp = v02;
 v02 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v12));
 v12 = _mm256_sub_pd(_mm256_mul_pd(gamma, v12), _mm256_mul_pd(sigma, tmp));
for (int g = 6; g < n - 1; g++)
{
v70= _mm256_loadu_pd(&V[i + (g + 1) * ldv ]);
v71= _mm256_loadu_pd(&V[i + (g + 1) * ldv + 4 * 1 ]);
v72= _mm256_loadu_pd(&V[i + (g + 1) * ldv + 4 * 2 ]);
gamma = _mm256_broadcast_sd(&G[2 * g + k * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * g + k * ldg + 1]);
tmp = v60;
 v60 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v70));
 v70 = _mm256_sub_pd(_mm256_mul_pd(gamma, v70), _mm256_mul_pd(sigma, tmp));
tmp = v61;
 v61 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v71));
 v71 = _mm256_sub_pd(_mm256_mul_pd(gamma, v71), _mm256_mul_pd(sigma, tmp));
tmp = v62;
 v62 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v72));
 v72 = _mm256_sub_pd(_mm256_mul_pd(gamma, v72), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (g - 1) + (k + 1) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (g - 1) + (k + 1) * ldg + 1]);
tmp = v50;
 v50 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v60));
 v60 = _mm256_sub_pd(_mm256_mul_pd(gamma, v60), _mm256_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v61));
 v61 = _mm256_sub_pd(_mm256_mul_pd(gamma, v61), _mm256_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v62));
 v62 = _mm256_sub_pd(_mm256_mul_pd(gamma, v62), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (g - 2) + (k + 2) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (g - 2) + (k + 2) * ldg + 1]);
tmp = v40;
 v40 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v50));
 v50 = _mm256_sub_pd(_mm256_mul_pd(gamma, v50), _mm256_mul_pd(sigma, tmp));
tmp = v41;
 v41 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v51));
 v51 = _mm256_sub_pd(_mm256_mul_pd(gamma, v51), _mm256_mul_pd(sigma, tmp));
tmp = v42;
 v42 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v52));
 v52 = _mm256_sub_pd(_mm256_mul_pd(gamma, v52), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (g - 3) + (k + 3) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (g - 3) + (k + 3) * ldg + 1]);
tmp = v30;
 v30 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v40));
 v40 = _mm256_sub_pd(_mm256_mul_pd(gamma, v40), _mm256_mul_pd(sigma, tmp));
tmp = v31;
 v31 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v41));
 v41 = _mm256_sub_pd(_mm256_mul_pd(gamma, v41), _mm256_mul_pd(sigma, tmp));
tmp = v32;
 v32 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v42));
 v42 = _mm256_sub_pd(_mm256_mul_pd(gamma, v42), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (g - 4) + (k + 4) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (g - 4) + (k + 4) * ldg + 1]);
tmp = v20;
 v20 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v30));
 v30 = _mm256_sub_pd(_mm256_mul_pd(gamma, v30), _mm256_mul_pd(sigma, tmp));
tmp = v21;
 v21 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v31));
 v31 = _mm256_sub_pd(_mm256_mul_pd(gamma, v31), _mm256_mul_pd(sigma, tmp));
tmp = v22;
 v22 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v32));
 v32 = _mm256_sub_pd(_mm256_mul_pd(gamma, v32), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (g - 5) + (k + 5) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (g - 5) + (k + 5) * ldg + 1]);
tmp = v10;
 v10 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v20));
 v20 = _mm256_sub_pd(_mm256_mul_pd(gamma, v20), _mm256_mul_pd(sigma, tmp));
tmp = v11;
 v11 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v21));
 v21 = _mm256_sub_pd(_mm256_mul_pd(gamma, v21), _mm256_mul_pd(sigma, tmp));
tmp = v12;
 v12 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v22));
 v22 = _mm256_sub_pd(_mm256_mul_pd(gamma, v22), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (g - 6) + (k + 6) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (g - 6) + (k + 6) * ldg + 1]);
tmp = v00;
 v00 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v10));
 v10 = _mm256_sub_pd(_mm256_mul_pd(gamma, v10), _mm256_mul_pd(sigma, tmp));
tmp = v01;
 v01 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v11));
 v11 = _mm256_sub_pd(_mm256_mul_pd(gamma, v11), _mm256_mul_pd(sigma, tmp));
tmp = v02;
 v02 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v12));
 v12 = _mm256_sub_pd(_mm256_mul_pd(gamma, v12), _mm256_mul_pd(sigma, tmp));
_mm256_storeu_pd(&V[i + (g-6) * ldv ], v00);
_mm256_storeu_pd(&V[i + (g-6) * ldv + 4 * 1], v01);
_mm256_storeu_pd(&V[i + (g-6) * ldv + 4 * 2], v02);
v00=v10;
v01=v11;
v02=v12;
v10=v20;
v11=v21;
v12=v22;
v20=v30;
v21=v31;
v22=v32;
v30=v40;
v31=v41;
v32=v42;
v40=v50;
v41=v51;
v42=v52;
v50=v60;
v51=v61;
v52=v62;
v60=v70;
v61=v71;
v62=v72;
}
gamma = _mm256_broadcast_sd(&G[2 * (n - 2) + (k + 1) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 2) + (k + 1) * ldg + 1]);
tmp = v50;
 v50 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v60));
 v60 = _mm256_sub_pd(_mm256_mul_pd(gamma, v60), _mm256_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v61));
 v61 = _mm256_sub_pd(_mm256_mul_pd(gamma, v61), _mm256_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v62));
 v62 = _mm256_sub_pd(_mm256_mul_pd(gamma, v62), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 3) + (k + 2) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 3) + (k + 2) * ldg + 1]);
tmp = v40;
 v40 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v50));
 v50 = _mm256_sub_pd(_mm256_mul_pd(gamma, v50), _mm256_mul_pd(sigma, tmp));
tmp = v41;
 v41 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v51));
 v51 = _mm256_sub_pd(_mm256_mul_pd(gamma, v51), _mm256_mul_pd(sigma, tmp));
tmp = v42;
 v42 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v52));
 v52 = _mm256_sub_pd(_mm256_mul_pd(gamma, v52), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 4) + (k + 3) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 4) + (k + 3) * ldg + 1]);
tmp = v30;
 v30 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v40));
 v40 = _mm256_sub_pd(_mm256_mul_pd(gamma, v40), _mm256_mul_pd(sigma, tmp));
tmp = v31;
 v31 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v41));
 v41 = _mm256_sub_pd(_mm256_mul_pd(gamma, v41), _mm256_mul_pd(sigma, tmp));
tmp = v32;
 v32 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v42));
 v42 = _mm256_sub_pd(_mm256_mul_pd(gamma, v42), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 5) + (k + 4) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 5) + (k + 4) * ldg + 1]);
tmp = v20;
 v20 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v30));
 v30 = _mm256_sub_pd(_mm256_mul_pd(gamma, v30), _mm256_mul_pd(sigma, tmp));
tmp = v21;
 v21 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v31));
 v31 = _mm256_sub_pd(_mm256_mul_pd(gamma, v31), _mm256_mul_pd(sigma, tmp));
tmp = v22;
 v22 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v32));
 v32 = _mm256_sub_pd(_mm256_mul_pd(gamma, v32), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 6) + (k + 5) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 6) + (k + 5) * ldg + 1]);
tmp = v10;
 v10 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v20));
 v20 = _mm256_sub_pd(_mm256_mul_pd(gamma, v20), _mm256_mul_pd(sigma, tmp));
tmp = v11;
 v11 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v21));
 v21 = _mm256_sub_pd(_mm256_mul_pd(gamma, v21), _mm256_mul_pd(sigma, tmp));
tmp = v12;
 v12 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v22));
 v22 = _mm256_sub_pd(_mm256_mul_pd(gamma, v22), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 7) + (k + 6) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 7) + (k + 6) * ldg + 1]);
tmp = v00;
 v00 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v10));
 v10 = _mm256_sub_pd(_mm256_mul_pd(gamma, v10), _mm256_mul_pd(sigma, tmp));
tmp = v01;
 v01 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v11));
 v11 = _mm256_sub_pd(_mm256_mul_pd(gamma, v11), _mm256_mul_pd(sigma, tmp));
tmp = v02;
 v02 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v12));
 v12 = _mm256_sub_pd(_mm256_mul_pd(gamma, v12), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 2) + (k + 2) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 2) + (k + 2) * ldg + 1]);
tmp = v50;
 v50 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v60));
 v60 = _mm256_sub_pd(_mm256_mul_pd(gamma, v60), _mm256_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v61));
 v61 = _mm256_sub_pd(_mm256_mul_pd(gamma, v61), _mm256_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v62));
 v62 = _mm256_sub_pd(_mm256_mul_pd(gamma, v62), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 3) + (k + 3) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 3) + (k + 3) * ldg + 1]);
tmp = v40;
 v40 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v50));
 v50 = _mm256_sub_pd(_mm256_mul_pd(gamma, v50), _mm256_mul_pd(sigma, tmp));
tmp = v41;
 v41 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v51));
 v51 = _mm256_sub_pd(_mm256_mul_pd(gamma, v51), _mm256_mul_pd(sigma, tmp));
tmp = v42;
 v42 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v52));
 v52 = _mm256_sub_pd(_mm256_mul_pd(gamma, v52), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 4) + (k + 4) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 4) + (k + 4) * ldg + 1]);
tmp = v30;
 v30 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v40));
 v40 = _mm256_sub_pd(_mm256_mul_pd(gamma, v40), _mm256_mul_pd(sigma, tmp));
tmp = v31;
 v31 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v41));
 v41 = _mm256_sub_pd(_mm256_mul_pd(gamma, v41), _mm256_mul_pd(sigma, tmp));
tmp = v32;
 v32 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v42));
 v42 = _mm256_sub_pd(_mm256_mul_pd(gamma, v42), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 5) + (k + 5) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 5) + (k + 5) * ldg + 1]);
tmp = v20;
 v20 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v30));
 v30 = _mm256_sub_pd(_mm256_mul_pd(gamma, v30), _mm256_mul_pd(sigma, tmp));
tmp = v21;
 v21 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v31));
 v31 = _mm256_sub_pd(_mm256_mul_pd(gamma, v31), _mm256_mul_pd(sigma, tmp));
tmp = v22;
 v22 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v32));
 v32 = _mm256_sub_pd(_mm256_mul_pd(gamma, v32), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 6) + (k + 6) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 6) + (k + 6) * ldg + 1]);
tmp = v10;
 v10 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v20));
 v20 = _mm256_sub_pd(_mm256_mul_pd(gamma, v20), _mm256_mul_pd(sigma, tmp));
tmp = v11;
 v11 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v21));
 v21 = _mm256_sub_pd(_mm256_mul_pd(gamma, v21), _mm256_mul_pd(sigma, tmp));
tmp = v12;
 v12 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v22));
 v22 = _mm256_sub_pd(_mm256_mul_pd(gamma, v22), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 2) + (k + 3) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 2) + (k + 3) * ldg + 1]);
tmp = v50;
 v50 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v60));
 v60 = _mm256_sub_pd(_mm256_mul_pd(gamma, v60), _mm256_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v61));
 v61 = _mm256_sub_pd(_mm256_mul_pd(gamma, v61), _mm256_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v62));
 v62 = _mm256_sub_pd(_mm256_mul_pd(gamma, v62), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 3) + (k + 4) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 3) + (k + 4) * ldg + 1]);
tmp = v40;
 v40 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v50));
 v50 = _mm256_sub_pd(_mm256_mul_pd(gamma, v50), _mm256_mul_pd(sigma, tmp));
tmp = v41;
 v41 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v51));
 v51 = _mm256_sub_pd(_mm256_mul_pd(gamma, v51), _mm256_mul_pd(sigma, tmp));
tmp = v42;
 v42 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v52));
 v52 = _mm256_sub_pd(_mm256_mul_pd(gamma, v52), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 4) + (k + 5) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 4) + (k + 5) * ldg + 1]);
tmp = v30;
 v30 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v40));
 v40 = _mm256_sub_pd(_mm256_mul_pd(gamma, v40), _mm256_mul_pd(sigma, tmp));
tmp = v31;
 v31 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v41));
 v41 = _mm256_sub_pd(_mm256_mul_pd(gamma, v41), _mm256_mul_pd(sigma, tmp));
tmp = v32;
 v32 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v42));
 v42 = _mm256_sub_pd(_mm256_mul_pd(gamma, v42), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 5) + (k + 6) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 5) + (k + 6) * ldg + 1]);
tmp = v20;
 v20 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v30));
 v30 = _mm256_sub_pd(_mm256_mul_pd(gamma, v30), _mm256_mul_pd(sigma, tmp));
tmp = v21;
 v21 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v31));
 v31 = _mm256_sub_pd(_mm256_mul_pd(gamma, v31), _mm256_mul_pd(sigma, tmp));
tmp = v22;
 v22 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v32));
 v32 = _mm256_sub_pd(_mm256_mul_pd(gamma, v32), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 2) + (k + 4) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 2) + (k + 4) * ldg + 1]);
tmp = v50;
 v50 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v60));
 v60 = _mm256_sub_pd(_mm256_mul_pd(gamma, v60), _mm256_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v61));
 v61 = _mm256_sub_pd(_mm256_mul_pd(gamma, v61), _mm256_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v62));
 v62 = _mm256_sub_pd(_mm256_mul_pd(gamma, v62), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 3) + (k + 5) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 3) + (k + 5) * ldg + 1]);
tmp = v40;
 v40 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v50));
 v50 = _mm256_sub_pd(_mm256_mul_pd(gamma, v50), _mm256_mul_pd(sigma, tmp));
tmp = v41;
 v41 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v51));
 v51 = _mm256_sub_pd(_mm256_mul_pd(gamma, v51), _mm256_mul_pd(sigma, tmp));
tmp = v42;
 v42 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v52));
 v52 = _mm256_sub_pd(_mm256_mul_pd(gamma, v52), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 4) + (k + 6) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 4) + (k + 6) * ldg + 1]);
tmp = v30;
 v30 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v40));
 v40 = _mm256_sub_pd(_mm256_mul_pd(gamma, v40), _mm256_mul_pd(sigma, tmp));
tmp = v31;
 v31 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v41));
 v41 = _mm256_sub_pd(_mm256_mul_pd(gamma, v41), _mm256_mul_pd(sigma, tmp));
tmp = v32;
 v32 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v42));
 v42 = _mm256_sub_pd(_mm256_mul_pd(gamma, v42), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 2) + (k + 5) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 2) + (k + 5) * ldg + 1]);
tmp = v50;
 v50 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v60));
 v60 = _mm256_sub_pd(_mm256_mul_pd(gamma, v60), _mm256_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v61));
 v61 = _mm256_sub_pd(_mm256_mul_pd(gamma, v61), _mm256_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v62));
 v62 = _mm256_sub_pd(_mm256_mul_pd(gamma, v62), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 3) + (k + 6) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 3) + (k + 6) * ldg + 1]);
tmp = v40;
 v40 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v50));
 v50 = _mm256_sub_pd(_mm256_mul_pd(gamma, v50), _mm256_mul_pd(sigma, tmp));
tmp = v41;
 v41 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v51));
 v51 = _mm256_sub_pd(_mm256_mul_pd(gamma, v51), _mm256_mul_pd(sigma, tmp));
tmp = v42;
 v42 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v52));
 v52 = _mm256_sub_pd(_mm256_mul_pd(gamma, v52), _mm256_mul_pd(sigma, tmp));
gamma = _mm256_broadcast_sd(&G[2 * (n - 2) + (k + 6) * ldg]);
sigma = _mm256_broadcast_sd(&G[2 * (n - 2) + (k + 6) * ldg + 1]);
tmp = v50;
 v50 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v60));
 v60 = _mm256_sub_pd(_mm256_mul_pd(gamma, v60), _mm256_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v61));
 v61 = _mm256_sub_pd(_mm256_mul_pd(gamma, v61), _mm256_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm256_add_pd(_mm256_mul_pd(gamma, tmp), _mm256_mul_pd(sigma, v62));
 v62 = _mm256_sub_pd(_mm256_mul_pd(gamma, v62), _mm256_mul_pd(sigma, tmp));
_mm256_storeu_pd(&V[i + (n - 7) * ldv], v00);
_mm256_storeu_pd(&V[i + (n - 7) * ldv + 4 * 1], v01);
_mm256_storeu_pd(&V[i + (n - 7) * ldv + 4 * 2], v02);
_mm256_storeu_pd(&V[i + (n - 6) * ldv], v10);
_mm256_storeu_pd(&V[i + (n - 6) * ldv + 4 * 1], v11);
_mm256_storeu_pd(&V[i + (n - 6) * ldv + 4 * 2], v12);
_mm256_storeu_pd(&V[i + (n - 5) * ldv], v20);
_mm256_storeu_pd(&V[i + (n - 5) * ldv + 4 * 1], v21);
_mm256_storeu_pd(&V[i + (n - 5) * ldv + 4 * 2], v22);
_mm256_storeu_pd(&V[i + (n - 4) * ldv], v30);
_mm256_storeu_pd(&V[i + (n - 4) * ldv + 4 * 1], v31);
_mm256_storeu_pd(&V[i + (n - 4) * ldv + 4 * 2], v32);
_mm256_storeu_pd(&V[i + (n - 3) * ldv], v40);
_mm256_storeu_pd(&V[i + (n - 3) * ldv + 4 * 1], v41);
_mm256_storeu_pd(&V[i + (n - 3) * ldv + 4 * 2], v42);
_mm256_storeu_pd(&V[i + (n - 2) * ldv], v50);
_mm256_storeu_pd(&V[i + (n - 2) * ldv + 4 * 1], v51);
_mm256_storeu_pd(&V[i + (n - 2) * ldv + 4 * 2], v52);
_mm256_storeu_pd(&V[i + (n - 1) * ldv], v60);
_mm256_storeu_pd(&V[i + (n - 1) * ldv + 4 * 1], v61);
_mm256_storeu_pd(&V[i + (n - 1) * ldv + 4 * 2], v62);
}
void apply_rev_avx_mv_seq(int k,int m, int n, double *G, double *V,int ldg)
{
__m512d  v00,  v01,  v02,  v10,  v11,  v12,  v20,  v21,  v22,  v30,  v31,  v32,  v40,  v41,  v42,  v50,  v51,  v52,  v60,  v61,  v62,  v70,  v71,  v72, gamma, sigma, tmp;
v00 = _mm512_loadu_pd(&V[0 + 0]);
v01 = _mm512_loadu_pd(&V[0 + 8]);
v02 = _mm512_loadu_pd(&V[0 + 16]);
v10 = _mm512_loadu_pd(&V[24 + 0]);
v11 = _mm512_loadu_pd(&V[24 + 8]);
v12 = _mm512_loadu_pd(&V[24 + 16]);
v20 = _mm512_loadu_pd(&V[48 + 0]);
v21 = _mm512_loadu_pd(&V[48 + 8]);
v22 = _mm512_loadu_pd(&V[48 + 16]);
v30 = _mm512_loadu_pd(&V[72 + 0]);
v31 = _mm512_loadu_pd(&V[72 + 8]);
v32 = _mm512_loadu_pd(&V[72 + 16]);
v40 = _mm512_loadu_pd(&V[96 + 0]);
v41 = _mm512_loadu_pd(&V[96 + 8]);
v42 = _mm512_loadu_pd(&V[96 + 16]);
v50 = _mm512_loadu_pd(&V[120 + 0]);
v51 = _mm512_loadu_pd(&V[120 + 8]);
v52 = _mm512_loadu_pd(&V[120 + 16]);
v60 = _mm512_loadu_pd(&V[144 + 0]);
v61 = _mm512_loadu_pd(&V[144 + 8]);
v62 = _mm512_loadu_pd(&V[144 + 16]);
    gamma = _mm512_set1_pd(G[2 * 0 + k * ldg]);
    sigma = _mm512_set1_pd(G[2 * 0 + k * ldg + 1]);
 tmp = v00;
 v00 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v10));
 v10 = _mm512_sub_pd(_mm512_mul_pd(gamma, v10), _mm512_mul_pd(sigma, tmp));
 tmp = v01;
 v01 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v11));
 v11 = _mm512_sub_pd(_mm512_mul_pd(gamma, v11), _mm512_mul_pd(sigma, tmp));
 tmp = v02;
 v02 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v12));
 v12 = _mm512_sub_pd(_mm512_mul_pd(gamma, v12), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 1  + k * ldg]);
    sigma = _mm512_set1_pd(G[2 * 1  + k * ldg + 1]);
 tmp = v10;
 v10 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v20));
 v20 = _mm512_sub_pd(_mm512_mul_pd(gamma, v20), _mm512_mul_pd(sigma, tmp));
 tmp = v11;
 v11 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v21));
 v21 = _mm512_sub_pd(_mm512_mul_pd(gamma, v21), _mm512_mul_pd(sigma, tmp));
 tmp = v12;
 v12 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v22));
 v22 = _mm512_sub_pd(_mm512_mul_pd(gamma, v22), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 0 + (k + 1) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 0 + (k + 1) * ldg  + 1]);
 tmp = v00;
 v00 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v10));
 v10 = _mm512_sub_pd(_mm512_mul_pd(gamma, v10), _mm512_mul_pd(sigma, tmp));
 tmp = v01;
 v01 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v11));
 v11 = _mm512_sub_pd(_mm512_mul_pd(gamma, v11), _mm512_mul_pd(sigma, tmp));
 tmp = v02;
 v02 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v12));
 v12 = _mm512_sub_pd(_mm512_mul_pd(gamma, v12), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 2  + k * ldg]);
    sigma = _mm512_set1_pd(G[2 * 2  + k * ldg + 1]);
 tmp = v20;
 v20 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v30));
 v30 = _mm512_sub_pd(_mm512_mul_pd(gamma, v30), _mm512_mul_pd(sigma, tmp));
 tmp = v21;
 v21 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v31));
 v31 = _mm512_sub_pd(_mm512_mul_pd(gamma, v31), _mm512_mul_pd(sigma, tmp));
 tmp = v22;
 v22 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v32));
 v32 = _mm512_sub_pd(_mm512_mul_pd(gamma, v32), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 1  + (k + 1) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 1  + (k + 1) * ldg  + 1]);
 tmp = v10;
 v10 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v20));
 v20 = _mm512_sub_pd(_mm512_mul_pd(gamma, v20), _mm512_mul_pd(sigma, tmp));
 tmp = v11;
 v11 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v21));
 v21 = _mm512_sub_pd(_mm512_mul_pd(gamma, v21), _mm512_mul_pd(sigma, tmp));
 tmp = v12;
 v12 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v22));
 v22 = _mm512_sub_pd(_mm512_mul_pd(gamma, v22), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 0 + (k + 2) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 0 + (k + 2) * ldg  + 1]);
 tmp = v00;
 v00 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v10));
 v10 = _mm512_sub_pd(_mm512_mul_pd(gamma, v10), _mm512_mul_pd(sigma, tmp));
 tmp = v01;
 v01 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v11));
 v11 = _mm512_sub_pd(_mm512_mul_pd(gamma, v11), _mm512_mul_pd(sigma, tmp));
 tmp = v02;
 v02 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v12));
 v12 = _mm512_sub_pd(_mm512_mul_pd(gamma, v12), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 3  + k * ldg]);
    sigma = _mm512_set1_pd(G[2 * 3  + k * ldg + 1]);
 tmp = v30;
 v30 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v40));
 v40 = _mm512_sub_pd(_mm512_mul_pd(gamma, v40), _mm512_mul_pd(sigma, tmp));
 tmp = v31;
 v31 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v41));
 v41 = _mm512_sub_pd(_mm512_mul_pd(gamma, v41), _mm512_mul_pd(sigma, tmp));
 tmp = v32;
 v32 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v42));
 v42 = _mm512_sub_pd(_mm512_mul_pd(gamma, v42), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 2  + (k + 1) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 2  + (k + 1) * ldg  + 1]);
 tmp = v20;
 v20 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v30));
 v30 = _mm512_sub_pd(_mm512_mul_pd(gamma, v30), _mm512_mul_pd(sigma, tmp));
 tmp = v21;
 v21 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v31));
 v31 = _mm512_sub_pd(_mm512_mul_pd(gamma, v31), _mm512_mul_pd(sigma, tmp));
 tmp = v22;
 v22 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v32));
 v32 = _mm512_sub_pd(_mm512_mul_pd(gamma, v32), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 1  + (k + 2) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 1  + (k + 2) * ldg  + 1]);
 tmp = v10;
 v10 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v20));
 v20 = _mm512_sub_pd(_mm512_mul_pd(gamma, v20), _mm512_mul_pd(sigma, tmp));
 tmp = v11;
 v11 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v21));
 v21 = _mm512_sub_pd(_mm512_mul_pd(gamma, v21), _mm512_mul_pd(sigma, tmp));
 tmp = v12;
 v12 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v22));
 v22 = _mm512_sub_pd(_mm512_mul_pd(gamma, v22), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 0 + (k + 3) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 0 + (k + 3) * ldg  + 1]);
 tmp = v00;
 v00 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v10));
 v10 = _mm512_sub_pd(_mm512_mul_pd(gamma, v10), _mm512_mul_pd(sigma, tmp));
 tmp = v01;
 v01 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v11));
 v11 = _mm512_sub_pd(_mm512_mul_pd(gamma, v11), _mm512_mul_pd(sigma, tmp));
 tmp = v02;
 v02 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v12));
 v12 = _mm512_sub_pd(_mm512_mul_pd(gamma, v12), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 4  + k * ldg]);
    sigma = _mm512_set1_pd(G[2 * 4  + k * ldg + 1]);
 tmp = v40;
 v40 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v50));
 v50 = _mm512_sub_pd(_mm512_mul_pd(gamma, v50), _mm512_mul_pd(sigma, tmp));
 tmp = v41;
 v41 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v51));
 v51 = _mm512_sub_pd(_mm512_mul_pd(gamma, v51), _mm512_mul_pd(sigma, tmp));
 tmp = v42;
 v42 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v52));
 v52 = _mm512_sub_pd(_mm512_mul_pd(gamma, v52), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 3  + (k + 1) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 3  + (k + 1) * ldg  + 1]);
 tmp = v30;
 v30 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v40));
 v40 = _mm512_sub_pd(_mm512_mul_pd(gamma, v40), _mm512_mul_pd(sigma, tmp));
 tmp = v31;
 v31 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v41));
 v41 = _mm512_sub_pd(_mm512_mul_pd(gamma, v41), _mm512_mul_pd(sigma, tmp));
 tmp = v32;
 v32 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v42));
 v42 = _mm512_sub_pd(_mm512_mul_pd(gamma, v42), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 2  + (k + 2) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 2  + (k + 2) * ldg  + 1]);
 tmp = v20;
 v20 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v30));
 v30 = _mm512_sub_pd(_mm512_mul_pd(gamma, v30), _mm512_mul_pd(sigma, tmp));
 tmp = v21;
 v21 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v31));
 v31 = _mm512_sub_pd(_mm512_mul_pd(gamma, v31), _mm512_mul_pd(sigma, tmp));
 tmp = v22;
 v22 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v32));
 v32 = _mm512_sub_pd(_mm512_mul_pd(gamma, v32), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 1  + (k + 3) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 1  + (k + 3) * ldg  + 1]);
 tmp = v10;
 v10 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v20));
 v20 = _mm512_sub_pd(_mm512_mul_pd(gamma, v20), _mm512_mul_pd(sigma, tmp));
 tmp = v11;
 v11 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v21));
 v21 = _mm512_sub_pd(_mm512_mul_pd(gamma, v21), _mm512_mul_pd(sigma, tmp));
 tmp = v12;
 v12 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v22));
 v22 = _mm512_sub_pd(_mm512_mul_pd(gamma, v22), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 0 + (k + 4) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 0 + (k + 4) * ldg  + 1]);
 tmp = v00;
 v00 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v10));
 v10 = _mm512_sub_pd(_mm512_mul_pd(gamma, v10), _mm512_mul_pd(sigma, tmp));
 tmp = v01;
 v01 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v11));
 v11 = _mm512_sub_pd(_mm512_mul_pd(gamma, v11), _mm512_mul_pd(sigma, tmp));
 tmp = v02;
 v02 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v12));
 v12 = _mm512_sub_pd(_mm512_mul_pd(gamma, v12), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 5  + k * ldg]);
    sigma = _mm512_set1_pd(G[2 * 5  + k * ldg + 1]);
 tmp = v50;
 v50 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v60));
 v60 = _mm512_sub_pd(_mm512_mul_pd(gamma, v60), _mm512_mul_pd(sigma, tmp));
 tmp = v51;
 v51 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v61));
 v61 = _mm512_sub_pd(_mm512_mul_pd(gamma, v61), _mm512_mul_pd(sigma, tmp));
 tmp = v52;
 v52 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v62));
 v62 = _mm512_sub_pd(_mm512_mul_pd(gamma, v62), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 4  + (k + 1) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 4  + (k + 1) * ldg  + 1]);
 tmp = v40;
 v40 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v50));
 v50 = _mm512_sub_pd(_mm512_mul_pd(gamma, v50), _mm512_mul_pd(sigma, tmp));
 tmp = v41;
 v41 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v51));
 v51 = _mm512_sub_pd(_mm512_mul_pd(gamma, v51), _mm512_mul_pd(sigma, tmp));
 tmp = v42;
 v42 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v52));
 v52 = _mm512_sub_pd(_mm512_mul_pd(gamma, v52), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 3  + (k + 2) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 3  + (k + 2) * ldg  + 1]);
 tmp = v30;
 v30 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v40));
 v40 = _mm512_sub_pd(_mm512_mul_pd(gamma, v40), _mm512_mul_pd(sigma, tmp));
 tmp = v31;
 v31 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v41));
 v41 = _mm512_sub_pd(_mm512_mul_pd(gamma, v41), _mm512_mul_pd(sigma, tmp));
 tmp = v32;
 v32 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v42));
 v42 = _mm512_sub_pd(_mm512_mul_pd(gamma, v42), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 2  + (k + 3) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 2  + (k + 3) * ldg  + 1]);
 tmp = v20;
 v20 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v30));
 v30 = _mm512_sub_pd(_mm512_mul_pd(gamma, v30), _mm512_mul_pd(sigma, tmp));
 tmp = v21;
 v21 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v31));
 v31 = _mm512_sub_pd(_mm512_mul_pd(gamma, v31), _mm512_mul_pd(sigma, tmp));
 tmp = v22;
 v22 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v32));
 v32 = _mm512_sub_pd(_mm512_mul_pd(gamma, v32), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 1  + (k + 4) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 1  + (k + 4) * ldg  + 1]);
 tmp = v10;
 v10 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v20));
 v20 = _mm512_sub_pd(_mm512_mul_pd(gamma, v20), _mm512_mul_pd(sigma, tmp));
 tmp = v11;
 v11 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v21));
 v21 = _mm512_sub_pd(_mm512_mul_pd(gamma, v21), _mm512_mul_pd(sigma, tmp));
 tmp = v12;
 v12 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v22));
 v22 = _mm512_sub_pd(_mm512_mul_pd(gamma, v22), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 0 + (k + 5) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 0 + (k + 5) * ldg  + 1]);
 tmp = v00;
 v00 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v10));
 v10 = _mm512_sub_pd(_mm512_mul_pd(gamma, v10), _mm512_mul_pd(sigma, tmp));
 tmp = v01;
 v01 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v11));
 v11 = _mm512_sub_pd(_mm512_mul_pd(gamma, v11), _mm512_mul_pd(sigma, tmp));
 tmp = v02;
 v02 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v12));
 v12 = _mm512_sub_pd(_mm512_mul_pd(gamma, v12), _mm512_mul_pd(sigma, tmp));
for (int g = 6; g < n - 1; g++)
{
v70 = _mm512_loadu_pd(&V[(g + 1) * 24 + 0]);
v71 = _mm512_loadu_pd(&V[(g + 1) * 24 + 8]);
v72 = _mm512_loadu_pd(&V[(g + 1) * 24 + 16]);
gamma = _mm512_set1_pd(G[2 * g + k * ldg]);
sigma = _mm512_set1_pd(G[2 * g + k * ldg + 1]);
tmp = v60;
 v60 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v70));
 v70 = _mm512_sub_pd(_mm512_mul_pd(gamma, v70), _mm512_mul_pd(sigma, tmp));
tmp = v61;
 v61 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v71));
 v71 = _mm512_sub_pd(_mm512_mul_pd(gamma, v71), _mm512_mul_pd(sigma, tmp));
tmp = v62;
 v62 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v72));
 v72 = _mm512_sub_pd(_mm512_mul_pd(gamma, v72), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (g - 1) + (k + 1) * ldg]);
sigma = _mm512_set1_pd(G[2 * (g - 1) + (k + 1) * ldg + 1]);
tmp = v50;
 v50 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v60));
 v60 = _mm512_sub_pd(_mm512_mul_pd(gamma, v60), _mm512_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v61));
 v61 = _mm512_sub_pd(_mm512_mul_pd(gamma, v61), _mm512_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v62));
 v62 = _mm512_sub_pd(_mm512_mul_pd(gamma, v62), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (g - 2) + (k + 2) * ldg]);
sigma = _mm512_set1_pd(G[2 * (g - 2) + (k + 2) * ldg + 1]);
tmp = v40;
 v40 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v50));
 v50 = _mm512_sub_pd(_mm512_mul_pd(gamma, v50), _mm512_mul_pd(sigma, tmp));
tmp = v41;
 v41 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v51));
 v51 = _mm512_sub_pd(_mm512_mul_pd(gamma, v51), _mm512_mul_pd(sigma, tmp));
tmp = v42;
 v42 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v52));
 v52 = _mm512_sub_pd(_mm512_mul_pd(gamma, v52), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (g - 3) + (k + 3) * ldg]);
sigma = _mm512_set1_pd(G[2 * (g - 3) + (k + 3) * ldg + 1]);
tmp = v30;
 v30 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v40));
 v40 = _mm512_sub_pd(_mm512_mul_pd(gamma, v40), _mm512_mul_pd(sigma, tmp));
tmp = v31;
 v31 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v41));
 v41 = _mm512_sub_pd(_mm512_mul_pd(gamma, v41), _mm512_mul_pd(sigma, tmp));
tmp = v32;
 v32 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v42));
 v42 = _mm512_sub_pd(_mm512_mul_pd(gamma, v42), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (g - 4) + (k + 4) * ldg]);
sigma = _mm512_set1_pd(G[2 * (g - 4) + (k + 4) * ldg + 1]);
tmp = v20;
 v20 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v30));
 v30 = _mm512_sub_pd(_mm512_mul_pd(gamma, v30), _mm512_mul_pd(sigma, tmp));
tmp = v21;
 v21 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v31));
 v31 = _mm512_sub_pd(_mm512_mul_pd(gamma, v31), _mm512_mul_pd(sigma, tmp));
tmp = v22;
 v22 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v32));
 v32 = _mm512_sub_pd(_mm512_mul_pd(gamma, v32), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (g - 5) + (k + 5) * ldg]);
sigma = _mm512_set1_pd(G[2 * (g - 5) + (k + 5) * ldg + 1]);
tmp = v10;
 v10 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v20));
 v20 = _mm512_sub_pd(_mm512_mul_pd(gamma, v20), _mm512_mul_pd(sigma, tmp));
tmp = v11;
 v11 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v21));
 v21 = _mm512_sub_pd(_mm512_mul_pd(gamma, v21), _mm512_mul_pd(sigma, tmp));
tmp = v12;
 v12 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v22));
 v22 = _mm512_sub_pd(_mm512_mul_pd(gamma, v22), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (g - 6) + (k + 6) * ldg]);
sigma = _mm512_set1_pd(G[2 * (g - 6) + (k + 6) * ldg + 1]);
tmp = v00;
 v00 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v10));
 v10 = _mm512_sub_pd(_mm512_mul_pd(gamma, v10), _mm512_mul_pd(sigma, tmp));
tmp = v01;
 v01 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v11));
 v11 = _mm512_sub_pd(_mm512_mul_pd(gamma, v11), _mm512_mul_pd(sigma, tmp));
tmp = v02;
 v02 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v12));
 v12 = _mm512_sub_pd(_mm512_mul_pd(gamma, v12), _mm512_mul_pd(sigma, tmp));
_mm512_storeu_pd(&V[24 * (g - 6)], v00);
_mm512_storeu_pd(&V[24 * (g - 6) + 8 * 1], v01);
_mm512_storeu_pd(&V[24 * (g - 6) + 8 * 2], v02);
v00=v10;
v01=v11;
v02=v12;
v10=v20;
v11=v21;
v12=v22;
v20=v30;
v21=v31;
v22=v32;
v30=v40;
v31=v41;
v32=v42;
v40=v50;
v41=v51;
v42=v52;
v50=v60;
v51=v61;
v52=v62;
v60=v70;
v61=v71;
v62=v72;
}
gamma = _mm512_set1_pd(G[2 * (n - 2) + (k + 1) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 2) + (k + 1) * ldg + 1]);
tmp = v50;
 v50 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v60));
 v60 = _mm512_sub_pd(_mm512_mul_pd(gamma, v60), _mm512_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v61));
 v61 = _mm512_sub_pd(_mm512_mul_pd(gamma, v61), _mm512_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v62));
 v62 = _mm512_sub_pd(_mm512_mul_pd(gamma, v62), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 3) + (k + 2) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 3) + (k + 2) * ldg + 1]);
tmp = v40;
 v40 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v50));
 v50 = _mm512_sub_pd(_mm512_mul_pd(gamma, v50), _mm512_mul_pd(sigma, tmp));
tmp = v41;
 v41 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v51));
 v51 = _mm512_sub_pd(_mm512_mul_pd(gamma, v51), _mm512_mul_pd(sigma, tmp));
tmp = v42;
 v42 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v52));
 v52 = _mm512_sub_pd(_mm512_mul_pd(gamma, v52), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 4) + (k + 3) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 4) + (k + 3) * ldg + 1]);
tmp = v30;
 v30 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v40));
 v40 = _mm512_sub_pd(_mm512_mul_pd(gamma, v40), _mm512_mul_pd(sigma, tmp));
tmp = v31;
 v31 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v41));
 v41 = _mm512_sub_pd(_mm512_mul_pd(gamma, v41), _mm512_mul_pd(sigma, tmp));
tmp = v32;
 v32 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v42));
 v42 = _mm512_sub_pd(_mm512_mul_pd(gamma, v42), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 5) + (k + 4) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 5) + (k + 4) * ldg + 1]);
tmp = v20;
 v20 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v30));
 v30 = _mm512_sub_pd(_mm512_mul_pd(gamma, v30), _mm512_mul_pd(sigma, tmp));
tmp = v21;
 v21 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v31));
 v31 = _mm512_sub_pd(_mm512_mul_pd(gamma, v31), _mm512_mul_pd(sigma, tmp));
tmp = v22;
 v22 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v32));
 v32 = _mm512_sub_pd(_mm512_mul_pd(gamma, v32), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 6) + (k + 5) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 6) + (k + 5) * ldg + 1]);
tmp = v10;
 v10 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v20));
 v20 = _mm512_sub_pd(_mm512_mul_pd(gamma, v20), _mm512_mul_pd(sigma, tmp));
tmp = v11;
 v11 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v21));
 v21 = _mm512_sub_pd(_mm512_mul_pd(gamma, v21), _mm512_mul_pd(sigma, tmp));
tmp = v12;
 v12 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v22));
 v22 = _mm512_sub_pd(_mm512_mul_pd(gamma, v22), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 7) + (k + 6) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 7) + (k + 6) * ldg + 1]);
tmp = v00;
 v00 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v10));
 v10 = _mm512_sub_pd(_mm512_mul_pd(gamma, v10), _mm512_mul_pd(sigma, tmp));
tmp = v01;
 v01 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v11));
 v11 = _mm512_sub_pd(_mm512_mul_pd(gamma, v11), _mm512_mul_pd(sigma, tmp));
tmp = v02;
 v02 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v12));
 v12 = _mm512_sub_pd(_mm512_mul_pd(gamma, v12), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 2) + (k + 2) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 2) + (k + 2) * ldg + 1]);
tmp = v50;
 v50 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v60));
 v60 = _mm512_sub_pd(_mm512_mul_pd(gamma, v60), _mm512_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v61));
 v61 = _mm512_sub_pd(_mm512_mul_pd(gamma, v61), _mm512_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v62));
 v62 = _mm512_sub_pd(_mm512_mul_pd(gamma, v62), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 3) + (k + 3) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 3) + (k + 3) * ldg + 1]);
tmp = v40;
 v40 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v50));
 v50 = _mm512_sub_pd(_mm512_mul_pd(gamma, v50), _mm512_mul_pd(sigma, tmp));
tmp = v41;
 v41 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v51));
 v51 = _mm512_sub_pd(_mm512_mul_pd(gamma, v51), _mm512_mul_pd(sigma, tmp));
tmp = v42;
 v42 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v52));
 v52 = _mm512_sub_pd(_mm512_mul_pd(gamma, v52), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 4) + (k + 4) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 4) + (k + 4) * ldg + 1]);
tmp = v30;
 v30 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v40));
 v40 = _mm512_sub_pd(_mm512_mul_pd(gamma, v40), _mm512_mul_pd(sigma, tmp));
tmp = v31;
 v31 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v41));
 v41 = _mm512_sub_pd(_mm512_mul_pd(gamma, v41), _mm512_mul_pd(sigma, tmp));
tmp = v32;
 v32 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v42));
 v42 = _mm512_sub_pd(_mm512_mul_pd(gamma, v42), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 5) + (k + 5) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 5) + (k + 5) * ldg + 1]);
tmp = v20;
 v20 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v30));
 v30 = _mm512_sub_pd(_mm512_mul_pd(gamma, v30), _mm512_mul_pd(sigma, tmp));
tmp = v21;
 v21 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v31));
 v31 = _mm512_sub_pd(_mm512_mul_pd(gamma, v31), _mm512_mul_pd(sigma, tmp));
tmp = v22;
 v22 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v32));
 v32 = _mm512_sub_pd(_mm512_mul_pd(gamma, v32), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 6) + (k + 6) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 6) + (k + 6) * ldg + 1]);
tmp = v10;
 v10 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v20));
 v20 = _mm512_sub_pd(_mm512_mul_pd(gamma, v20), _mm512_mul_pd(sigma, tmp));
tmp = v11;
 v11 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v21));
 v21 = _mm512_sub_pd(_mm512_mul_pd(gamma, v21), _mm512_mul_pd(sigma, tmp));
tmp = v12;
 v12 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v22));
 v22 = _mm512_sub_pd(_mm512_mul_pd(gamma, v22), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 2) + (k + 3) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 2) + (k + 3) * ldg + 1]);
tmp = v50;
 v50 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v60));
 v60 = _mm512_sub_pd(_mm512_mul_pd(gamma, v60), _mm512_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v61));
 v61 = _mm512_sub_pd(_mm512_mul_pd(gamma, v61), _mm512_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v62));
 v62 = _mm512_sub_pd(_mm512_mul_pd(gamma, v62), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 3) + (k + 4) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 3) + (k + 4) * ldg + 1]);
tmp = v40;
 v40 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v50));
 v50 = _mm512_sub_pd(_mm512_mul_pd(gamma, v50), _mm512_mul_pd(sigma, tmp));
tmp = v41;
 v41 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v51));
 v51 = _mm512_sub_pd(_mm512_mul_pd(gamma, v51), _mm512_mul_pd(sigma, tmp));
tmp = v42;
 v42 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v52));
 v52 = _mm512_sub_pd(_mm512_mul_pd(gamma, v52), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 4) + (k + 5) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 4) + (k + 5) * ldg + 1]);
tmp = v30;
 v30 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v40));
 v40 = _mm512_sub_pd(_mm512_mul_pd(gamma, v40), _mm512_mul_pd(sigma, tmp));
tmp = v31;
 v31 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v41));
 v41 = _mm512_sub_pd(_mm512_mul_pd(gamma, v41), _mm512_mul_pd(sigma, tmp));
tmp = v32;
 v32 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v42));
 v42 = _mm512_sub_pd(_mm512_mul_pd(gamma, v42), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 5) + (k + 6) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 5) + (k + 6) * ldg + 1]);
tmp = v20;
 v20 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v30));
 v30 = _mm512_sub_pd(_mm512_mul_pd(gamma, v30), _mm512_mul_pd(sigma, tmp));
tmp = v21;
 v21 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v31));
 v31 = _mm512_sub_pd(_mm512_mul_pd(gamma, v31), _mm512_mul_pd(sigma, tmp));
tmp = v22;
 v22 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v32));
 v32 = _mm512_sub_pd(_mm512_mul_pd(gamma, v32), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 2) + (k + 4) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 2) + (k + 4) * ldg + 1]);
tmp = v50;
 v50 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v60));
 v60 = _mm512_sub_pd(_mm512_mul_pd(gamma, v60), _mm512_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v61));
 v61 = _mm512_sub_pd(_mm512_mul_pd(gamma, v61), _mm512_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v62));
 v62 = _mm512_sub_pd(_mm512_mul_pd(gamma, v62), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 3) + (k + 5) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 3) + (k + 5) * ldg + 1]);
tmp = v40;
 v40 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v50));
 v50 = _mm512_sub_pd(_mm512_mul_pd(gamma, v50), _mm512_mul_pd(sigma, tmp));
tmp = v41;
 v41 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v51));
 v51 = _mm512_sub_pd(_mm512_mul_pd(gamma, v51), _mm512_mul_pd(sigma, tmp));
tmp = v42;
 v42 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v52));
 v52 = _mm512_sub_pd(_mm512_mul_pd(gamma, v52), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 4) + (k + 6) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 4) + (k + 6) * ldg + 1]);
tmp = v30;
 v30 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v40));
 v40 = _mm512_sub_pd(_mm512_mul_pd(gamma, v40), _mm512_mul_pd(sigma, tmp));
tmp = v31;
 v31 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v41));
 v41 = _mm512_sub_pd(_mm512_mul_pd(gamma, v41), _mm512_mul_pd(sigma, tmp));
tmp = v32;
 v32 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v42));
 v42 = _mm512_sub_pd(_mm512_mul_pd(gamma, v42), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 2) + (k + 5) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 2) + (k + 5) * ldg + 1]);
tmp = v50;
 v50 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v60));
 v60 = _mm512_sub_pd(_mm512_mul_pd(gamma, v60), _mm512_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v61));
 v61 = _mm512_sub_pd(_mm512_mul_pd(gamma, v61), _mm512_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v62));
 v62 = _mm512_sub_pd(_mm512_mul_pd(gamma, v62), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 3) + (k + 6) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 3) + (k + 6) * ldg + 1]);
tmp = v40;
 v40 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v50));
 v50 = _mm512_sub_pd(_mm512_mul_pd(gamma, v50), _mm512_mul_pd(sigma, tmp));
tmp = v41;
 v41 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v51));
 v51 = _mm512_sub_pd(_mm512_mul_pd(gamma, v51), _mm512_mul_pd(sigma, tmp));
tmp = v42;
 v42 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v52));
 v52 = _mm512_sub_pd(_mm512_mul_pd(gamma, v52), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 2) + (k + 6) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 2) + (k + 6) * ldg + 1]);
tmp = v50;
 v50 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v60));
 v60 = _mm512_sub_pd(_mm512_mul_pd(gamma, v60), _mm512_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v61));
 v61 = _mm512_sub_pd(_mm512_mul_pd(gamma, v61), _mm512_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v62));
 v62 = _mm512_sub_pd(_mm512_mul_pd(gamma, v62), _mm512_mul_pd(sigma, tmp));
_mm512_storeu_pd(&V[24 * (n - 7)], v00);
_mm512_storeu_pd(&V[24 * (n - 7)+ 8 * 1], v01);
_mm512_storeu_pd(&V[24 * (n - 7)+ 8 * 2], v02);
_mm512_storeu_pd(&V[24 * (n - 6)], v10);
_mm512_storeu_pd(&V[24 * (n - 6)+ 8 * 1], v11);
_mm512_storeu_pd(&V[24 * (n - 6)+ 8 * 2], v12);
_mm512_storeu_pd(&V[24 * (n - 5)], v20);
_mm512_storeu_pd(&V[24 * (n - 5)+ 8 * 1], v21);
_mm512_storeu_pd(&V[24 * (n - 5)+ 8 * 2], v22);
_mm512_storeu_pd(&V[24 * (n - 4)], v30);
_mm512_storeu_pd(&V[24 * (n - 4)+ 8 * 1], v31);
_mm512_storeu_pd(&V[24 * (n - 4)+ 8 * 2], v32);
_mm512_storeu_pd(&V[24 * (n - 3)], v40);
_mm512_storeu_pd(&V[24 * (n - 3)+ 8 * 1], v41);
_mm512_storeu_pd(&V[24 * (n - 3)+ 8 * 2], v42);
_mm512_storeu_pd(&V[24 * (n - 2)], v50);
_mm512_storeu_pd(&V[24 * (n - 2)+ 8 * 1], v51);
_mm512_storeu_pd(&V[24 * (n - 2)+ 8 * 2], v52);
_mm512_storeu_pd(&V[24 * (n - 1)], v60);
_mm512_storeu_pd(&V[24 * (n - 1)+ 8 * 1], v61);
_mm512_storeu_pd(&V[24 * (n - 1)+ 8 * 2], v62);
}
void apply_rev_avx512_mv_seq(int k,int m, int n, double *G, double *V,int ldg)
{
__m512d  v00,  v01,  v02,  v10,  v11,  v12,  v20,  v21,  v22,  v30,  v31,  v32,  v40,  v41,  v42,  v50,  v51,  v52,  v60,  v61,  v62,  v70,  v71,  v72, gamma, sigma, tmp;
v00 = _mm512_loadu_pd(&V[0 + 0]);
v01 = _mm512_loadu_pd(&V[0 + 8]);
v02 = _mm512_loadu_pd(&V[0 + 16]);
v10 = _mm512_loadu_pd(&V[24 + 0]);
v11 = _mm512_loadu_pd(&V[24 + 8]);
v12 = _mm512_loadu_pd(&V[24 + 16]);
v20 = _mm512_loadu_pd(&V[48 + 0]);
v21 = _mm512_loadu_pd(&V[48 + 8]);
v22 = _mm512_loadu_pd(&V[48 + 16]);
v30 = _mm512_loadu_pd(&V[72 + 0]);
v31 = _mm512_loadu_pd(&V[72 + 8]);
v32 = _mm512_loadu_pd(&V[72 + 16]);
v40 = _mm512_loadu_pd(&V[96 + 0]);
v41 = _mm512_loadu_pd(&V[96 + 8]);
v42 = _mm512_loadu_pd(&V[96 + 16]);
v50 = _mm512_loadu_pd(&V[120 + 0]);
v51 = _mm512_loadu_pd(&V[120 + 8]);
v52 = _mm512_loadu_pd(&V[120 + 16]);
v60 = _mm512_loadu_pd(&V[144 + 0]);
v61 = _mm512_loadu_pd(&V[144 + 8]);
v62 = _mm512_loadu_pd(&V[144 + 16]);
    gamma = _mm512_set1_pd(G[2 * 0 + k * ldg]);
    sigma = _mm512_set1_pd(G[2 * 0 + k * ldg + 1]);
 tmp = v00;
 v00 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v10));
 v10 = _mm512_sub_pd(_mm512_mul_pd(gamma, v10), _mm512_mul_pd(sigma, tmp));
 tmp = v01;
 v01 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v11));
 v11 = _mm512_sub_pd(_mm512_mul_pd(gamma, v11), _mm512_mul_pd(sigma, tmp));
 tmp = v02;
 v02 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v12));
 v12 = _mm512_sub_pd(_mm512_mul_pd(gamma, v12), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 1  + k * ldg]);
    sigma = _mm512_set1_pd(G[2 * 1  + k * ldg + 1]);
 tmp = v10;
 v10 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v20));
 v20 = _mm512_sub_pd(_mm512_mul_pd(gamma, v20), _mm512_mul_pd(sigma, tmp));
 tmp = v11;
 v11 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v21));
 v21 = _mm512_sub_pd(_mm512_mul_pd(gamma, v21), _mm512_mul_pd(sigma, tmp));
 tmp = v12;
 v12 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v22));
 v22 = _mm512_sub_pd(_mm512_mul_pd(gamma, v22), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 0 + (k + 1) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 0 + (k + 1) * ldg  + 1]);
 tmp = v00;
 v00 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v10));
 v10 = _mm512_sub_pd(_mm512_mul_pd(gamma, v10), _mm512_mul_pd(sigma, tmp));
 tmp = v01;
 v01 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v11));
 v11 = _mm512_sub_pd(_mm512_mul_pd(gamma, v11), _mm512_mul_pd(sigma, tmp));
 tmp = v02;
 v02 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v12));
 v12 = _mm512_sub_pd(_mm512_mul_pd(gamma, v12), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 2  + k * ldg]);
    sigma = _mm512_set1_pd(G[2 * 2  + k * ldg + 1]);
 tmp = v20;
 v20 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v30));
 v30 = _mm512_sub_pd(_mm512_mul_pd(gamma, v30), _mm512_mul_pd(sigma, tmp));
 tmp = v21;
 v21 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v31));
 v31 = _mm512_sub_pd(_mm512_mul_pd(gamma, v31), _mm512_mul_pd(sigma, tmp));
 tmp = v22;
 v22 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v32));
 v32 = _mm512_sub_pd(_mm512_mul_pd(gamma, v32), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 1  + (k + 1) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 1  + (k + 1) * ldg  + 1]);
 tmp = v10;
 v10 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v20));
 v20 = _mm512_sub_pd(_mm512_mul_pd(gamma, v20), _mm512_mul_pd(sigma, tmp));
 tmp = v11;
 v11 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v21));
 v21 = _mm512_sub_pd(_mm512_mul_pd(gamma, v21), _mm512_mul_pd(sigma, tmp));
 tmp = v12;
 v12 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v22));
 v22 = _mm512_sub_pd(_mm512_mul_pd(gamma, v22), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 0 + (k + 2) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 0 + (k + 2) * ldg  + 1]);
 tmp = v00;
 v00 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v10));
 v10 = _mm512_sub_pd(_mm512_mul_pd(gamma, v10), _mm512_mul_pd(sigma, tmp));
 tmp = v01;
 v01 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v11));
 v11 = _mm512_sub_pd(_mm512_mul_pd(gamma, v11), _mm512_mul_pd(sigma, tmp));
 tmp = v02;
 v02 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v12));
 v12 = _mm512_sub_pd(_mm512_mul_pd(gamma, v12), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 3  + k * ldg]);
    sigma = _mm512_set1_pd(G[2 * 3  + k * ldg + 1]);
 tmp = v30;
 v30 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v40));
 v40 = _mm512_sub_pd(_mm512_mul_pd(gamma, v40), _mm512_mul_pd(sigma, tmp));
 tmp = v31;
 v31 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v41));
 v41 = _mm512_sub_pd(_mm512_mul_pd(gamma, v41), _mm512_mul_pd(sigma, tmp));
 tmp = v32;
 v32 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v42));
 v42 = _mm512_sub_pd(_mm512_mul_pd(gamma, v42), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 2  + (k + 1) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 2  + (k + 1) * ldg  + 1]);
 tmp = v20;
 v20 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v30));
 v30 = _mm512_sub_pd(_mm512_mul_pd(gamma, v30), _mm512_mul_pd(sigma, tmp));
 tmp = v21;
 v21 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v31));
 v31 = _mm512_sub_pd(_mm512_mul_pd(gamma, v31), _mm512_mul_pd(sigma, tmp));
 tmp = v22;
 v22 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v32));
 v32 = _mm512_sub_pd(_mm512_mul_pd(gamma, v32), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 1  + (k + 2) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 1  + (k + 2) * ldg  + 1]);
 tmp = v10;
 v10 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v20));
 v20 = _mm512_sub_pd(_mm512_mul_pd(gamma, v20), _mm512_mul_pd(sigma, tmp));
 tmp = v11;
 v11 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v21));
 v21 = _mm512_sub_pd(_mm512_mul_pd(gamma, v21), _mm512_mul_pd(sigma, tmp));
 tmp = v12;
 v12 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v22));
 v22 = _mm512_sub_pd(_mm512_mul_pd(gamma, v22), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 0 + (k + 3) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 0 + (k + 3) * ldg  + 1]);
 tmp = v00;
 v00 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v10));
 v10 = _mm512_sub_pd(_mm512_mul_pd(gamma, v10), _mm512_mul_pd(sigma, tmp));
 tmp = v01;
 v01 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v11));
 v11 = _mm512_sub_pd(_mm512_mul_pd(gamma, v11), _mm512_mul_pd(sigma, tmp));
 tmp = v02;
 v02 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v12));
 v12 = _mm512_sub_pd(_mm512_mul_pd(gamma, v12), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 4  + k * ldg]);
    sigma = _mm512_set1_pd(G[2 * 4  + k * ldg + 1]);
 tmp = v40;
 v40 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v50));
 v50 = _mm512_sub_pd(_mm512_mul_pd(gamma, v50), _mm512_mul_pd(sigma, tmp));
 tmp = v41;
 v41 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v51));
 v51 = _mm512_sub_pd(_mm512_mul_pd(gamma, v51), _mm512_mul_pd(sigma, tmp));
 tmp = v42;
 v42 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v52));
 v52 = _mm512_sub_pd(_mm512_mul_pd(gamma, v52), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 3  + (k + 1) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 3  + (k + 1) * ldg  + 1]);
 tmp = v30;
 v30 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v40));
 v40 = _mm512_sub_pd(_mm512_mul_pd(gamma, v40), _mm512_mul_pd(sigma, tmp));
 tmp = v31;
 v31 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v41));
 v41 = _mm512_sub_pd(_mm512_mul_pd(gamma, v41), _mm512_mul_pd(sigma, tmp));
 tmp = v32;
 v32 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v42));
 v42 = _mm512_sub_pd(_mm512_mul_pd(gamma, v42), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 2  + (k + 2) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 2  + (k + 2) * ldg  + 1]);
 tmp = v20;
 v20 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v30));
 v30 = _mm512_sub_pd(_mm512_mul_pd(gamma, v30), _mm512_mul_pd(sigma, tmp));
 tmp = v21;
 v21 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v31));
 v31 = _mm512_sub_pd(_mm512_mul_pd(gamma, v31), _mm512_mul_pd(sigma, tmp));
 tmp = v22;
 v22 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v32));
 v32 = _mm512_sub_pd(_mm512_mul_pd(gamma, v32), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 1  + (k + 3) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 1  + (k + 3) * ldg  + 1]);
 tmp = v10;
 v10 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v20));
 v20 = _mm512_sub_pd(_mm512_mul_pd(gamma, v20), _mm512_mul_pd(sigma, tmp));
 tmp = v11;
 v11 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v21));
 v21 = _mm512_sub_pd(_mm512_mul_pd(gamma, v21), _mm512_mul_pd(sigma, tmp));
 tmp = v12;
 v12 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v22));
 v22 = _mm512_sub_pd(_mm512_mul_pd(gamma, v22), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 0 + (k + 4) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 0 + (k + 4) * ldg  + 1]);
 tmp = v00;
 v00 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v10));
 v10 = _mm512_sub_pd(_mm512_mul_pd(gamma, v10), _mm512_mul_pd(sigma, tmp));
 tmp = v01;
 v01 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v11));
 v11 = _mm512_sub_pd(_mm512_mul_pd(gamma, v11), _mm512_mul_pd(sigma, tmp));
 tmp = v02;
 v02 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v12));
 v12 = _mm512_sub_pd(_mm512_mul_pd(gamma, v12), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 5  + k * ldg]);
    sigma = _mm512_set1_pd(G[2 * 5  + k * ldg + 1]);
 tmp = v50;
 v50 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v60));
 v60 = _mm512_sub_pd(_mm512_mul_pd(gamma, v60), _mm512_mul_pd(sigma, tmp));
 tmp = v51;
 v51 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v61));
 v61 = _mm512_sub_pd(_mm512_mul_pd(gamma, v61), _mm512_mul_pd(sigma, tmp));
 tmp = v52;
 v52 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v62));
 v62 = _mm512_sub_pd(_mm512_mul_pd(gamma, v62), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 4  + (k + 1) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 4  + (k + 1) * ldg  + 1]);
 tmp = v40;
 v40 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v50));
 v50 = _mm512_sub_pd(_mm512_mul_pd(gamma, v50), _mm512_mul_pd(sigma, tmp));
 tmp = v41;
 v41 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v51));
 v51 = _mm512_sub_pd(_mm512_mul_pd(gamma, v51), _mm512_mul_pd(sigma, tmp));
 tmp = v42;
 v42 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v52));
 v52 = _mm512_sub_pd(_mm512_mul_pd(gamma, v52), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 3  + (k + 2) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 3  + (k + 2) * ldg  + 1]);
 tmp = v30;
 v30 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v40));
 v40 = _mm512_sub_pd(_mm512_mul_pd(gamma, v40), _mm512_mul_pd(sigma, tmp));
 tmp = v31;
 v31 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v41));
 v41 = _mm512_sub_pd(_mm512_mul_pd(gamma, v41), _mm512_mul_pd(sigma, tmp));
 tmp = v32;
 v32 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v42));
 v42 = _mm512_sub_pd(_mm512_mul_pd(gamma, v42), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 2  + (k + 3) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 2  + (k + 3) * ldg  + 1]);
 tmp = v20;
 v20 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v30));
 v30 = _mm512_sub_pd(_mm512_mul_pd(gamma, v30), _mm512_mul_pd(sigma, tmp));
 tmp = v21;
 v21 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v31));
 v31 = _mm512_sub_pd(_mm512_mul_pd(gamma, v31), _mm512_mul_pd(sigma, tmp));
 tmp = v22;
 v22 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v32));
 v32 = _mm512_sub_pd(_mm512_mul_pd(gamma, v32), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 1  + (k + 4) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 1  + (k + 4) * ldg  + 1]);
 tmp = v10;
 v10 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v20));
 v20 = _mm512_sub_pd(_mm512_mul_pd(gamma, v20), _mm512_mul_pd(sigma, tmp));
 tmp = v11;
 v11 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v21));
 v21 = _mm512_sub_pd(_mm512_mul_pd(gamma, v21), _mm512_mul_pd(sigma, tmp));
 tmp = v12;
 v12 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v22));
 v22 = _mm512_sub_pd(_mm512_mul_pd(gamma, v22), _mm512_mul_pd(sigma, tmp));
    gamma = _mm512_set1_pd(G[2 * 0 + (k + 5) * ldg ]);
    sigma = _mm512_set1_pd(G[2 * 0 + (k + 5) * ldg  + 1]);
 tmp = v00;
 v00 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v10));
 v10 = _mm512_sub_pd(_mm512_mul_pd(gamma, v10), _mm512_mul_pd(sigma, tmp));
 tmp = v01;
 v01 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v11));
 v11 = _mm512_sub_pd(_mm512_mul_pd(gamma, v11), _mm512_mul_pd(sigma, tmp));
 tmp = v02;
 v02 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v12));
 v12 = _mm512_sub_pd(_mm512_mul_pd(gamma, v12), _mm512_mul_pd(sigma, tmp));
for (int g = 6; g < n - 1; g++)
{
v70 = _mm512_loadu_pd(&V[(g + 1) * 24 + 0]);
v71 = _mm512_loadu_pd(&V[(g + 1) * 24 + 4]);
v72 = _mm512_loadu_pd(&V[(g + 1) * 24 + 8]);
gamma = _mm512_set1_pd(G[2 * g + k * ldg]);
sigma = _mm512_set1_pd(G[2 * g + k * ldg + 1]);
tmp = v60;
 v60 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v70));
 v70 = _mm512_sub_pd(_mm512_mul_pd(gamma, v70), _mm512_mul_pd(sigma, tmp));
tmp = v61;
 v61 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v71));
 v71 = _mm512_sub_pd(_mm512_mul_pd(gamma, v71), _mm512_mul_pd(sigma, tmp));
tmp = v62;
 v62 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v72));
 v72 = _mm512_sub_pd(_mm512_mul_pd(gamma, v72), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (g - 1) + (k + 1) * ldg]);
sigma = _mm512_set1_pd(G[2 * (g - 1) + (k + 1) * ldg + 1]);
tmp = v50;
 v50 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v60));
 v60 = _mm512_sub_pd(_mm512_mul_pd(gamma, v60), _mm512_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v61));
 v61 = _mm512_sub_pd(_mm512_mul_pd(gamma, v61), _mm512_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v62));
 v62 = _mm512_sub_pd(_mm512_mul_pd(gamma, v62), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (g - 2) + (k + 2) * ldg]);
sigma = _mm512_set1_pd(G[2 * (g - 2) + (k + 2) * ldg + 1]);
tmp = v40;
 v40 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v50));
 v50 = _mm512_sub_pd(_mm512_mul_pd(gamma, v50), _mm512_mul_pd(sigma, tmp));
tmp = v41;
 v41 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v51));
 v51 = _mm512_sub_pd(_mm512_mul_pd(gamma, v51), _mm512_mul_pd(sigma, tmp));
tmp = v42;
 v42 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v52));
 v52 = _mm512_sub_pd(_mm512_mul_pd(gamma, v52), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (g - 3) + (k + 3) * ldg]);
sigma = _mm512_set1_pd(G[2 * (g - 3) + (k + 3) * ldg + 1]);
tmp = v30;
 v30 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v40));
 v40 = _mm512_sub_pd(_mm512_mul_pd(gamma, v40), _mm512_mul_pd(sigma, tmp));
tmp = v31;
 v31 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v41));
 v41 = _mm512_sub_pd(_mm512_mul_pd(gamma, v41), _mm512_mul_pd(sigma, tmp));
tmp = v32;
 v32 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v42));
 v42 = _mm512_sub_pd(_mm512_mul_pd(gamma, v42), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (g - 4) + (k + 4) * ldg]);
sigma = _mm512_set1_pd(G[2 * (g - 4) + (k + 4) * ldg + 1]);
tmp = v20;
 v20 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v30));
 v30 = _mm512_sub_pd(_mm512_mul_pd(gamma, v30), _mm512_mul_pd(sigma, tmp));
tmp = v21;
 v21 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v31));
 v31 = _mm512_sub_pd(_mm512_mul_pd(gamma, v31), _mm512_mul_pd(sigma, tmp));
tmp = v22;
 v22 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v32));
 v32 = _mm512_sub_pd(_mm512_mul_pd(gamma, v32), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (g - 5) + (k + 5) * ldg]);
sigma = _mm512_set1_pd(G[2 * (g - 5) + (k + 5) * ldg + 1]);
tmp = v10;
 v10 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v20));
 v20 = _mm512_sub_pd(_mm512_mul_pd(gamma, v20), _mm512_mul_pd(sigma, tmp));
tmp = v11;
 v11 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v21));
 v21 = _mm512_sub_pd(_mm512_mul_pd(gamma, v21), _mm512_mul_pd(sigma, tmp));
tmp = v12;
 v12 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v22));
 v22 = _mm512_sub_pd(_mm512_mul_pd(gamma, v22), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (g - 6) + (k + 6) * ldg]);
sigma = _mm512_set1_pd(G[2 * (g - 6) + (k + 6) * ldg + 1]);
tmp = v00;
 v00 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v10));
 v10 = _mm512_sub_pd(_mm512_mul_pd(gamma, v10), _mm512_mul_pd(sigma, tmp));
tmp = v01;
 v01 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v11));
 v11 = _mm512_sub_pd(_mm512_mul_pd(gamma, v11), _mm512_mul_pd(sigma, tmp));
tmp = v02;
 v02 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v12));
 v12 = _mm512_sub_pd(_mm512_mul_pd(gamma, v12), _mm512_mul_pd(sigma, tmp));
_mm512_storeu_pd(&V[24 * (g - 6)], v00);
_mm512_storeu_pd(&V[24 * (g - 6) + 8 * 1], v01);
_mm512_storeu_pd(&V[24 * (g - 6) + 8 * 2], v02);
v00=v10;
v01=v11;
v02=v12;
v10=v20;
v11=v21;
v12=v22;
v20=v30;
v21=v31;
v22=v32;
v30=v40;
v31=v41;
v32=v42;
v40=v50;
v41=v51;
v42=v52;
v50=v60;
v51=v61;
v52=v62;
v60=v70;
v61=v71;
v62=v72;
}
gamma = _mm512_set1_pd(G[2 * (n - 2) + (k + 1) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 2) + (k + 1) * ldg + 1]);
tmp = v50;
 v50 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v60));
 v60 = _mm512_sub_pd(_mm512_mul_pd(gamma, v60), _mm512_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v61));
 v61 = _mm512_sub_pd(_mm512_mul_pd(gamma, v61), _mm512_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v62));
 v62 = _mm512_sub_pd(_mm512_mul_pd(gamma, v62), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 3) + (k + 2) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 3) + (k + 2) * ldg + 1]);
tmp = v40;
 v40 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v50));
 v50 = _mm512_sub_pd(_mm512_mul_pd(gamma, v50), _mm512_mul_pd(sigma, tmp));
tmp = v41;
 v41 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v51));
 v51 = _mm512_sub_pd(_mm512_mul_pd(gamma, v51), _mm512_mul_pd(sigma, tmp));
tmp = v42;
 v42 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v52));
 v52 = _mm512_sub_pd(_mm512_mul_pd(gamma, v52), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 4) + (k + 3) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 4) + (k + 3) * ldg + 1]);
tmp = v30;
 v30 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v40));
 v40 = _mm512_sub_pd(_mm512_mul_pd(gamma, v40), _mm512_mul_pd(sigma, tmp));
tmp = v31;
 v31 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v41));
 v41 = _mm512_sub_pd(_mm512_mul_pd(gamma, v41), _mm512_mul_pd(sigma, tmp));
tmp = v32;
 v32 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v42));
 v42 = _mm512_sub_pd(_mm512_mul_pd(gamma, v42), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 5) + (k + 4) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 5) + (k + 4) * ldg + 1]);
tmp = v20;
 v20 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v30));
 v30 = _mm512_sub_pd(_mm512_mul_pd(gamma, v30), _mm512_mul_pd(sigma, tmp));
tmp = v21;
 v21 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v31));
 v31 = _mm512_sub_pd(_mm512_mul_pd(gamma, v31), _mm512_mul_pd(sigma, tmp));
tmp = v22;
 v22 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v32));
 v32 = _mm512_sub_pd(_mm512_mul_pd(gamma, v32), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 6) + (k + 5) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 6) + (k + 5) * ldg + 1]);
tmp = v10;
 v10 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v20));
 v20 = _mm512_sub_pd(_mm512_mul_pd(gamma, v20), _mm512_mul_pd(sigma, tmp));
tmp = v11;
 v11 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v21));
 v21 = _mm512_sub_pd(_mm512_mul_pd(gamma, v21), _mm512_mul_pd(sigma, tmp));
tmp = v12;
 v12 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v22));
 v22 = _mm512_sub_pd(_mm512_mul_pd(gamma, v22), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 7) + (k + 6) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 7) + (k + 6) * ldg + 1]);
tmp = v00;
 v00 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v10));
 v10 = _mm512_sub_pd(_mm512_mul_pd(gamma, v10), _mm512_mul_pd(sigma, tmp));
tmp = v01;
 v01 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v11));
 v11 = _mm512_sub_pd(_mm512_mul_pd(gamma, v11), _mm512_mul_pd(sigma, tmp));
tmp = v02;
 v02 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v12));
 v12 = _mm512_sub_pd(_mm512_mul_pd(gamma, v12), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 2) + (k + 2) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 2) + (k + 2) * ldg + 1]);
tmp = v50;
 v50 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v60));
 v60 = _mm512_sub_pd(_mm512_mul_pd(gamma, v60), _mm512_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v61));
 v61 = _mm512_sub_pd(_mm512_mul_pd(gamma, v61), _mm512_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v62));
 v62 = _mm512_sub_pd(_mm512_mul_pd(gamma, v62), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 3) + (k + 3) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 3) + (k + 3) * ldg + 1]);
tmp = v40;
 v40 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v50));
 v50 = _mm512_sub_pd(_mm512_mul_pd(gamma, v50), _mm512_mul_pd(sigma, tmp));
tmp = v41;
 v41 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v51));
 v51 = _mm512_sub_pd(_mm512_mul_pd(gamma, v51), _mm512_mul_pd(sigma, tmp));
tmp = v42;
 v42 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v52));
 v52 = _mm512_sub_pd(_mm512_mul_pd(gamma, v52), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 4) + (k + 4) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 4) + (k + 4) * ldg + 1]);
tmp = v30;
 v30 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v40));
 v40 = _mm512_sub_pd(_mm512_mul_pd(gamma, v40), _mm512_mul_pd(sigma, tmp));
tmp = v31;
 v31 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v41));
 v41 = _mm512_sub_pd(_mm512_mul_pd(gamma, v41), _mm512_mul_pd(sigma, tmp));
tmp = v32;
 v32 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v42));
 v42 = _mm512_sub_pd(_mm512_mul_pd(gamma, v42), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 5) + (k + 5) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 5) + (k + 5) * ldg + 1]);
tmp = v20;
 v20 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v30));
 v30 = _mm512_sub_pd(_mm512_mul_pd(gamma, v30), _mm512_mul_pd(sigma, tmp));
tmp = v21;
 v21 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v31));
 v31 = _mm512_sub_pd(_mm512_mul_pd(gamma, v31), _mm512_mul_pd(sigma, tmp));
tmp = v22;
 v22 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v32));
 v32 = _mm512_sub_pd(_mm512_mul_pd(gamma, v32), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 6) + (k + 6) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 6) + (k + 6) * ldg + 1]);
tmp = v10;
 v10 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v20));
 v20 = _mm512_sub_pd(_mm512_mul_pd(gamma, v20), _mm512_mul_pd(sigma, tmp));
tmp = v11;
 v11 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v21));
 v21 = _mm512_sub_pd(_mm512_mul_pd(gamma, v21), _mm512_mul_pd(sigma, tmp));
tmp = v12;
 v12 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v22));
 v22 = _mm512_sub_pd(_mm512_mul_pd(gamma, v22), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 2) + (k + 3) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 2) + (k + 3) * ldg + 1]);
tmp = v50;
 v50 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v60));
 v60 = _mm512_sub_pd(_mm512_mul_pd(gamma, v60), _mm512_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v61));
 v61 = _mm512_sub_pd(_mm512_mul_pd(gamma, v61), _mm512_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v62));
 v62 = _mm512_sub_pd(_mm512_mul_pd(gamma, v62), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 3) + (k + 4) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 3) + (k + 4) * ldg + 1]);
tmp = v40;
 v40 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v50));
 v50 = _mm512_sub_pd(_mm512_mul_pd(gamma, v50), _mm512_mul_pd(sigma, tmp));
tmp = v41;
 v41 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v51));
 v51 = _mm512_sub_pd(_mm512_mul_pd(gamma, v51), _mm512_mul_pd(sigma, tmp));
tmp = v42;
 v42 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v52));
 v52 = _mm512_sub_pd(_mm512_mul_pd(gamma, v52), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 4) + (k + 5) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 4) + (k + 5) * ldg + 1]);
tmp = v30;
 v30 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v40));
 v40 = _mm512_sub_pd(_mm512_mul_pd(gamma, v40), _mm512_mul_pd(sigma, tmp));
tmp = v31;
 v31 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v41));
 v41 = _mm512_sub_pd(_mm512_mul_pd(gamma, v41), _mm512_mul_pd(sigma, tmp));
tmp = v32;
 v32 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v42));
 v42 = _mm512_sub_pd(_mm512_mul_pd(gamma, v42), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 5) + (k + 6) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 5) + (k + 6) * ldg + 1]);
tmp = v20;
 v20 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v30));
 v30 = _mm512_sub_pd(_mm512_mul_pd(gamma, v30), _mm512_mul_pd(sigma, tmp));
tmp = v21;
 v21 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v31));
 v31 = _mm512_sub_pd(_mm512_mul_pd(gamma, v31), _mm512_mul_pd(sigma, tmp));
tmp = v22;
 v22 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v32));
 v32 = _mm512_sub_pd(_mm512_mul_pd(gamma, v32), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 2) + (k + 4) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 2) + (k + 4) * ldg + 1]);
tmp = v50;
 v50 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v60));
 v60 = _mm512_sub_pd(_mm512_mul_pd(gamma, v60), _mm512_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v61));
 v61 = _mm512_sub_pd(_mm512_mul_pd(gamma, v61), _mm512_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v62));
 v62 = _mm512_sub_pd(_mm512_mul_pd(gamma, v62), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 3) + (k + 5) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 3) + (k + 5) * ldg + 1]);
tmp = v40;
 v40 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v50));
 v50 = _mm512_sub_pd(_mm512_mul_pd(gamma, v50), _mm512_mul_pd(sigma, tmp));
tmp = v41;
 v41 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v51));
 v51 = _mm512_sub_pd(_mm512_mul_pd(gamma, v51), _mm512_mul_pd(sigma, tmp));
tmp = v42;
 v42 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v52));
 v52 = _mm512_sub_pd(_mm512_mul_pd(gamma, v52), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 4) + (k + 6) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 4) + (k + 6) * ldg + 1]);
tmp = v30;
 v30 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v40));
 v40 = _mm512_sub_pd(_mm512_mul_pd(gamma, v40), _mm512_mul_pd(sigma, tmp));
tmp = v31;
 v31 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v41));
 v41 = _mm512_sub_pd(_mm512_mul_pd(gamma, v41), _mm512_mul_pd(sigma, tmp));
tmp = v32;
 v32 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v42));
 v42 = _mm512_sub_pd(_mm512_mul_pd(gamma, v42), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 2) + (k + 5) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 2) + (k + 5) * ldg + 1]);
tmp = v50;
 v50 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v60));
 v60 = _mm512_sub_pd(_mm512_mul_pd(gamma, v60), _mm512_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v61));
 v61 = _mm512_sub_pd(_mm512_mul_pd(gamma, v61), _mm512_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v62));
 v62 = _mm512_sub_pd(_mm512_mul_pd(gamma, v62), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 3) + (k + 6) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 3) + (k + 6) * ldg + 1]);
tmp = v40;
 v40 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v50));
 v50 = _mm512_sub_pd(_mm512_mul_pd(gamma, v50), _mm512_mul_pd(sigma, tmp));
tmp = v41;
 v41 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v51));
 v51 = _mm512_sub_pd(_mm512_mul_pd(gamma, v51), _mm512_mul_pd(sigma, tmp));
tmp = v42;
 v42 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v52));
 v52 = _mm512_sub_pd(_mm512_mul_pd(gamma, v52), _mm512_mul_pd(sigma, tmp));
gamma = _mm512_set1_pd(G[2 * (n - 2) + (k + 6) * ldg]);
sigma = _mm512_set1_pd(G[2 * (n - 2) + (k + 6) * ldg + 1]);
tmp = v50;
 v50 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v60));
 v60 = _mm512_sub_pd(_mm512_mul_pd(gamma, v60), _mm512_mul_pd(sigma, tmp));
tmp = v51;
 v51 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v61));
 v61 = _mm512_sub_pd(_mm512_mul_pd(gamma, v61), _mm512_mul_pd(sigma, tmp));
tmp = v52;
 v52 = _mm512_add_pd(_mm512_mul_pd(gamma, tmp), _mm512_mul_pd(sigma, v62));
 v62 = _mm512_sub_pd(_mm512_mul_pd(gamma, v62), _mm512_mul_pd(sigma, tmp));
_mm512_storeu_pd(&V[24 * (n - 7)], v00);
_mm512_storeu_pd(&V[24 * (n - 7)+ 8 * 1], v01);
_mm512_storeu_pd(&V[24 * (n - 7)+ 8 * 2], v02);
_mm512_storeu_pd(&V[24 * (n - 6)], v10);
_mm512_storeu_pd(&V[24 * (n - 6)+ 8 * 1], v11);
_mm512_storeu_pd(&V[24 * (n - 6)+ 8 * 2], v12);
_mm512_storeu_pd(&V[24 * (n - 5)], v20);
_mm512_storeu_pd(&V[24 * (n - 5)+ 8 * 1], v21);
_mm512_storeu_pd(&V[24 * (n - 5)+ 8 * 2], v22);
_mm512_storeu_pd(&V[24 * (n - 4)], v30);
_mm512_storeu_pd(&V[24 * (n - 4)+ 8 * 1], v31);
_mm512_storeu_pd(&V[24 * (n - 4)+ 8 * 2], v32);
_mm512_storeu_pd(&V[24 * (n - 3)], v40);
_mm512_storeu_pd(&V[24 * (n - 3)+ 8 * 1], v41);
_mm512_storeu_pd(&V[24 * (n - 3)+ 8 * 2], v42);
_mm512_storeu_pd(&V[24 * (n - 2)], v50);
_mm512_storeu_pd(&V[24 * (n - 2)+ 8 * 1], v51);
_mm512_storeu_pd(&V[24 * (n - 2)+ 8 * 2], v52);
_mm512_storeu_pd(&V[24 * (n - 1)], v60);
_mm512_storeu_pd(&V[24 * (n - 1)+ 8 * 1], v61);
_mm512_storeu_pd(&V[24 * (n - 1)+ 8 * 2], v62);
}
